{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MY_aiqxYOG6T"
   },
   "source": [
    "# 全人類がわかるディープラーニング Day3演習\n",
    "\n",
    "## 概要\n",
    "\n",
    "本演習では深層学習の基礎である多層パーセプトロンによる学習を穴埋め形式で実装します。なお、予め用意されたコードはそのまま使用し、指示された穴埋め部を編集してください。\n",
    "演習問題文は<font color=\"Red\">赤字</font>です。このファイルは必ず最後までコードをすべて実行し、「最後までコードが実行可能」・「学習結果の出力がある」・「学習が成功している」の３つを満たした状態で提出してください。\n",
    "\n",
    "また、乱数設定により実行結果が異なるため、<font color=\"Red\">コードを完成させたあと、必ずもう一度一番上のセルから順に最後まで実行して結果を確認してください。</font>\n",
    "\n",
    "所要時間：4~8時間"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7FW9tbQuOG6U"
   },
   "source": [
    "## ライブラリのインポート\n",
    "\n",
    "必要なライブラリをインポートします。エラーになる場合は該当するものをインストールしてください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Jr7dWekfOG6V"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline\n",
    "# 乱数シードを指定\n",
    "np.random.seed(seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hEcnF2whOG6X"
   },
   "outputs": [],
   "source": [
    "if os.path.exists('mnist_784'):\n",
    "    with open('mnist_784','rb') as f:\n",
    "        mnist = pickle.load(f)\n",
    "else:\n",
    "    mnist = datasets.fetch_openml('mnist_784')\n",
    "    with open('mnist_784', 'wb') as f:\n",
    "        pickle.dump(mnist, f)\n",
    "# 画像とラベルを取得\n",
    "X, T = mnist.data, mnist.target\n",
    "# 訓練データとテストデータに分割\n",
    "x_train, x_test, t_train, t_test = train_test_split(X, T, test_size=0.2)\n",
    "\n",
    "# ラベルデータをint型にし、one-hot-vectorに変換します\n",
    "t_train = np.eye(10)[t_train.astype(\"int\")]\n",
    "t_test = np.eye(10)[t_test.astype(\"int\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Emh7bUhBOG6Z"
   },
   "source": [
    "## データの説明\n",
    "\n",
    "mnist と呼ばれる手書き数字の認識問題である。\n",
    "\n",
    "データは 784 次元の配列となっています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oFpveFljOG6Z",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAADgJJREFUeJzt3X+MVfWZx/HPs1o0UowSIhDLSpdo1ahL60RNZrOBoAibJsgfJeWPillkGoKxjcasUZNimiamsd2Ff4hTSxhjS8EfowS0pdGm2sQYR2JGKFCMGWEEhhpMkBiD6LN/zKEdce73zNxzzj13fN6vhNwfz/nx5IbPnHPv997zNXcXgHj+pe4GANSD8ANBEX4gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCOrcVu7MzPg6IVAxd7exLFfoyG9mi8xsv5m9Y2b3F9kWgNayZr/bb2bnSPqbpFskDUp6Q9Jyd/9rYh2O/EDFWnHkv0HSO+7+rrufkvQ7SUsKbA9ACxUJ/6WSDo14PJg99wVm1mVmfWbWV2BfAEpW5AO/0U4tvnRa7+7dkrolTvuBdlLkyD8oadaIx9+QdLhYOwBapUj435B0uZl908wmSfq+pG3ltAWgak2f9rv7aTO7S9IfJJ0jaaO77ymtMwCVanqor6md8Z4fqFxLvuQDYOIi/EBQhB8IivADQRF+ICjCDwRF+IGgCD8QFOEHgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiAowg8ERfiBoAg/EBThB4Ii/EBQhB8IivADQRF+IKimp+iWJDMbkPSRpM8knXb3jjKaAqq2bNmyZH3Lli3Jel9fX7Le2dmZrJ86dSpZb4VC4c/Md/cPStgOgBbitB8Iqmj4XdJOM3vTzLrKaAhAaxQ97e9098NmdomkP5rZPnd/ZeQC2R8F/jAAbabQkd/dD2e3xyT1SrphlGW63b2DDwOB9tJ0+M1ssplNOXNf0kJJu8tqDEC1ipz2T5fUa2ZntvNbd/99KV0BqFzT4Xf3dyX9e4m9AKW6+uqrG9buuOOO5Lrunqzv3Lmz0PrtgKE+ICjCDwRF+IGgCD8QFOEHgiL8QFBl/KoPaEtr1qxpWFu0aFFy3f7+/mR9x44dyfqnn36arLcDjvxAUIQfCIrwA0ERfiAowg8ERfiBoAg/EBTj/F8BV155ZcPaxx9/nFz34MGDZbfTMg8++GCynnd57pTHH388Wd+1a1fT224XHPmBoAg/EBThB4Ii/EBQhB8IivADQRF+IChr5SWGzaz9r2fchh599NFkfdWqVQ1rJ06cSK573XXXJesffvhhsl6lOXPmJOuvvfZasj5t2rSGtVdffTW57uLFi5P1vO9P1MndbSzLceQHgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaByf89vZhslfVfSMXe/JntuqqQtkmZLGpC0zN3rGxBucxdeeGGy3tnZmazfeuutyfqUKVOaqknSvHnzkvXe3t5kvYjJkycn63lj7alx/DzHjx9P1s8777xkvZ3H+cdqLEf+TZLOnuHgfkkvufvlkl7KHgOYQHLD7+6vSDr7z+QSST3Z/R5Jt5XcF4CKNfuef7q7H5Gk7PaS8loC0AqVX8PPzLokdVW9HwDj0+yRf8jMZkpSdnus0YLu3u3uHe7e0eS+AFSg2fBvk7Qiu79C0vPltAOgVXLDb2abJb0m6VtmNmhmKyU9IukWMzsg6ZbsMYAJJPc9v7svb1BaUHIvE1beOPy6deuS9SuuuKLQ/gcHBxvWHnvsseS627dvL7TvIhYsSP8XWr9+faHtHz16tGFt69atyXXrvI5Bq/ANPyAowg8ERfiBoAg/EBThB4Ii/EBQTNE9RjfddFPD2kMPPZRct+hQ3o4dO5L1F154oWFtw4YNhfZd1AUXXNCwlvdT5qJ6enoa1jZv3lzpvicCjvxAUIQfCIrwA0ERfiAowg8ERfiBoAg/EBTj/JlJkyYl60uWLGlYKzpevW3btmT96aefTtaffPLJQvuvUupnu/fdd1+hbb///vvJ+p49ewpt/6uOIz8QFOEHgiL8QFCEHwiK8ANBEX4gKMIPBGXu3rqdmbVuZ+OUd/ntF198sbJ9v/zyy8n6zTffXNm+i1q4cGGynro0+Lnnpr9mMjQ0lKznvS5Rx/nd3cayHEd+ICjCDwRF+IGgCD8QFOEHgiL8QFCEHwgqd5zfzDZK+q6kY+5+TfbcWkmrJP09W+wBd2988fh/bqttx/nzLF26tGEt7/f0qWvXl2Hfvn0Na729vZXue/78+cl6ar6DPP39/cn69ddfn6yfPn266X1PZGWO82+StGiU5//X3edm/3KDD6C95Ibf3V+RdLwFvQBooSLv+e8ys34z22hmF5fWEYCWaDb8GyTNkTRX0hFJv2i0oJl1mVmfmfU1uS8AFWgq/O4+5O6fufvnkn4l6YbEst3u3uHuHc02CaB8TYXfzGaOeLhU0u5y2gHQKrmX7jazzZLmSZpmZoOSfiJpnpnNleSSBiT9sMIeAVSA3/OX4KKLLkrW77333mR99erVyfrUqVPH3VOrmKWHlIv8/9q/f3+yvmjRaCPQ//Tee+81ve+JjN/zA0gi/EBQhB8IivADQRF+ICjCDwTFUF8bmD59erK+ePHiZP2qq65qWDt69Ghy3bvvvjtZv+yyy5L1IkN9zz33XHLde+65J1kfGBhI1qNiqA9AEuEHgiL8QFCEHwiK8ANBEX4gKMIPBJX7e35UL28q6k2bNlW27xtvvDFZzxvnL+LAgQPJOuP41eLIDwRF+IGgCD8QFOEHgiL8QFCEHwiK8ANBMc7/Fbdy5cpk/dprry20/U8++SRZT01tvns3c73UiSM/EBThB4Ii/EBQhB8IivADQRF+ICjCDwSVe91+M5sl6QlJMyR9Lqnb3deZ2VRJWyTNljQgaZm7f5izLa7bX4E777yzYW39+vXJdc8///xC++7v70/W586dW2j7GL8yr9t/WtK97n6VpJskrTGzqyXdL+kld79c0kvZYwATRG743f2Iu+/K7n8kaa+kSyUtkdSTLdYj6baqmgRQvnG95zez2ZK+Lel1SdPd/Yg0/AdC0iVlNwegOmP+br+ZfV3SM5J+7O4n8uZoG7Fel6Su5toDUJUxHfnN7GsaDv5v3P3Z7OkhM5uZ1WdKOjbauu7e7e4d7t5RRsMAypEbfhs+xP9a0l53/+WI0jZJK7L7KyQ9X357AKoyltP+Tkk/kPS2mb2VPfeApEckbTWzlZIOSvpeNS1i/vz5TdeLDuXt27cvWX/44YcLbR/1yQ2/u/9FUqM3+AvKbQdAq/ANPyAowg8ERfiBoAg/EBThB4Ii/EBQXLq7DcyYMSNZv/3225P15cuXl9nOF+zcuTNZ7+3trWzfqBZHfiAowg8ERfiBoAg/EBThB4Ii/EBQhB8IinH+NpD3m/sFC6r75fTq1auT9e7u7sr2jXpx5AeCIvxAUIQfCIrwA0ERfiAowg8ERfiBoBjnbwOHDh0qVD958mTD2tq1a5PrPvXUU8l63hTumLg48gNBEX4gKMIPBEX4gaAIPxAU4QeCIvxAUJY3jmtmsyQ9IWmGpM8ldbv7OjNbK2mVpL9niz7g7i/kbItBY6Bi7m5jWW4s4Z8paaa77zKzKZLelHSbpGWSTrr7o2NtivAD1Rtr+HO/4efuRyQdye5/ZGZ7JV1arD0AdRvXe34zmy3p25Jez566y8z6zWyjmV3cYJ0uM+szs75CnQIoVe5p/z8WNPu6pD9L+pm7P2tm0yV9IMkl/VTDbw3+O2cbnPYDFSvtPb8kmdnXJG2X9Ad3/+Uo9dmStrv7NTnbIfxAxcYa/tzTfjMzSb+WtHdk8LMPAs9YKmn3eJsEUJ+xfNr/H5JelfS2hof6JOkBScslzdXwaf+ApB9mHw6mtsWRH6hYqaf9ZSH8QPVKO+0H8NVE+IGgCD8QFOEHgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCKrVU3R/IOm9EY+nZc+1o3btrV37kuitWWX2dtlYF2zp7/m/tHOzPnfvqK2BhHbtrV37kuitWXX1xmk/EBThB4KqO/zdNe8/pV17a9e+JHprVi291fqeH0B96j7yA6hJLeE3s0Vmtt/M3jGz++vooREzGzCzt83srbqnGMumQTtmZrtHPDfVzP5oZgey21GnSaupt7Vm9n722r1lZv9VU2+zzOxPZrbXzPaY2Y+y52t97RJ91fK6tfy038zOkfQ3SbdIGpT0hqTl7v7XljbSgJkNSOpw99rHhM3sPyWdlPTEmdmQzOznko67+yPZH86L3f1/2qS3tRrnzM0V9dZoZuk7VONrV+aM12Wo48h/g6R33P1ddz8l6XeSltTQR9tz91ckHT/r6SWSerL7PRr+z9NyDXprC+5+xN13Zfc/knRmZulaX7tEX7WoI/yXSjo04vGg2mvKb5e008zeNLOuupsZxfQzMyNlt5fU3M/ZcmdubqWzZpZum9eumRmvy1ZH+EebTaSdhhw63f07khZLWpOd3mJsNkiao+Fp3I5I+kWdzWQzSz8j6cfufqLOXkYapa9aXrc6wj8oadaIx9+QdLiGPkbl7oez22OSejX8NqWdDJ2ZJDW7PVZzP//g7kPu/pm7fy7pV6rxtctmln5G0m/c/dns6dpfu9H6qut1qyP8b0i63My+aWaTJH1f0rYa+vgSM5ucfRAjM5ssaaHab/bhbZJWZPdXSHq+xl6+oF1mbm40s7Rqfu3abcbrWr7kkw1l/J+kcyRtdPeftbyJUZjZv2n4aC8N/+Lxt3X2ZmabJc3T8K++hiT9RNJzkrZK+ldJByV9z91b/sFbg97maZwzN1fUW6OZpV9Xja9dmTNel9IP3/ADYuIbfkBQhB8IivADQRF+ICjCDwRF+IGgCD8QFOEHgvp/KFspzNrw4W8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label:  [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label:  [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label:  [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label:  [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# データを5つ表示\n",
    "for i in range(5):\n",
    "    plt.gray()\n",
    "    plt.imshow(x_train[i].reshape((28,28)))\n",
    "    plt.show()\n",
    "    print(\"label: \", t_train[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Bouk_Et-OG6b"
   },
   "source": [
    "## Optimizer の実装"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EPWM5OYiOG6c"
   },
   "source": [
    "### 確率的勾配降下法\n",
    "\n",
    "1-1. <font color=\"Red\">確率的勾配降下法を用いたOptimizerのクラス SGD を完成させてください。</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SNsQV6acOG6d"
   },
   "outputs": [],
   "source": [
    "class SGD:\n",
    "\n",
    "    def __init__(self, lr=0.01):\n",
    "        self.lr = lr\n",
    "        \n",
    "    def update(self, params, grads):\n",
    "        for key in params.keys():\n",
    "            ###### 問1-1 ######z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n8S61WJZOG6e"
   },
   "source": [
    "### Adam\n",
    "\n",
    "1-2. <font color=\"Red\">Adamを用いたOptimizerのクラス Adam を完成させてください。</font>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sdM19jOEOG6f"
   },
   "outputs": [],
   "source": [
    "class Adam:\n",
    "\n",
    "    def __init__(self, lr=0.001, beta1=0.9, beta2=0.999):\n",
    "        self.lr = lr\n",
    "        self.beta1 = beta1\n",
    "        self.beta2 = beta2\n",
    "        self.iter = 0\n",
    "        self.m = None\n",
    "        self.v = None\n",
    "        \n",
    "    def update(self, params, grads):\n",
    "        if self.m is None:\n",
    "            self.m, self.v = {}, {}\n",
    "            for key, val in params.items():\n",
    "                self.m[key] = np.zeros_like(val)\n",
    "                self.v[key] = np.zeros_like(val)\n",
    "        \n",
    "        self.iter += 1\n",
    "        \n",
    "        for key in params.keys():\n",
    "            self.m[key] = ###### 問1-2-1 ######\n",
    "            self.v[key] = ###### 問1-2-2 ######\n",
    "            m_unbias = self.m[key] / ###### 問1-2-3 ######\n",
    "            v_unbias = self.v[key] / ###### 問1-2-4 ######\n",
    "            params[key] -= self.lr * m_unbias / (np.sqrt(v_unbias) + 1e-7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "R-NaWscJOG6g"
   },
   "source": [
    "## コスト関数\n",
    "\n",
    "多クラス分類問題なので、クロスエントロピーをコスト関数して用います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kwiPxmeMOG6h"
   },
   "outputs": [],
   "source": [
    "def cross_entropy_error(y, t):\n",
    "    if y.ndim == 1:\n",
    "        t = t.reshape(1, t.size)\n",
    "        y = y.reshape(1, y.size)\n",
    "    if t.size == y.size:\n",
    "        t = t.argmax(axis=1)\n",
    "    batch_size = y.shape[0]\n",
    "    return -np.sum(np.log(y[np.arange(batch_size), t] + 1e-7)) / batch_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OL6uU4NXOG6i"
   },
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    x = x.T\n",
    "    _x = x - np.max(x, axis=0)\n",
    "    _x = np.exp(_x) / np.sum(np.exp(_x), axis=0)\n",
    "    return _x.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Y78Ii3foOG6k"
   },
   "source": [
    "## ネットワークの実装\n",
    "\n",
    "まずはバッチ正規化を入れない普通の三層ニューラルネットワークを実装します。問題にはなっていませんが、day1の復習も兼ねてコードを読み理解しておいてください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YkgxEeUhOG6l"
   },
   "outputs": [],
   "source": [
    "class mnistMultiLayerNet:\n",
    "    \"\"\"\n",
    "    layer0: 784 次元の入力\n",
    "    ↓ w1, b1 で線形結合\n",
    "    ↓ relu で活性化\n",
    "    layer1: 100 次元の隠れ層\n",
    "    ↓ w2, b2 で線形結合\n",
    "    ↓ relu で活性化\n",
    "    layer2: 100 次元の隠れ層\n",
    "    ↓ w3, b3 で線形結合\n",
    "    ↓ relu で活性化\n",
    "    layer3: 100 次元の隠れ層\n",
    "    ↓ w4, b4 で線形結合\n",
    "    ↓ relu で活性化\n",
    "    layer4: 100 次元の隠れ層\n",
    "    ↓ w5, b5 で線形結合\n",
    "    layer5: 10 次元の出力層\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.input_size = 784\n",
    "        self.output_size = 10\n",
    "        self.hidden_size_list = [100, 100, 100, 100]\n",
    "        self.all_size_list = [self.input_size] + self.hidden_size_list + [self.output_size]\n",
    "        self.hidden_layer_num = len(self.hidden_size_list)\n",
    "        self.weight_decay_lambda =0\n",
    "        self.params = {}\n",
    "        self.layers = {}\n",
    "        self.grads = {}\n",
    "\n",
    "        # 重みとバイアスの初期化\n",
    "        for idx in range(1, len(self.all_size_list)):\n",
    "            self.params['w' + str(idx)] = np.random.randn(self.all_size_list[idx-1], self.all_size_list[idx]) * 0.085\n",
    "            self.params['b' + str(idx)] = np.zeros(self.all_size_list[idx], dtype=float)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        relu = lambda x : np.maximum(0, x)  # 活性化関数として ReLU を使用\n",
    "        self.layers['layer0'] = x\n",
    "        for idx in range(1, len(self.all_size_list) - 1):\n",
    "            w = self.params['w' + str(idx)]\n",
    "            b = self.params['b' + str(idx)]\n",
    "            x = self.layers['layer' + str(idx - 1)]\n",
    "            self.layers['layer' + str(idx)] = relu(np.dot(x, w) + b)\n",
    "        idx = len(self.all_size_list) - 1\n",
    "        w = self.params['w' + str(idx)]\n",
    "        b = self.params['b' + str(idx)]\n",
    "        x = self.layers['layer' + str(idx - 1)]\n",
    "        self.layers['layer' + str(idx)] = softmax(np.dot(x, w) + b)\n",
    "        \n",
    "        return self.layers['layer' + str(idx)]\n",
    "        \n",
    "\n",
    "    def loss(self, y, t):\n",
    "        return cross_entropy_error(y, t)\n",
    "    \n",
    "    def backward(self, t, y):\n",
    "        delta = (y - t) / t.shape[0]\n",
    "        self.grads['b5'] = np.sum(delta, axis=0)\n",
    "        self.grads['w5'] = np.dot(self.layers['layer4'].transpose(), delta)\n",
    "        # 誤差逆伝播\n",
    "        for idx in range(4, 0, -1):\n",
    "            delta = np.dot(delta, self.params['w' + str(idx + 1)].transpose())\n",
    "            delta = delta *  (self.layers['layer' + str(idx)] > 0)\n",
    "            self.grads['b' + str(idx)] = np.sum(delta, axis=0)\n",
    "            self.grads['w' + str(idx)] = np.dot(self.layers['layer'+str(idx - 1)].transpose(), delta)\n",
    "        return self.grads\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZGnDfiCwOG6m"
   },
   "source": [
    "## バッチ正規化を用いるネットワーク\n",
    "\n",
    "各層について、重みを掛けて足し合わせた後バッチ正規化を行う。\n",
    "\n",
    "2. <font color=\"Red\">バッチ正規化を用いたニューラルネットワークを完成させてください。</font>\n",
    "\n",
    "  バッチ正規化の順伝播は以下の式に従って実装します。\n",
    "  \n",
    "  - （訓練時のみ）まずは計算しているミニバッチについて、平均と分散を求めます。各次元について、全データを通じた平均・分散を計算するため、平均・分散を計算する軸にご注意ください。\n",
    "\n",
    "  - （訓練時のみ）テスト時に使用するために、訓練データ全体での平均を推定します。モーメンタム $m$ を用いて今までの平均 $\\mu_{old} $ を計算しているミニバッチの平均 $\\mu$ の方向に移動させ、新しい平均$\\mu_{new} $を求めます。\n",
    "  $$\n",
    "  \\mu_{new} = m \\mu_{old} + ( 1 - m)\\mu\n",
    "  $$\n",
    "\n",
    "  - （訓練時のみ）同様に今までの分散 $\\sigma_{old} ^ 2$ を計算しているミニバッチの平均 $\\sigma^2$の方向に移動させ、 新しい分散$\\sigma_{new}^2$ を求めます。\n",
    "  $$\n",
    "  \\sigma_{new}^2 = m \\sigma_{old}^2 + ( 1 - m)\\sigma^2\n",
    "  $$\n",
    "\n",
    "  - 求めた平均 $\\mu$ と分散 $\\sigma^2$ を用いて、入力 $x$ を正規化した値 $x_n$ を求めます。分散$\\sigma^2$から標準偏差 $\\sigma$ を求めるときに、アンダーフローを避けるために 10e-7 ($10 \\times 10 ^ {-7}$) を足してから平方根を取っています。\n",
    "  テスト時には、移動平均により推定した訓練データ全体での平均・分散を使用します。\n",
    "  $$\n",
    "  \\sigma = \\sqrt{\\sigma ^ 2 + 10 \\times 10 ^ {-7}} \n",
    "  $$\n",
    "  $$\n",
    "  x_n = (x - \\mu) / \\sigma\n",
    "  $$\n",
    "\n",
    "   - 正規化した値 $x_n$に対して $\\gamma$ を用いて変倍し、$\\beta$ を用いて移動を行い、活性化関数に渡す出力 $y$ を求めます。\n",
    "   $$\n",
    "   y = \\gamma x_n + \\beta\n",
    "   $$\n",
    " \n",
    "   バッチ正規化の誤差逆伝播は以下の式に従って実装します。\n",
    "   \n",
    "   - 直前まで逆伝播してきた$1, 2, \\dots , N$ 番目(Nはバッチサイズ)の出力データ$y_k$による勾配 $\\frac{\\partial L}{\\partial y_k}$を用いて $\\gamma$ と$\\beta$による勾配を計算します。 $x_{nk}$ はミニバッチの中のk番目の入力データを正規化した後の値を表します。\n",
    "   $$\n",
    "   \\begin{eqnarray} \n",
    "   \\frac{\\partial L}{\\partial \\gamma} & = & \\sum_{k=1}^{N} \\frac{\\partial L}{\\partial y_k} \\frac{\\partial y_k}{\\partial \\gamma} = \\sum_{k=1}^{N} \\frac{\\partial L}{\\partial y_k} x_{nk} \\\\ \n",
    "\\frac{\\partial L}{\\partial \\beta} & = & \\sum_{k=1}^{N} \\frac{\\partial L}{\\partial y_k} \\frac{\\partial y_k}{\\partial \\beta} =  \\sum_{k=1}^{N} \\frac{\\partial L}{\\partial y_k} \n",
    "\\end{eqnarray}\n",
    "   $$\n",
    "   \n",
    "   - $1, 2, \\dots , N$ 番目の入力データ$x_k$による勾配 $\\frac{\\partial L}{\\partial x_k}$を計算します（コードでは高速化のため少々異なった計算をしています）。\n",
    "   \n",
    "   $$\n",
    "  \\begin{equation} \n",
    "  \\frac{\\partial L}{\\partial x_k} \n",
    "  = \\frac{\\gamma}{\\sigma} \\Bigg[ \\frac{\\partial L}{\\partial y_k} \n",
    "  - \\frac{1}{N} \\bigg[ \\frac{\\partial L}{\\partial \\beta} + x_{nk} \\frac{\\partial L}{\\partial \\gamma} \\bigg] \\Bigg] \n",
    "  \\end{equation}\n",
    "  $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zavAJFafOG6n"
   },
   "outputs": [],
   "source": [
    "class mnistMultiLayerBatchNet:\n",
    "    \"\"\"\n",
    "    layer0: 784 次元の入力\n",
    "    ↓ w1, b1 で線形結合\n",
    "    ↓バッチ正規化 gamma1倍しbeta1だけずらす\n",
    "    ↓ relu で活性化\n",
    "    layer1: 100 次元の隠れ層\n",
    "    ↓ w2, b2 で線形結合\n",
    "    ↓バッチ正規化 gamma2倍しbeta2だけずらす\n",
    "    ↓ relu で活性化\n",
    "    layer2: 100 次元の隠れ層\n",
    "    ↓ w3, b3 で線形結合\n",
    "    ↓バッチ正規化 gamma3倍しbeta3だけずらす\n",
    "    ↓ relu で活性化\n",
    "    layer3: 100 次元の隠れ層\n",
    "    ↓ w4, b4 で線形結合\n",
    "    ↓バッチ正規化 gamma4倍しbeta4だけずらす\n",
    "    ↓ relu で活性化\n",
    "    layer4: 100 次元の隠れ層\n",
    "    ↓ w5, b5 で線形結合\n",
    "    layer5: 10 次元の出力層\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.input_size = 784\n",
    "        self.output_size = 10\n",
    "        self.hidden_size_list = [100, 100, 100, 100]\n",
    "        self.all_size_list = [self.input_size] + self.hidden_size_list + [self.output_size]\n",
    "        self.hidden_layer_num = len(self.hidden_size_list)\n",
    "        self.weight_decay_lambda =0\n",
    "        self.params = {}\n",
    "        self.layers = {}\n",
    "        self.grads = {}\n",
    "        self.norms = {}\n",
    "        self.momentum = 0.9\n",
    "\n",
    "        # パラメータの初期化\n",
    "        for idx in range(1, len(self.all_size_list)):\n",
    "            # 線形結合層のパラメータ\n",
    "            self.params['w' + str(idx)] = np.random.randn(self.all_size_list[idx-1], self.all_size_list[idx]) * 0.085\n",
    "            self.params['b' + str(idx)] = np.zeros(self.all_size_list[idx], dtype=float)\n",
    "            \n",
    "            # バッチ正規化でシフトさせるときに用いるγとβを更新するパラメータとし初期化\n",
    "            # mu と sigma は実行時の平均と分散\n",
    "            if idx != len(self.all_size_list) - 1:\n",
    "                self.params['gamma' + str(idx)] = np.ones(self.all_size_list[idx])\n",
    "                self.params['beta' + str(idx)] = np.zeros(self.all_size_list[idx])\n",
    "                self.norms['mu' + str(idx)] = None\n",
    "                self.norms['var' + str(idx)] = None\n",
    "        \n",
    "    def forward(self, x, train_flg=False):\n",
    "        relu = lambda x : np.maximum(0, x)  # 活性化関数として ReLU を使用\n",
    "        self.layers['layer0'] = x\n",
    "        for idx in range(1, len(self.all_size_list) - 1):\n",
    "            # 線形結合層\n",
    "            w = self.params['w' + str(idx)]\n",
    "            b = self.params['b' + str(idx)]\n",
    "            x = self.layers['layer' + str(idx - 1)]\n",
    "            x = np.dot(x, w) + b\n",
    "            \n",
    "            # バッチ正規化\n",
    "            # 平均と分散の初期化\n",
    "            if self.norms['mu' + str(idx)] is None:\n",
    "                N, D = x.shape\n",
    "                self.norms['mu' + str(idx)] = np.zeros(D)\n",
    "                self.norms['var' + str(idx)] = np.zeros(D)\n",
    "            if train_flg:\n",
    "                mu = ###### 問2.1 ######          # 今回のミニバッチの平均\n",
    "                xc = x - mu                   # 今回のミニバッチの平均との差分\n",
    "                var = ###### 問2.2 ######  # 今回のミニバッチの分散\n",
    "                std = np.sqrt(var + 10e-7)    # 今回のミニバッチの標準偏差\n",
    "                xn = xc / std                 # 正規化\n",
    "\n",
    "                # 全体の平均と分散を移動平均により求める\n",
    "                self.norms['mu' + str(idx)] = ###### 問2.3 ######\n",
    "                self.norms['var' + str(idx)] = ###### 問2.4 ######\n",
    "                \n",
    "                # 誤差逆伝播で使う中間データ\n",
    "                self.norms['xc' + str(idx)] = xc\n",
    "                self.norms['xn' + str(idx)] = xn\n",
    "                self.norms['std' + str(idx)] = std\n",
    "                self.norms['size' + str(idx)] = x.shape[0]\n",
    "            else:\n",
    "                # テスト時は全体の平均と分散を使って正規化する\n",
    "                xc = ###### 問2.5 ######\n",
    "                xn = ###### 問2.6 ######\n",
    "                \n",
    "            # バッチ正規化でシフトさせる\n",
    "            shifted = ###### 問2.7 ######\n",
    "            \n",
    "            # relu を使って活性化\n",
    "            self.layers['layer' + str(idx)] = relu(shifted)\n",
    "\n",
    "        # 出力層\n",
    "        idx = len(self.all_size_list) - 1\n",
    "        w = self.params['w' + str(idx)]\n",
    "        b = self.params['b' + str(idx)]\n",
    "        x = self.layers['layer' + str(idx - 1)]\n",
    "        self.layers['layer' + str(idx)] = softmax(np.dot(x, w) + b)\n",
    "        \n",
    "        return self.layers['layer' + str(idx)]\n",
    "        \n",
    "\n",
    "    def loss(self, y, t):\n",
    "        return cross_entropy_error(y, t)\n",
    "    \n",
    "    def backward(self, t, y):\n",
    "        # 出力層における誤差の勾配（クロスエントロピー関数の勾配）\n",
    "        delta = (y - t) / t.shape[0]\n",
    "        \n",
    "        # 出力層手前の線形結合層における勾配の逆伝播\n",
    "        self.grads['b5'] = np.sum(delta, axis=0)\n",
    "        self.grads['w5'] = np.dot(self.layers['layer4'].transpose(), delta)\n",
    "        \n",
    "        # 誤差逆伝播\n",
    "        for idx in range(4, 0, -1):\n",
    "            delta = np.dot(delta, self.params['w' + str(idx + 1)].transpose())\n",
    "            \n",
    "            # relu の微分\n",
    "            delta = delta *  (self.layers['layer' + str(idx)] > 0)\n",
    "            \n",
    "            # バッチ正規化における勾配の逆伝播\n",
    "            self.grads['beta' + str(idx)] = ###### 問2.8 ######\n",
    "            self.grads['gamma' + str(idx)] = ###### 問2.9 ######\n",
    "            dxn = self.params['gamma' + str(idx)] * delta\n",
    "            dxc = dxn / self.norms['std' + str(idx)]\n",
    "            dstd = -np.sum((dxn * self.norms['xc' + str(idx)]) / (self.norms['std' + str(idx)] * self.norms['std' + str(idx)]), axis=0)\n",
    "            dvar = 0.5 * dstd / self.norms['std' + str(idx)]\n",
    "            dxc += (2.0 / self.norms['size' + str(idx)]) * self.norms['xc' + str(idx)] * dvar\n",
    "            dmu = np.sum(dxc, axis=0)\n",
    "            delta = dxc - dmu / self.norms['size' + str(idx)]\n",
    "            \n",
    "            # 線形結合層における勾配の逆伝播\n",
    "            self.grads['b' + str(idx)] = np.sum(delta, axis=0)\n",
    "            self.grads['w' + str(idx)] = np.dot(self.layers['layer'+str(idx - 1)].transpose(), delta)\n",
    "            \n",
    "        return self.grads\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2QrrsrJHOG6p"
   },
   "source": [
    "## ミニバッチを用いた学習\n",
    "\n",
    "3. <font color=\"Red\">ミニバッチサイズ128に分割して学習させるように以下のプログラムを完成させてください。</font>\n",
    " - xとtの対応を保ったままシャッフルさせたのち、バッチサイズ分だけデータを取り出します。\n",
    " - ヒント: numpy.random.permutation を用いることで、データのインデックスをシャッフルした配列を用意することで、シャッフルインデックス配列permに対して、前からバッチサイズずつインデックスを切り出せばミニバッチの抽出が行えます。\n",
    " - また、学習用のコードは実行に時間がかかります。完了するまで5~10分ほどを要しますのでご注意ください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SR705KyHOG6p"
   },
   "outputs": [],
   "source": [
    "bn = mnistMultiLayerBatchNet()\n",
    "nobn = mnistMultiLayerNet()\n",
    "adambn = mnistMultiLayerBatchNet()\n",
    "adamnobn = mnistMultiLayerNet()\n",
    "\n",
    "bn_acc_list = []\n",
    "nobn_acc_list = []\n",
    "adambn_acc_list = []\n",
    "adamnobn_acc_list = []\n",
    "\n",
    "sgd = SGD(lr = 0.01)\n",
    "adam = Adam(lr=0.01)\n",
    "\n",
    "# ミニバッチアルゴリズム\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hL36vPejOG6r",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for epoch in range(20):\n",
    "    # ランダムにミニバッチへ分割するために、インデックスをランダムに並び替える\n",
    "    perm = ###### 問3.1 ######\n",
    "    \n",
    "    # batch_size ごとにデータを読み込んで学習させる\n",
    "    for idx in ###### 問3.2 ######:\n",
    "        x = ###### 問3.3 ######\n",
    "        t =  ###### 問3.4 ######\n",
    "        \n",
    "        y = bn.forward(x, train_flg=True)\n",
    "        grads = bn.backward(t, y)\n",
    "        sgd.update(bn.params,grads)\n",
    "        \n",
    "        y = adambn.forward(x, train_flg=True)\n",
    "        grads = adambn.backward(t, y)\n",
    "        adam.update(adambn.params,grads)\n",
    "        \n",
    "        y = nobn.forward(x)\n",
    "        grads = nobn.backward(t,y)\n",
    "        sgd.update(nobn.params, grads)\n",
    "        \n",
    "        y = adamnobn.forward(x)\n",
    "        grads = adamnobn.backward(t, y)\n",
    "        adam.update(adamnobn.params,grads)\n",
    "\n",
    "    y_test = bn.forward(x_test)\n",
    "    bn_acc_list.append((y_test.argmax(axis=1) == t_test.argmax(axis=1)).mean())\n",
    "    y_test = nobn.forward(x_test)\n",
    "    nobn_acc_list.append((y_test.argmax(axis=1) == t_test.argmax(axis=1)).mean())\n",
    "    y_test = adambn.forward(x_test)\n",
    "    adambn_acc_list.append((y_test.argmax(axis=1) == t_test.argmax(axis=1)).mean())\n",
    "    y_test = adamnobn.forward(x_test)\n",
    "    adamnobn_acc_list.append((y_test.argmax(axis=1) == t_test.argmax(axis=1)).mean())\n",
    "\n",
    "    print(f'EPOCH {epoch + 1} | NoBatch ACCURACY (SGD) {nobn_acc_list[-1]:.2%} | Batch ACCURACY (SGD){bn_acc_list[-1]:.2%} | NoBatch ACCURACY (Adam){adamnobn_acc_list[-1]:.2%} | Batch ACCURACY (Adam) {adambn_acc_list[-1]:.2%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JYmN3xRhOG6t"
   },
   "source": [
    "## 学習結果\n",
    "学習結果を可視化してみます。まずはSGDを使った学習についてのみ比較を行います。結果のグラフが以下のグラフと一致していれば学習は成功しています。<img src = \"sgd.png\">\n",
    "\n",
    "学習結果からわかる通り、バッチ正規化を加えることでテスト精度が高い水準で安定させることが可能となります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fBfEm6vvOG6t",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x = range(20)\n",
    "plt.plot(x, bn_acc_list, color='turquoise')\n",
    "plt.plot(x, nobn_acc_list, color='tomato')\n",
    "\n",
    "plt.legend(['BatchNormalization', 'Normal Network'])\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bKh5jSYNOG6v"
   },
   "source": [
    "次にAdamで学習した場合も含めてプロットしてみましょう。結果のグラフが以下と一致していれば学習成功です。\n",
    "<img src=\"adam.png\">\n",
    "Adamで学習すると、SGDよりも学習が進みやすく、高い精度が実現できていることがわかるかと思います。\n",
    "\n",
    "また、バッチ正規化を加えないネットワークでは過学習により途中からテスト精度が急に低下していることがわかります。バッチ正規化を加えることで正則化の役割も可能となっていることが読み取れます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MWW5j2lWOG6w"
   },
   "outputs": [],
   "source": [
    "x = range(20)\n",
    "plt.plot(x, bn_acc_list, color='turquoise', linestyle = '-')\n",
    "plt.plot(x, nobn_acc_list, color='tomato', linestyle='-')\n",
    "plt.plot(x, adambn_acc_list, color='turquoise', linestyle = '--')\n",
    "plt.plot(x, adamnobn_acc_list, color='tomato', linestyle='--')\n",
    "\n",
    "plt.ylim((0.85, 1))\n",
    "\n",
    "plt.legend(['BatchNormalization(SGD)', 'Normal Network(SGD)', 'BatchNormalization(Adam)', 'Normal Network(Adam)'])\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Day3演習.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
