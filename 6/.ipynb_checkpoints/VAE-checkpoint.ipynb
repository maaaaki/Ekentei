{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EPZ7IA-GiFHL"
   },
   "source": [
    "この演習のコードは\n",
    "教科書： Francois Chollet さんの「Deep Learning with Python」のサンプルコードを授業用に修正したものです。\n",
    "元のソースコードは[こちら](https://github.com/fchollet/deep-learning-with-python-notebooks/blob/master/8.4-generating-images-with-vaes.ipynb)から見ることができます。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MiJ1odRQ4JBY"
   },
   "outputs": [],
   "source": [
    "#Kerasの設定\n",
    "import keras\n",
    "from keras import layers\n",
    "from keras import backend as K\n",
    "from keras.models import Model\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QfUvWC1Q7wd2"
   },
   "outputs": [],
   "source": [
    "img_shape = (28, 28, 1) # 学習(インプット)データのサイズ\n",
    "input_dim = 784 # 28×28=784：損失関数の計算で使用するためのもの\n",
    "latent_dim = 2  # 潜在空間の次元：今回は可視化が分かりやすいように2次元にする\n",
    "\n",
    "#エンコーダー(画像→潜在変数)\n",
    "input_img = keras.Input(shape=img_shape)\n",
    "# ゼロパディングしてConvolution:28×28×32の特徴マップへ変換\n",
    "x = layers.Conv2D(32, 3,\n",
    "                  padding='same', activation='relu')(input_img) \n",
    "# ゼロパディングしてConvolution:28×28×64の特徴マップへ変換\n",
    "x = layers.Conv2D(64, 3,\n",
    "                  padding='same', activation='relu',\n",
    "                  strides=(2, 2))(x)\n",
    "#ハンズオンでの時間を節約するために以下の構造を省略する\n",
    "#x = layers.Conv2D(64, 3,\n",
    "#                  padding='same', activation='relu')(x)\n",
    "#x = layers.Conv2D(64, 3,\n",
    "#                  padding='same', activation='relu')(x)\n",
    "shape_before_flattening = K.int_shape(x)#画像生成(デコード)時に必要な情報\n",
    "\n",
    "x = layers.Flatten()(x)#28×28×64=50176次元のベクトルに変換\n",
    "x = layers.Dense(32, activation='relu')(x)\n",
    "\n",
    "z_mean = layers.Dense(latent_dim)(x)#潜在変数(二次元)空間上でのガウス分布の平均を出力\n",
    "z_log_var = layers.Dense(latent_dim)(x)#潜在変数(二次元)空間上でのガウス分布の分散を出力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1MfBr18O8JHn"
   },
   "outputs": [],
   "source": [
    "def sampling(args):\n",
    "    z_mean, z_log_var = args\n",
    "    epsilon = K.random_normal(shape=(K.shape(z_mean)[0], latent_dim),\n",
    "                              mean=0., stddev=1.)#Kerasでは一貫して最初の次元がサンプル数(バッチサイズ)\n",
    "    return z_mean + K.exp(z_log_var) * epsilon\n",
    "\n",
    "z = layers.Lambda(sampling)([z_mean, z_log_var])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "legOT9JiK4fz"
   },
   "source": [
    "Kerasでは事前定義された様々な層(Layer)をレゴブロックのように組み合わせてモデルを作成する。 \n",
    "しかし、事前定義された層(Layer)だけでは実装できな機能(Layer)が存在しない場合、自分で層(Layer)を実装する必要がある。\n",
    "独自のLayerを実装するためには、 \n",
    "重みを持たない層(Layer)に関してはLambdaで定義し、\n",
    "学習可能な重みを持たせたい場合はカスタム層(Layer)の実装を行う。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fk1iXW6F8PhJ"
   },
   "outputs": [],
   "source": [
    "#デコーダー(潜在変数→画像)\n",
    "decoder_input = layers.Input(K.int_shape(z)[1:])#デコーダの入力形式(2次元)\n",
    "\n",
    "# flattenする前の画像の形状→flaten後の次元を計算:28×28×64=50176次元\n",
    "# 全結合で2次元→28×28×64=50176次元のベクトルへ変換\n",
    "x = layers.Dense(np.prod(shape_before_flattening[1:]),\n",
    "                 activation='relu')(decoder_input)\n",
    "\n",
    "# 28×28×64次元のベクトルを28×28×64の特徴マップへ変換\n",
    "x = layers.Reshape(shape_before_flattening[1:])(x)\n",
    "\n",
    "# ゼロパディングしてDeconvolution:28×28×32の特徴マップへ変換\n",
    "x = layers.Conv2DTranspose(32, 3,\n",
    "                           padding='same', activation='relu',\n",
    "                           strides=(2, 2))(x)\n",
    "# ゼロパディングしてConvolution:28×28×1の出力画像へ変換\n",
    "#各ピクセルの値を[0,1]に限定していたので活性化関数はsigmoidを使う\n",
    "x = layers.Conv2D(1, 3,\n",
    "                  padding='same', activation='sigmoid')(x)\n",
    "\n",
    "# デコーダモデルを定義\n",
    "decoder = Model(decoder_input, x)\n",
    "\n",
    "# 潜在空間のzをデコードしたz_decodedを定義\n",
    "z_decoded = decoder(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SfY7An9pHwcE"
   },
   "outputs": [],
   "source": [
    "#学習可能な重みを持たせたいのでカスタム層(Layer)で実装\n",
    "class CustomVariationalLayer(keras.layers.Layer):\n",
    "    #VAEの損失関数の定義のまま実装\n",
    "    #ただし、潜在変数のサンプリングはここではデータ毎に１回のみで実装\n",
    "    #(VAEではこれでも十分であることが知られている)\n",
    "    def vae_loss(self, x, z_decoded):\n",
    "        x = K.flatten(x)\n",
    "        z_decoded = K.flatten(z_decoded)\n",
    "       \n",
    "        #keras.metrics.binary_crossentropyは平均値を返すので\n",
    "        #28×28=784次元倍することでavg->sumに変える必要がある\n",
    "        reconst_loss = input_dim*keras.metrics.binary_crossentropy(x, z_decoded)\n",
    "        #潜在変数の次元の軸(axis=-1)でKLlossの和を計算\n",
    "        kl_loss = -0.5*K.sum(\n",
    "            1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)\n",
    "        #データ(バッチ)で平均する\n",
    "        return K.mean(reconst_loss + kl_loss)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = inputs[0]\n",
    "        z_decoded = inputs[1]\n",
    "        loss = self.vae_loss(x, z_decoded)\n",
    "        self.add_loss(loss, inputs=inputs)\n",
    "        # この出力は使わないのでダミー\n",
    "        return x\n",
    "\n",
    "# カスタム層のモデルをcallして損失関数の値を得る\n",
    "y = CustomVariationalLayer()([input_img, z_decoded])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NrT0KCzC8YR9"
   },
   "outputs": [],
   "source": [
    "from keras.datasets import mnist #MNISTを使う場合\n",
    "#from keras.datasets import fashion_mnist #Fashion-MNISTを使う場合\n",
    "\n",
    "vae = Model(input_img, y)\n",
    "vae.compile(optimizer='rmsprop', loss=None)\n",
    "vae.summary()\n",
    "\n",
    "#MNISTを使って学習する場合\n",
    "(x_train, _), (x_test, y_test) = mnist.load_data()\n",
    "#Fashion-MNISTを使って学習する場合\n",
    "#(x_train, _), (x_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "x_train = x_train.astype('float32') / 255.#各ピクセルの値を[0,1]に制限\n",
    "x_train = x_train.reshape(x_train.shape + (1,))#(データ数, 28, 28)→(データ数, 28, 28, 1)へ変換（チャネル数を追加）\n",
    "x_test = x_test.astype('float32') / 255.#各ピクセルの値を[0,1]に制限\n",
    "x_test = x_test.reshape(x_test.shape + (1,))\n",
    "\n",
    "vae.fit(x=x_train, y=None,\n",
    "        shuffle=True,\n",
    "        epochs=2,\n",
    "        batch_size=16,\n",
    "        validation_data=(x_test, None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ziwHG_wt-XSw"
   },
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "\n",
    "#2次元の潜在空間上に画像を配置して可視化\n",
    "n = 15  # 可視化の画像を15×15のグリッドで配置\n",
    "digit_size = 28 #画像のサイズ28×28\n",
    "\n",
    "figure = np.zeros((digit_size * n, digit_size * n))#(28×15)×(28×15)の図を作る\n",
    "#[0.05,0.95]を15のグリッドで区切った空間を\n",
    "#ガウス分布のパーセント点関数(Percent point function)\n",
    "#=累積分布関数の逆関数を使って変換\n",
    "#norm.ppf(0.25)=-0.6745\n",
    "#norm.ppf(0.50)=0.0\n",
    "#norm.ppf(0.75)~0.6745\n",
    "grid_x = norm.ppf(np.linspace(0.05, 0.95, n))\n",
    "grid_y = norm.ppf(np.linspace(0.05, 0.95, n))\n",
    "\n",
    "#画像を配置\n",
    "batch_size=10\n",
    "for i, yi in enumerate(grid_x):\n",
    "    for j, xi in enumerate(grid_y):\n",
    "        #潜在変数を設定\n",
    "        z_sample = np.array([[xi, yi]])\n",
    "        #1つの潜在変数あたりbatch_size個の画像を生成\n",
    "        z_sample = np.tile(z_sample, batch_size).reshape(batch_size, 2)\n",
    "        x_decoded = decoder.predict(z_sample, batch_size=batch_size)\n",
    "        \n",
    "        digits = x_decoded.reshape(batch_size,digit_size, digit_size)\n",
    "        #生成した画像のうち一つだけ表示\n",
    "        digit  = digits[0]\n",
    "        #生成した画像の平均を表示\n",
    "        #digit  = np.mean(digits,axis=0)\n",
    "        \n",
    "        figure[i * digit_size: (i + 1) * digit_size,\n",
    "               j * digit_size: (j + 1) * digit_size] = digit\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(figure, cmap='Greys_r')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "VAE.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
