{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gZ-6_bCyV9vP"
   },
   "source": [
    "# 全人類がわかるディープラーニング Day1演習\n",
    "\n",
    "## 概要\n",
    "\n",
    "本演習では深層学習の基礎である多層パーセプトロンによる学習を穴埋め形式で実装します。<br>\n",
    "予め用意されたコード（訓練用・テスト用データの取得、ミニバッチ学習など）はそのまま使用し、指示された穴埋め部（順伝播と誤差逆伝播）を編集してください。<br>\n",
    "問題は全20問、大きく2つの大問に分かれ、それぞれに10の小問がついています。問題文は<font color=\"Red\">赤字</font>で表示されています。<br>\n",
    "このファイルは必ず最後までコードをすべて実行し、「最後までコードが実行可能」・「学習結果の出力がある」・「学習が成功している」の３つを満たした状態で提出してください。\n",
    "\n",
    "所要時間：3~5時間"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xOUGJkhcV9vQ"
   },
   "source": [
    "## 大問１ 回帰モデル演習\n",
    "\n",
    "### ライブラリのインポート\n",
    "\n",
    "必要なライブラリをインポートします。エラーになる場合は該当するものをインストールしてください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7MatX272V9vR"
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import cv2\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline\n",
    "# \"%matplotlib inline\" の代わりに以下のコマンドを使用できる場合、3次元で座標軸を操作可能なプロットを表示することができます。\n",
    "# %matplotlib notebook\n",
    "\n",
    "\n",
    "# 乱数シードを指定\n",
    "np.random.seed(seed=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_iTHROrWV9vT"
   },
   "source": [
    "### データの３次元散布図を作成する関数\n",
    "\n",
    "データ可視化に使用します。演習の問題とは関係ありませんので読み飛ばしてください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yHUAp5A8V9vT"
   },
   "outputs": [],
   "source": [
    "def plot_data(data, name='Data Plot'):\n",
    "    # グラフ作成\n",
    "    fig = plt.figure()\n",
    "    ax = Axes3D(fig)\n",
    "\n",
    "    # 軸ラベルの設定\n",
    "    ax.set_xlabel(\"X0-axis\")\n",
    "    ax.set_ylabel(\"X1-axis\")\n",
    "    ax.set_zlabel(\"Y-axis\")\n",
    "\n",
    "    # 表示範囲の設定\n",
    "    ax.set_xlim(-2, 2)\n",
    "    ax.set_ylim(-2, 2)\n",
    "    ax.set_zlim(0, 10)\n",
    "\n",
    "    ax.plot(data[:, 0], data[:, 1], data[:, 2],\n",
    "            \"o\", color=\"#ff2222\", ms=2, mew=0.5)\n",
    "    ax.set_title(name)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mI9FnjLqV9vV"
   },
   "source": [
    "### データの読み込み\n",
    "\n",
    "本演習では、train_data.csvを訓練用データ、test_data.csvをテスト用データとして使用します。データはx0, x1, yの3列からなり、以下の式に従っています。\n",
    "\n",
    "$$ y = \\left\\{ \\begin{array}{ll} (x_0-1)^2 + (x_1-1)^2 & (x_0 \\gt 0) \\\\ (x_0+1)^2 + (x_1+1)^2 & (x_0 \\leq 0) \\end{array} \\right. $$\n",
    "\n",
    "訓練データ10000個の(x0, x1, y)の組を多層パーセプトロンで学習し、テストデータ2000個の学習におけるコストの推移を観測します。\n",
    "まずはデータのプロットを表示してみます。\n",
    "\n",
    "※ここでエラーとなっている場合はライブラリのインポートが完了していないか、正常にデータを読み込めていません。同ディレクトリ内にダウンロードした`train_data.csv`と`test_data.csv`が存在していることを確認してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XM3KcYopV9vV",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# データの読み込み\n",
    "with open('train_data.csv') as f:\n",
    "    reader = csv.reader(f)\n",
    "    train_data = np.array([[float(x) for x in row] for row in reader])\n",
    "with open('test_data.csv') as f:\n",
    "    reader = csv.reader(f)\n",
    "    test_data = np.array([[float(x) for x in row] for row in reader])\n",
    "\n",
    "# 訓練データを可視化\n",
    "plot_data(train_data, 'Train Data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mW-UkTq3V9vY"
   },
   "source": [
    "### データの数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2Ru3iZ5yV9vY"
   },
   "outputs": [],
   "source": [
    "N_train = train_data.shape[0]\n",
    "print('訓練データの数: ', N_train)\n",
    "N_test = test_data.shape[0]\n",
    "print('テストデータの数: ', N_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xXM_DlAfV9va"
   },
   "source": [
    "### 活性化関数 relu\n",
    "\n",
    "<font color=\"Red\">問1-1 relu関数を完成させてください。</font>\n",
    "- 以下の式で定義されるrelu関数を実装します。\n",
    "$$ x = relu(v) = \\left\\{ \\begin{array}{ll} v & (v \\gt 0) \\\\ 0 & (v \\leq 0) \\end{array} \\right. $$\n",
    "- 引数`v`の各要素と0の大きい方を取り、`x`とします。\n",
    "- ヒント: numpy.maximum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J4NBTAmMV9va"
   },
   "outputs": [],
   "source": [
    "def relu(v):\n",
    "    '''\n",
    "    活性化関数 relu\n",
    "    v: (float) [N, M]\n",
    "    x: (float) [N, M]\n",
    "    '''\n",
    "    x = #### 問1-1 ####\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ok40MMDdV9vc"
   },
   "source": [
    "### コスト関数 平均二乗誤差\n",
    "\n",
    "<font color=\"Red\">問1-2 関数を完成させてください。</font>\n",
    "- 以下の式で定義されるコスト関数を実装します。\n",
    "$$ MSE = \\frac{1}{n} \\sum_{i}^{n} \\sum_{j}^{k} (t_{ij}-y_{ij})^2 $$\n",
    "$$ n:バッチサイズ, k:出力の次元 $$\n",
    "- `t`と`y`の差の2乗の平均を取り、`mse`とします。\n",
    "- ヒント: numpy.sum(), numpy.mean(), numpy.square()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iWUtjg7lV9vc"
   },
   "outputs": [],
   "source": [
    "def MSE(t, y):\n",
    "    '''\n",
    "    コスト関数 Mean Squared Error\n",
    "    t: (float) [N, M]     \n",
    "    y: (float) [N, M]\n",
    "    mse: (float)\n",
    "    '''\n",
    "    mse = #### 問1-2 ####\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Y2J_LDgPV9ve"
   },
   "source": [
    "### 多層パーセプトロンの定義\n",
    "\n",
    "<font color=\"Red\">問1-3 ~ 1-6 順伝播forward関数を完成させてください。</font>\n",
    "- 以下の式で定義される順伝播を実装します。(Φは活性化関数)\n",
    "$$\n",
    "X_{i+1} = \\phi(X_i \\cdot W_i + B_i)\n",
    "$$    \n",
    "- 第1層`self.layer1`を定義します。入力層`self.layer0`と重み`self.w1`との内積を取り、バイアス`self.b1`を加算します。そして活性化関数`relu`に渡します。\n",
    "- 第2層`self.layer2`を定義します。第1層`self.layer1`と重み`self.w2`との内積を取り、バイアス`self.b2`を加算します。そして活性化関数`relu`に渡します。\n",
    "- 第3層`self.layer3`を定義します。第2層`self.layer2`と重み`self.w3`との内積を取り、バイアス`self.b3`を加算します。そして活性化関数`relu`に渡します。\n",
    "- 出力層`self.out`を定義します。第3層`self.layer3`と重み`self.w4`との内積を取り、バイアス`self.b4`を加算します。\n",
    "- 出力層では活性化関数Φは使用しないことに注意せよ\n",
    "- ヒント: np.dot()<br>\n",
    "\n",
    "<font color=\"Red\"> 問1-7 ~ 1-10 逆伝播によって誤差と勾配を求めるbackward関数を完成させてください。</font>\n",
    "- 出力層誤差`delta4`を定義します。二乗誤差の微分なので、以下の式に従います。\n",
    "$$\n",
    "\\delta_{out} = \\frac{d(T-Y)^2}{dY} = -2(T-Y)\n",
    "$$\n",
    "- 誤差逆伝播は以下の式に従います。\n",
    "$$\n",
    "\\delta_i = \\phi'(v_{i+1})*\\delta_{i+1} \\cdot W_{i+1}^t \n",
    "$$\n",
    "$$\n",
    "\\phi'(v_i) = \\left\\{ \\begin{array}{ll} v_i \\frac{d}{dv_i} & (v_i \\gt 0) \\\\ 0 \\frac{d}{dv_i} & (v_i \\leq 0) \\end{array} \\right. = \n",
    "\\left\\{ \\begin{array}{ll} 1 & (v_i \\gt 0) \\\\ 0 & (v_i \\leq 0) \\end{array} \\right. = \n",
    "\\left\\{ \\begin{array}{ll} 1 & (x_i \\gt 0) \\\\ 0 & (x_i \\leq 0) \\end{array} \\right.\n",
    "\\\\\n",
    "\\phi(v_i) = x_i\n",
    "$$\n",
    "- 第3層誤差`delta3`を定義します。出力層誤差`delta4`と重み`self.w4`の転置との内積を取ります。\n",
    "- 第2層誤差`delta2`を定義します。第3層誤差`delta3`と第3層`self.layer3`におけるreluの微分との積を取り、重み`self.w3`の転置との内積を取ります。\n",
    "- 第1層誤差`delta1`を定義します。第2層誤差`delta2`と第2層`self.layer2`におけるreluの微分との積を取り、重み`self.w2`の転置との内積を取ります。\n",
    "- ヒント: numpy.dot(), numpy.transpose()\n",
    "- ヒント: reluの微分は該当する層の各要素が0より大きいものは1, 0以下のものは0としたベクトルに等しい\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 識別モデル\n",
    "class MLP_regressor():\n",
    "    '''\n",
    "    多層パーセプトロン Multi Layered Perceptron\n",
    "    構成: [入力層, 第1層, 第2層, 第3層, 出力層]\n",
    "    ノード数: [2, 50, 50, 10, 1]\n",
    "    '''\n",
    "\n",
    "    def __init__(self):\n",
    "        '''\n",
    "        コンストラクタ\n",
    "        パラメータ（重みw, バイアスb）の定義\n",
    "        第1層重み self.w1: [2, 50] 平均0, 標準偏差0.1の乱数\n",
    "        第2層重み self.w2: [50, 50] 平均0, 標準偏差0.1の乱数\n",
    "        第3層重み self.w3: [50, 10] 平均0, 標準偏差0.1の乱数\n",
    "        第4層重み self.w4: [10, 1] 平均0, 標準偏差0.1の乱数\n",
    "        \n",
    "        第1層バイアス self.b1: [50] 要素が全て0\n",
    "        第2層バイアス self.b2: [50] 要素が全て0\n",
    "        第3層バイアス self.b3: [10] 要素が全て0\n",
    "        第4層バイアス self.b4: [1] 要素が全て0\n",
    "        \n",
    "        numpyの乱数については以下のページを参照\n",
    "        https://docs.scipy.org/doc/numpy/reference/routines.random.html\n",
    "        '''\n",
    "        \n",
    "        # 重みの定義\n",
    "        self.w1 = np.random.randn(2, 50) * 0.1\n",
    "        self.w2 = np.random.randn(50, 50) * 0.1\n",
    "        self.w3 = np.random.randn(50, 10) * 0.1\n",
    "        self.w4 = np.random.randn(10, 1) * 0.1\n",
    "\n",
    "        # バイアスの定義\n",
    "        self.b1 = np.zeros(50, dtype=float)\n",
    "        self.b2 = np.zeros(50, dtype=float)\n",
    "        self.b3 = np.zeros(10, dtype=float)\n",
    "        self.b4 = np.zeros(1, dtype=float)\n",
    "\n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        順伝播\n",
    "        入力 x: [N, 2]\n",
    "        入力層 self.layer0: [N, 2]\n",
    "        第1層 self.layer1: [N, 50]\n",
    "        第2層 self.layer2: [N, 50]\n",
    "        第3層 self.layer3: [N, 10]\n",
    "        出力層 self.out: [N, 1]\n",
    "        '''\n",
    "        \n",
    "        self.layer0 = x\n",
    "        self.layer1 = #### 問1-3 ####\n",
    "        self.layer2 = #### 問1-4 ####\n",
    "        self.layer3 = #### 問1-5 ####\n",
    "        self.out = #### 問1-6 ####\n",
    "        return self.out\n",
    "\n",
    "    def backward(self, t, y):\n",
    "        '''\n",
    "        逆伝播\n",
    "        真の値 t: [N, 1]\n",
    "        予測値 y: [N, 1]\n",
    "        \n",
    "        出力層誤差 delta4: [N, 1]\n",
    "        第3層誤差 delta3: [N, 10]\n",
    "        第2層誤差 delta2: [N, 50]\n",
    "        第1層誤差 delta1: [N, 50]\n",
    "        \n",
    "        第4層b勾配 dedb4: [1]\n",
    "        第3層b勾配 dedb3: [10]\n",
    "        第2層b勾配 dedb2: [50]\n",
    "        第1層b勾配 dedb1: [50]\n",
    "        \n",
    "        第4層w勾配 dedw4: [10, 1]\n",
    "        第3層w勾配 dedw3: [50, 10]\n",
    "        第2層w勾配 dedw2: [50, 50]\n",
    "        第1層w勾配 dedw1: [2, 50]\n",
    "        '''\n",
    "        \n",
    "        # 出力層の誤差デルタは二乗誤差の微分\n",
    "        delta4 = #### 問1-7 ####\n",
    "        # 誤差逆伝播\n",
    "        delta3 = #### 問1-8 ####\n",
    "        delta2 = #### 問1-9 ####\n",
    "        delta1 = #### 問1-10 ####\n",
    "\n",
    "        # バイアスbのコスト関数eに対する勾配\n",
    "        self.dedb4 = np.mean(delta4, axis=0)\n",
    "        self.dedb3 = np.mean(delta3 * (self.layer3 > 0), axis=0)\n",
    "        self.dedb2 = np.mean(delta2 * (self.layer2 > 0), axis=0)\n",
    "        self.dedb1 = np.mean(delta1 * (self.layer1 > 0), axis=0)\n",
    "\n",
    "        # 重みwのコスト関数eに対する勾配\n",
    "        self.dedw4 = np.dot(self.layer3.T, delta4) / delta4.shape[0]\n",
    "        self.dedw3 = np.dot(self.layer2.T, delta3 * (self.layer3 > 0)) / delta3.shape[0]\n",
    "        self.dedw2 = np.dot(self.layer1.T, delta2 * (self.layer2 > 0)) / delta2.shape[0]\n",
    "        self.dedw1 = np.dot(self.layer0.T, delta1 * (self.layer1 > 0)) / delta1.shape[0]\n",
    "\n",
    "    def optimize_GradientDecent(self, lr):\n",
    "        '''\n",
    "        勾配降下法によるパラメータの更新\n",
    "        '''\n",
    "        self.b1 -= lr * self.dedb1\n",
    "        self.b2 -= lr * self.dedb2\n",
    "        self.b3 -= lr * self.dedb3\n",
    "        self.b4 -= lr * self.dedb4\n",
    "\n",
    "        self.w1 -= lr * self.dedw1\n",
    "        self.w2 -= lr * self.dedw2\n",
    "        self.w3 -= lr * self.dedw3\n",
    "        self.w4 -= lr * self.dedw4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t6W3OikUV9vh"
   },
   "source": [
    "### 学習\n",
    "\n",
    "以下ではこれまでで定義した多層パーセプトロンを使用し、データを学習します。\n",
    "コストが正常に減少し、500epochで0.5以下にまで到達していれば学習は成功していると言えます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Yjt_19ceV9vi"
   },
   "outputs": [],
   "source": [
    "# モデルの定義\n",
    "model = MLP_regressor()\n",
    "\n",
    "# 学習率\n",
    "lr = 0.01\n",
    "# 学習エポック数\n",
    "n_epoch = 500\n",
    "\n",
    "x_train = train_data[:, 0:2]\n",
    "t_train = train_data[:, 2:3]\n",
    "x_test = test_data[:, 0:2]\n",
    "t_test = test_data[:, 2:3]\n",
    "\n",
    "# n_epoch繰り返す\n",
    "for n in range(n_epoch):\n",
    "    # 訓練\n",
    "    # Day1範囲外のため、ミニバッチは使用しない\n",
    "    y = model.forward(x_train)\n",
    "    train_loss = MSE(t_train, y)\n",
    "    model.backward(t_train, y)\n",
    "    model.optimize_GradientDecent(lr)\n",
    "\n",
    "    # テスト\n",
    "    y = model.forward(x_test)\n",
    "    test_loss = MSE(t_test, y)\n",
    "\n",
    "    print('EPOCH ', n + 1, ' | TRAIN LOSS ',\n",
    "          train_loss, ' | TEST LOSS ', test_loss)\n",
    "regression_loss = test_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lrSDsuRJV9vj"
   },
   "source": [
    "### 予測データの散布図\n",
    "\n",
    "予測値の散布図と訓練データの散布図を比較してみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4ZD_ICriV9vk"
   },
   "outputs": [],
   "source": [
    "y = model.forward(x_test)\n",
    "predict_data = np.concatenate([x_test, y], axis=1)\n",
    "plot_data(predict_data, 'Predict Data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XsQUpnKUuono"
   },
   "source": [
    "## 大問２ 分類モデル演習\n",
    "\n",
    "大問１では層ごとに変数を定義し全計算を実装しましたが、大問２ではクラスと計算グラフを利用し、より汎用的なモデルを設計します。\n",
    "\n",
    "### データの読み込み\n",
    "\n",
    "本演習では、mnist(手書き数字データセット)を使用し、全結合ネットワークで手書き数字の画像の10分類を行います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eQTqyXx7uonq"
   },
   "outputs": [],
   "source": [
    "# mnistデータセットのロード(ネットワーク接続が必要・少し時間がかかります)\n",
    "if os.path.exists('mnist_784'):\n",
    "    with open('mnist_784','rb') as f:\n",
    "        mnist = pickle.load(f)\n",
    "else:\n",
    "    mnist = datasets.fetch_openml('mnist_784')\n",
    "    with open('mnist_784', 'wb') as f:\n",
    "        pickle.dump(mnist, f)\n",
    "    \n",
    "# 画像とラベルを取得\n",
    "X, T = mnist.data, mnist.target\n",
    "# 訓練データとテストデータに分割\n",
    "X_train, X_test, T_train, T_test = train_test_split(X, T, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2DTNnp49uons"
   },
   "outputs": [],
   "source": [
    "# ラベルデータをint型にし、one-hot-vectorに変換します\n",
    "T_train = np.eye(10)[T_train.astype(\"int\")]\n",
    "T_test = np.eye(10)[T_test.astype(\"int\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oM_kyhBXuonu"
   },
   "source": [
    "### one-hot-vectorとは？\n",
    "たとえば$a$が，0~9の整数のみを含むベクトルだとわかっている時に、各要素を数字に該当する列の要素のみが1、その他が0となるようなベクトルにする。\n",
    "$$\n",
    "\\begin{equation*}\n",
    "a=\n",
    "\\begin{pmatrix}\n",
    "1\\\\\n",
    "8\\\\\n",
    "4\\\\\n",
    "2\\\\\n",
    "0\n",
    "\\end{pmatrix}\\to\n",
    "a\\_onehot = \n",
    "\\begin{pmatrix}\n",
    "0, 1, 0, 0, 0, 0, 0, 0, 0, 0\\\\\n",
    "0, 0, 0, 0, 0, 0, 0, 0, 1, 0\\\\\n",
    "0, 0, 0, 0, 1, 0, 0, 0, 0, 0\\\\\n",
    "0, 0, 1, 0, 0, 0, 0, 0, 0, 0\\\\\n",
    "1, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
    "\\end{pmatrix}\n",
    "\\end{equation*}\n",
    "$$\n",
    "学習する正解ラベルデータは，one-hot-vectorで表されることが多い．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9ceab9_1uonu"
   },
   "source": [
    "### データの構造\n",
    "データ数、画像データXの形、ラベルTの形などを調べます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YspD5XgIuonv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "訓練データ数\t 56000\n",
      "テストデータ数\t 14000\n",
      "説明変数の形\t (784,)\n",
      "ラベルの形\t (10,)\n"
     ]
    }
   ],
   "source": [
    "N_train = len(X_train)\n",
    "N_test = len(X_test)\n",
    "X_shape = X_train[0].shape\n",
    "T_shape = T_train[0].shape\n",
    "\n",
    "print('訓練データ数\\t', N_train)\n",
    "print('テストデータ数\\t', N_test)\n",
    "print('説明変数の形\\t', X_shape)\n",
    "print('ラベルの形\\t', T_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dftd7w9-uon0"
   },
   "source": [
    "### データのサンプリング\n",
    "画像・ラベルデータをランダムにいくつか取り出して可視化します。\n",
    "画像は784要素の1次元ベクトルとしてXに格納されていますが、画像として表示するときは28x28の二次元にreshapeします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-BzfHL2guon1"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label:  2\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label:  1\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label:  8\n"
     ]
    }
   ],
   "source": [
    "# テストデータをランダムサンプリング\n",
    "perm = np.random.permutation(len(X_test))\n",
    "# サンプル画像を表示する\n",
    "plt.gray()\n",
    "for i in perm[:3]:\n",
    "    plt.imshow(X_test[perm[i]].reshape(28, 28))\n",
    "    plt.show()\n",
    "    print('Label: ', np.argmax(T_test[perm[i]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7TXsI9Aruon3"
   },
   "source": [
    "### softmax関数\n",
    "<font color=\"Red\">問2-1, 2-2 softmax関数を完成させてください。</font>\n",
    "\n",
    "```\n",
    "引数:\n",
    "    x: [N, M] (np.float)\n",
    "       Nはバッチサイズにあたる\n",
    "返値:\n",
    "    [N, M] (np.float)\n",
    "```\n",
    "\n",
    "バッチ計算が可能なsoftmax関数を実装します。<br>\n",
    "exp関数がオーバーフローすることを防ぐために、各データについて入力信号の最大値を引いて、0以下にします。<br>\n",
    "    numpyでは```[N, M] - [N]```の計算はブロードキャストができませんので、```x```を転置し```[M, N] - [N]```の形で計算を行ったあと、さらに転置をして元の形に戻します。\n",
    "$$\n",
    "softmax(x_{ij}) = \\frac{e^{x_{ij}'}}{\\sum_{k}^{M}{e^{x_{ik}'}}} \\\\ \n",
    "    x_{ij}' = x_{ij} - max_{j}x_{ij}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dmUxqrtXuon4"
   },
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    x = x.T\n",
    "    _x = x-np.max(x)\n",
    "    _x = np.exp(_x)/np.sum(np.exp(_x)) \n",
    "    return _x.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ckvG-P7Muon8"
   },
   "source": [
    "### 交差エントロピー誤差\n",
    "<font color=\"Red\">問2-3 交差エントロピー誤差を完成させてください。</font>\n",
    "```\n",
    "引数:\n",
    "    t: [N, M] (np.float)\n",
    "    y: [N, M] (np.float)\n",
    "返値:\n",
    "    error: (np.float)\n",
    "```\n",
    "バッチ計算が可能な交差エントロピー誤差関数を実装します。<br>\n",
    "```y == 0```のときlog関数が破綻しないよう、$ y $ に小さな値 $ \\delta = 10^{-8}$ を加算します。\n",
    "error は 以下の式に従います。\n",
    "$$ error = -\\frac {1}{N} \\sum_{i}^{N} \\sum_{j}^{M} {t_{ij} * log{(y_{ij} + \\delta)}} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K-zLEGCJuon8"
   },
   "outputs": [],
   "source": [
    "def cross_entropy_error(t, y):\n",
    "    delta = 1e-8\n",
    "    error = -np.mean(t*np.log(y+delta))\n",
    "    return error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jQ-MMtfhuon_"
   },
   "source": [
    "### ソフトマックスクロスエントロピー誤差\n",
    "<font color=\"Red\">問2-4 ソフトマックスクロスエントロピー誤差を完成させてください。</font>\n",
    "\n",
    "ソフトマックスクロスエントロピー誤差の順伝播と逆伝播のクラスを実装します。<br>\n",
    "順伝播```__call__(self, t, y)```ではyのソフトマックスを取り、tとのクロスエントロピー誤差を返します。その際にyとtをインスタンス変数self.yとself.tに記憶します。関数名を```__call__```としているのは、**関数オブジェクト**を作ることで\"インスタンス名()\"で順伝播を呼び出せるようにするためです。<br>\n",
    "逆伝播```backward(self)```では、順伝播で記憶されたself.yとself.tを使用して誤差に対する(softmaxを通す前の)yの勾配dyを計算します。<br>\n",
    "yの勾配は以下の式に従います。<br>\n",
    "※コードの```dy```と式の$ dy $は意味が異なり、```dy``` = $ \\frac {dL(t, y)}{dy} $であることに注意してください。\n",
    "$$ \\frac {dL(t, y)}{dy} = softmax(y) - t $$\n",
    "また、以降の計算ではバッチの平均を取るため、dyはバッチサイズで割ってから返します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tQ2HOaMjuooA"
   },
   "outputs": [],
   "source": [
    "class SoftmaxCrossEntropyLoss():\n",
    "    def __init__(self):\n",
    "        self.y = None\n",
    "        self.t = None\n",
    "        self.loss = None\n",
    "        \n",
    "    def __call__(self, t, y):\n",
    "        self.y = softmax(y)\n",
    "        self.t = t.copy()\n",
    "        self.loss = cross_entropy_error(self.t, self.y)\n",
    "        return self.loss\n",
    "    \n",
    "    def backward(self):\n",
    "        batch_size = self.t.shape[0]\n",
    "        dy = self.y-self.t\n",
    "        dy /= batch_size\n",
    "        return dy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RUqBmGWkuooG"
   },
   "source": [
    "### 全結合層\n",
    "<font color=\"Red\">問2-5 ~ 2-8 全結合層クラスを完成させてください。</font>\n",
    "\n",
    "全結合層の順伝播と逆伝播のクラスを実装します。\n",
    "```\n",
    "インスタンス変数:\n",
    "    self.w: [N, M] (np.float)\n",
    "            層の重み。正規分布で初期化。\n",
    "    self.b: [M] (np.float)\n",
    "            層のバイアス。ゼロで初期化。\n",
    "    self.x: [L, N] (np.float)\n",
    "            層の入力信号を記録。Lはバッチサイズ\n",
    "    self.dw: [N, M] (np.float)\n",
    "            層の重みの勾配\n",
    "    self.db: [M] (np.float)\n",
    "            層のバイアスの勾配\n",
    "            \n",
    "__call__(self, x):\n",
    "    引数:\n",
    "        x: [L, N] (np.float)\n",
    "            入力信号\n",
    "    返値:\n",
    "        out: [L, M] (np.float)\n",
    "            出力信号\n",
    "\n",
    "backward(self, dout):\n",
    "    引数:\n",
    "        dout: [L, M] (np.float)\n",
    "            出力信号の勾配\n",
    "    返値:\n",
    "        dx: [L, N] (np.float)\n",
    "            入力信号の勾配\n",
    "        \n",
    "```\n",
    "順伝播```__call__(self, x)```は入力信号xを層の重み```self.w```とバイアス```self.b```でアフィン変換し出力とします。\n",
    "計算は以下の式に従います。\n",
    "$$\n",
    "Affine(x) = x \\cdot w + b\n",
    "$$\n",
    "逆伝播```backward(self, dout)```は出力側の勾配[L, M]を入力側に逆伝播ます。入力の勾配```dx```、重みの勾配```dw```、バイアスの勾配```db```それぞれを計算し、```dx```を返します。\n",
    "計算は以下の式に従います。\n",
    "$$\n",
    "grad(x_{ij}) = \\sum_{k} grad(out_{ik}) \\frac{dout_{ik}}{dx_{ij}}\n",
    "$$\n",
    "$$\n",
    "grad(x_{ij}) = \\sum_{k} grad(out_{ik})w_{jk}\n",
    "$$\n",
    "$$\n",
    "grad(x) = grad(out) \\cdot w^T \\\\ \\space\n",
    "$$\n",
    "$$\n",
    "grad(w_{jk}) = \\sum_{i} grad(out_{ik}) \\frac{dout_{ik}}{dw_{jk}}\n",
    "$$\n",
    "$$\n",
    "grad(w_{jk}) = \\sum_{i} grad(out_{ik})x_{ij}\n",
    "$$\n",
    "$$\n",
    "grad(w) = x^T \\cdot grad(out) \\\\ \\space\n",
    "$$\n",
    "$$\n",
    "grad(b_{k}) = \\sum_{i} grad(out_{ik}) \\frac{dout_{ik}}{db_{k}}\n",
    "$$\n",
    "$$\n",
    "grad(b) = \\sum_{i} grad(out_{i})\n",
    "$$\n",
    "    \n",
    "実装コードでは$ grad(x) $ = ```dx```, $ grad(w) $ = ```dw```, $ grad(b) $ = ```db```と命名されています。 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hWc9zHaLuooG"
   },
   "outputs": [],
   "source": [
    "class FullyConnectedLayer():\n",
    "    def __init__(self, input_shape, output_shape):\n",
    "        self.w = np.random.randn(input_shape, output_shape) * 0.01\n",
    "        self.b = np.zeros(output_shape, dtype=np.float)\n",
    "        self.x = None\n",
    "        self.dw = None\n",
    "        self.db = None\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        self.x = x\n",
    "        out = np.dot(self.x,self.w) +self.b\n",
    "        return out\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        dx = np.dot(dout,np.transpose(self.w))\n",
    "        batch_size = dx.shape[0]\n",
    "        self.dw = np.dot(np.transpose(self.x),dout)\n",
    "        self.db = np.sum(dout,axis=0)\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wW6rnJLnuooK"
   },
   "source": [
    "### ReLU\n",
    "<font color=\"Red\">問2-9 ~ 2-10 ReLUクラスを完成させてください。</font>\n",
    "```\n",
    "インスタンス変数:\n",
    "    self.mask: [L, N] np.bool\n",
    "               マスクされるxのフラッグ\n",
    "               \n",
    "__call__(self, x):\n",
    "    引数:\n",
    "        x: [L, N] np.float\n",
    "    返値:\n",
    "        out: [L, N] np.float\n",
    "\n",
    "backward(self, dout):\n",
    "    引数:\n",
    "        dout: [L, N] np.float\n",
    "    返値:\n",
    "        dx: [L, N] np.float\n",
    "    \n",
    "```\n",
    "ReLUの順伝播と逆伝播をクラスで実装します。\n",
    "順伝播```__call__(self, x)```は入力信号xに対して、```x <= 0```部分が1、それ以外は0となるようなマトリックスself.maskを定義します。numpy配列の**ブールインデックス参照**を利用し、xのマスク部を0に変換し返します。\n",
    "逆伝播```backward(self, dout)```は出力信号の勾配doutの保存されたマスク部を0に変換し、dxとして入力信号の勾配を返します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TOyb4TJluooK"
   },
   "outputs": [],
   "source": [
    "class ReLU():\n",
    "    def __init__(self):\n",
    "        self.mask = None\n",
    "\n",
    "    def __call__(self, x):\n",
    "        self.mask = (x <= 0)\n",
    "        out = x.copy()\n",
    "        out[self.mask]=0\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        dout[self.mask]=0\n",
    "        dx = dout\n",
    "\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_xiLi0RZuooM"
   },
   "source": [
    "問題は以上になります。以下のモデルの構築と学習で実装が正しいことを確認しましょう。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gEKOU_q_uooN"
   },
   "source": [
    "### モデルの構築\n",
    "\n",
    "これまで各種の層をクラスで定義できましたので、ここではそれらを組み合わせることでモデルを簡単に設計することができます。問題にはなっていませんが、コードからモデルの構築の全体像を把握しましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mPA7c6d4uooN"
   },
   "outputs": [],
   "source": [
    "# 分類モデル\n",
    "class MLP_classifier():\n",
    "\n",
    "    def __init__(self):\n",
    "        '''\n",
    "        構造\n",
    "        x -> fc(783, 256) -> relu -> fc(256, 256) -> relu -> fc(256, 10) -> out\n",
    "        '''\n",
    "        \n",
    "        # 層の定義\n",
    "        self.fc1 = FullyConnectedLayer(784, 256)\n",
    "        self.relu1 = ReLU()\n",
    "        self.fc2 = FullyConnectedLayer(256, 256)\n",
    "        self.relu2 = ReLU()\n",
    "        self.fc3 = FullyConnectedLayer(256, 10)\n",
    "        self.out = None\n",
    "        \n",
    "        # 損失関数の定義\n",
    "        self.criterion = SoftmaxCrossEntropyLoss()\n",
    "\n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        順伝播\n",
    "        '''\n",
    "        \n",
    "        x = self.relu1(self.fc1(x))\n",
    "        x = self.relu2(self.fc2(x))\n",
    "        self.out = self.fc3(x)\n",
    "        \n",
    "        # backwardとの一貫性のためsoftmaxはこの順伝播関数内では行わない\n",
    "        # 予測するときはさらにsoftmaxを通す必要がある\n",
    "        return self.out\n",
    "\n",
    "    def backward(self, t):\n",
    "        '''\n",
    "        逆伝播\n",
    "        '''\n",
    "        \n",
    "        # 誤差を計算\n",
    "        loss = self.criterion(t, self.out)\n",
    "        # 勾配を逆伝播\n",
    "        d = self.criterion.backward()\n",
    "        d = self.fc3.backward(d)\n",
    "        d = self.relu2.backward(d)\n",
    "        d = self.fc2.backward(d)\n",
    "        d = self.relu1.backward(d)\n",
    "        d = self.fc1.backward(d)\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    def optimize_GradientDecent(self, lr):\n",
    "        '''\n",
    "        勾配降下法による全層のパラメータの更新\n",
    "        '''\n",
    "        for fc in [self.fc1, self.fc2, self.fc3]:\n",
    "            fc.w -= lr * fc.dw\n",
    "            fc.b -= lr * fc.db\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QnOW6bSQuooQ"
   },
   "source": [
    "### 学習\n",
    "\n",
    "20epochで分類精度が80%以上になっていれば学習は成功していると言えます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lB1l4MPHuooR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1 | TRAIN LOSS 1.32928 | TEST LOSS 1.18370 | ACCURACY 14.92%\n",
      "EPOCH 2 | TRAIN LOSS 1.32212 | TEST LOSS 1.19266 | ACCURACY 16.12%\n",
      "EPOCH 3 | TRAIN LOSS 1.33107 | TEST LOSS 1.32678 | ACCURACY 15.78%\n",
      "EPOCH 4 | TRAIN LOSS 1.46548 | TEST LOSS 1.80080 | ACCURACY 16.20%\n",
      "EPOCH 5 | TRAIN LOSS 1.82994 | TEST LOSS 1.84136 | ACCURACY 13.94%\n",
      "EPOCH 6 | TRAIN LOSS 1.84197 | TEST LOSS 1.84200 | ACCURACY 9.91%\n",
      "EPOCH 7 | TRAIN LOSS 1.84204 | TEST LOSS 1.84207 | ACCURACY 9.91%\n",
      "EPOCH 8 | TRAIN LOSS 1.84204 | TEST LOSS 1.84207 | ACCURACY 9.91%\n",
      "EPOCH 9 | TRAIN LOSS 1.84204 | TEST LOSS 1.84194 | ACCURACY 9.77%\n",
      "EPOCH 10 | TRAIN LOSS 1.84207 | TEST LOSS 1.84194 | ACCURACY 9.77%\n",
      "EPOCH 11 | TRAIN LOSS 1.84207 | TEST LOSS 1.84194 | ACCURACY 9.77%\n",
      "EPOCH 12 | TRAIN LOSS 1.84207 | TEST LOSS 1.84194 | ACCURACY 9.77%\n",
      "EPOCH 13 | TRAIN LOSS 1.84207 | TEST LOSS 1.84194 | ACCURACY 9.77%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yamada/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: RuntimeWarning: invalid value encountered in subtract\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 14 | TRAIN LOSS 1.84207 | TEST LOSS nan | ACCURACY 9.91%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yamada/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:6: RuntimeWarning: invalid value encountered in less_equal\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 15 | TRAIN LOSS nan | TEST LOSS nan | ACCURACY 9.91%\n",
      "EPOCH 16 | TRAIN LOSS nan | TEST LOSS nan | ACCURACY 9.91%\n",
      "EPOCH 17 | TRAIN LOSS nan | TEST LOSS nan | ACCURACY 9.91%\n",
      "EPOCH 18 | TRAIN LOSS nan | TEST LOSS nan | ACCURACY 9.91%\n",
      "EPOCH 19 | TRAIN LOSS nan | TEST LOSS nan | ACCURACY 9.91%\n",
      "EPOCH 20 | TRAIN LOSS nan | TEST LOSS nan | ACCURACY 9.91%\n"
     ]
    }
   ],
   "source": [
    "# モデルの宣言\n",
    "model = MLP_classifier()\n",
    "\n",
    "# 学習率\n",
    "lr = 0.005\n",
    "# 学習エポック数\n",
    "n_epoch = 20\n",
    "\n",
    "# n_epoch繰り返す\n",
    "for n in range(n_epoch):\n",
    "    # 訓練\n",
    "    # Day1範囲外のため、ミニバッチは使用しない\n",
    "    y = model.forward(X_train)\n",
    "    loss = model.backward(T_train)\n",
    "    model.optimize_GradientDecent(lr)\n",
    "    \n",
    "    # テスト\n",
    "    y = model.forward(X_test)\n",
    "    test_loss = model.backward(T_test)\n",
    "    pred = softmax(y)\n",
    "    accuracy = np.mean(np.equal(np.argmax(y, axis=1), np.argmax(T_test, axis=1)))\n",
    "    print(f'EPOCH {n + 1} | TRAIN LOSS {loss:.5f} | TEST LOSS {test_loss:.5f} | ACCURACY {accuracy:.2%}')\n",
    "classification_accuracy = accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CFcUU_10uooT"
   },
   "source": [
    "### 提出可否"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J3Zue9pAuooT"
   },
   "outputs": [],
   "source": [
    "print(\"大問1 回帰ロス: \", regression_loss)\n",
    "print(\"大問2 分類精度: \", classification_accuracy)\n",
    "pass0 = regression_loss < 0.5\n",
    "pass1 = classification_accuracy > 0.8\n",
    "if pass0 and pass1:\n",
    "    print(\"回帰モデルと分類モデルどちらも学習が成功しているので、提出可能です。\")\n",
    "else:\n",
    "    if not pass0:\n",
    "        print(\"回帰モデル（大問１）の学習が成功していません。\")\n",
    "    if not pass1:\n",
    "        print(\"分類モデル（大問２）の学習が成功していません。\")\n",
    "    print(\"回答を訂正してください。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ASs5wnq9uooV"
   },
   "source": [
    "### 補足\n",
    "\n",
    "今演習では簡単のため、ミニバッチ学習・重み減衰などの正則化・より高度な最適化・データのオーグメンテーション(拡張)など、Day2, Day3で学習する重要な手法を使用していません。これらを使用すれば、全結合層でもmnist手書き数字の分類精度を大きく上げることが可能です。例えばミニバッチを簡単に導入するだけで、20epochで97%以上の精度に達します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VsR1yu8tV9vl"
   },
   "source": [
    "### 発展\n",
    "\n",
    "大問１，大問２それぞれについて学習率・エポック数を変えてみて学習における挙動を観察してみましょう。また、多層パーセプトロンの総数やノード数を変更し、より良い精度を出せる条件を探してみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZOSo6nTIuooW"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Day1演習.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
