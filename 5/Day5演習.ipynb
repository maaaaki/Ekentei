{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LEQEe0luCvEj"
   },
   "source": [
    "# 全人類がわかるディープラーニング Day5演習\n",
    "\n",
    "## 概要\n",
    "\n",
    "本演習では自然言語処理に代表される系列データを扱うためのネットワークであるRNNやその派生ネットワークによる学習を穴埋め形式で実装します。なお、予め用意されたコードはそのまま使用し、指示された穴埋め部を編集してください。\n",
    "演習問題文は<font color=\"Red\">赤字</font>です。このファイルは必ず最後までコードをすべて実行し、「最後までコードが実行可能」・「学習結果の出力がある」・「学習が成功している」の３つを満たした状態で提出してください。\n",
    "\n",
    "所要時間：3~8時間"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Sm7ZvF2SCvEk"
   },
   "source": [
    "### ライブラリのインポート\n",
    "\n",
    "必要なライブラリをインポートします。エラーになる場合は該当するものをインストールしてください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c-thDJ_VCvEl"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# 乱数シードを指定\n",
    "np.random.seed(seed=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "h2zc3aStCvEn"
   },
   "source": [
    "## 基本的関数、アルゴリズムの実装\n",
    "\n",
    "- SGD\n",
    "- Adam\n",
    "- sigmoid\n",
    "- softmax\n",
    "- clip_grads\n",
    "    勾配クリッピング用の関数。実装自体は単純なので省略。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_dM-1Xrc-Aye"
   },
   "outputs": [],
   "source": [
    "class Affine:\n",
    "    def __init__(self, W, b):\n",
    "        self.params = [W, b]\n",
    "        self.grads = [np.zeros_like(W), np.zeros_like(b)]\n",
    "        self.x = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        N, D = x.shape\n",
    "        W, b = self.params\n",
    "\n",
    "        out = np.dot(x, W) + b\n",
    "        self.x = x\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        x = self.x\n",
    "        N, D = x.shape\n",
    "        W, b = self.params\n",
    "\n",
    "        db = np.sum(dout, axis=0)\n",
    "        dW = np.dot(x.T, dout)\n",
    "        dx = np.dot(dout, W.T)\n",
    "\n",
    "        self.grads[0][...] = dW\n",
    "        self.grads[1][...] = db\n",
    "\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RCuXbNbACvEo"
   },
   "outputs": [],
   "source": [
    "class SGD:\n",
    "    def __init__(self, lr=0.01):\n",
    "        self.lr = lr\n",
    "        \n",
    "    def update(self, params, grads):\n",
    "        for i in range(len(params)):\n",
    "            params[i] -= self.lr * grads[i]\n",
    "            \n",
    "class Adam:\n",
    "    def __init__(self, lr=0.001, beta1=0.9, beta2=0.999):\n",
    "        self.lr = lr\n",
    "        self.beta1 = beta1\n",
    "        self.beta2 = beta2\n",
    "        self.iter = 0\n",
    "        self.m = None\n",
    "        self.v = None\n",
    "        \n",
    "    def update(self, params, grads):\n",
    "        if self.m is None:\n",
    "            self.m, self.v = [], []\n",
    "            for param in params:\n",
    "                self.m.append(np.zeros_like(param))\n",
    "                self.v.append(np.zeros_like(param))\n",
    "        \n",
    "        self.iter += 1\n",
    "        lr_t = self.lr * np.sqrt(1.0 - self.beta2**self.iter) / (1.0 - self.beta1**self.iter)\n",
    "\n",
    "        for i in range(len(params)):\n",
    "            self.m[i] += (1 - self.beta1) * (grads[i] - self.m[i])\n",
    "            self.v[i] += (1 - self.beta2) * (grads[i]**2 - self.v[i])\n",
    "            \n",
    "            params[i] -= lr_t * self.m[i] / (np.sqrt(self.v[i]) + 1e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v-iaf2EbCvEp"
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def softmax(x):\n",
    "    if x.ndim == 2:\n",
    "        x = x - x.max(axis=1, keepdims=True)\n",
    "        x = np.exp(x)\n",
    "        x /= x.sum(axis=1, keepdims=True)\n",
    "    elif x.ndim == 1:\n",
    "        x = x - np.max(x)\n",
    "        x = np.exp(x) / np.sum(np.exp(x))\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OQF7Uc98CvFM"
   },
   "outputs": [],
   "source": [
    "def clip_grads(grads, max_norm):\n",
    "    total_norm = 0\n",
    "    for grad in grads:\n",
    "        total_norm += np.sum(grad ** 2)\n",
    "    total_norm = np.sqrt(total_norm)\n",
    "\n",
    "    rate = max_norm / (total_norm + 1e-6)\n",
    "    if rate < 1:\n",
    "        for grad in grads:\n",
    "            grad *= rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "icm4E44X-Ayo"
   },
   "source": [
    "## 自然言語処理用のレイヤークラス定義\n",
    "### Embedding クラス\n",
    "- 自然言語処理において、単語をベクトル（分散表現）に変換する前処理(Embeddingと言われる)が必須となる。\n",
    "- Embeddingクラスは入力されてきた単語列をべクトルに変換する。\n",
    "- 単語はID化されているため、一つのデータ（文章）は`[3,0,4,1]`のようになっている。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sg0VFsMT-Ayp"
   },
   "source": [
    "例えば\n",
    "\n",
    "単語 0 を `[0.5, 1.2]`\n",
    "\n",
    "単語 1 を`[-1.4, 0.7]`\n",
    "\n",
    "単語 2 を` [2.5, -0.9]`\n",
    "\n",
    "単語 3 を`[5.6, 9.8]`\n",
    "\n",
    "単語 4 を`[-2.3, -0.8]`\n",
    "\n",
    "に変換するようなEmbed 層を用意する場合、\n",
    "\n",
    "$\n",
    "\\begin{pmatrix}\n",
    "0.5 & 1.2 \\\\\n",
    "-1.4 & 0.7 \\\\\n",
    "2.5 & -0.9 \\\\\n",
    "5.6 & 9.8 \\\\\n",
    "-2.3 & -0.8 \\\\\n",
    "\\end{pmatrix}\n",
    "$\n",
    "\n",
    "のような変換行列を用意し、入力の単語IDをindexとして各単語を変換してやれば良い。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zemct8OW-Ayq"
   },
   "outputs": [],
   "source": [
    "class Embedding:\n",
    "    def __init__(self, W):\n",
    "        self.params = [W]\n",
    "        self.grads = [np.zeros_like(W)]\n",
    "        self.idx = None\n",
    "\n",
    "    def forward(self, idx):\n",
    "        W, = self.params\n",
    "        self.idx = idx\n",
    "        out = W[idx]\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        dW, = self.grads\n",
    "        dW[...] = 0\n",
    "        np.add.at(dW, self.idx, dout)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XBqVDDVq-Ayt"
   },
   "source": [
    "逆伝播については、変換行列に対して、入力時の単語に相当する箇所に伝播してきた勾配を足し合わせてやれば良いため、`np.add.at` を使用すれば良い。\n",
    "\n",
    "`np.add.at(dW, self.idx, dout)` によって、`dW[self.idx]`に対して`dout`が加えられる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LdNoWAOa-Ayu",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.6,  9.8],\n",
       "       [ 0.5,  1.2],\n",
       "       [-2.3, -0.8],\n",
       "       [-1.4,  0.7]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = np.array([[0.5, 1.2],\n",
    "              [-1.4, 0.7],\n",
    "              [2.5, -0.9],\n",
    "              [5.6, 9.8],\n",
    "              [-2.3, -0.8]])\n",
    "embedder_example = Embedding(w)\n",
    "minibatch_example = np.array([3,0,4,1])\n",
    "embedder_example.forward(minibatch_example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1SI5FXlf-Ayw"
   },
   "source": [
    "## Time層の実装\n",
    "RNNで系列データを扱う際、例えば時刻tでの入力データ$x_t$を順伝播させたのちに隠れ層の値$h_t$を得、次の時刻t+1での入力データ$x_{t+1}$を順伝播させ……というように、データを時刻ごとに分割してからRNN層やAffine層、Embedding層に入力するという形式を取らなくてはならず、系列データを一々分割し、各時刻データに対して順伝播をさせるというように手間がかかってしまう。\n",
    "\n",
    "そのため、全時刻に渡って一度に順伝播などの処理を行ってくれるように、ユニットを時刻方向に繋げ一つのユニットとすることを考える。\n",
    "ここではこのように時系列データをまとめて扱う層のことを`TimeEmbedding`や`TimeAffine`のように、各クラス名に`Time`を付けて表すことにする。\n",
    "\n",
    "<img src= time_layer_image.png>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "q_FnjBns-Ayx"
   },
   "source": [
    "### TimeEmbedding クラス\n",
    "\n",
    "TimeEmbedding クラスの入力として想定する形式は、\n",
    "\n",
    "（バッチサイズ）×（単語数=時刻数）\n",
    "\n",
    "であり、各単語をD次元ベクトルに変換するとすれば出力は\n",
    "\n",
    "（バッチサイズ）×（単語数=時刻数）×（次元数D）\n",
    "\n",
    "となる。\n",
    "\n",
    "系列に発展させた形としては、順伝播/逆伝播ともに時刻数tをfor文で順に処理してやれば良い。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MO8XOzIWCvEr"
   },
   "outputs": [],
   "source": [
    "class TimeEmbedding:\n",
    "    def __init__(self, W):\n",
    "        self.params = [W]\n",
    "        self.grads = [np.zeros_like(W)]\n",
    "        self.layers = None\n",
    "        self.W = W\n",
    "\n",
    "    def forward(self, xs):\n",
    "        N, T = xs.shape\n",
    "        V, D = self.W.shape\n",
    "\n",
    "        out = np.empty((N, T, D), dtype='f')\n",
    "        self.layers = []\n",
    "\n",
    "        for t in range(T):\n",
    "            layer = Embedding(self.W)\n",
    "            out[:, t, :] = layer.forward(xs[:, t])\n",
    "            self.layers.append(layer)\n",
    "\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        N, T, D = dout.shape\n",
    "\n",
    "        grad = 0\n",
    "        for t in range(T):\n",
    "            layer = self.layers[t]\n",
    "            layer.backward(dout[:, t, :])\n",
    "            grad += layer.grads[0]\n",
    "\n",
    "        self.grads[0][...] = grad\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0YWRoPBX-Ay1"
   },
   "source": [
    "### TimeAffine クラス\n",
    "TimeAffineクラスの入力として想定する形式は、\n",
    "\n",
    "（バッチサイズ）×（単語数=時刻数）×（単語ベクトル次元数）\n",
    "\n",
    "であり、このAffineクラスによって単語ベクトル次元数$D_1$から$D_2$に変換すると考えれば、サイズ$D_1 \\times D_2$ の重み行列を用意し、\n",
    "\n",
    "（バッチサイズ）×（単語数=時刻数）×（$D_2$）\n",
    "\n",
    "が出力となる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H8oo7Gr_CvEu"
   },
   "outputs": [],
   "source": [
    "class TimeAffine:\n",
    "    def __init__(self, W, b):\n",
    "        self.params = [W, b]\n",
    "        self.grads = [np.zeros_like(W), np.zeros_like(b)]\n",
    "        self.x = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        N, T, D = x.shape\n",
    "        W, b = self.params\n",
    "\n",
    "        rx = x.reshape(N*T, -1)\n",
    "        out = np.dot(rx, W) + b\n",
    "        self.x = x\n",
    "        return out.reshape(N, T, -1)\n",
    "\n",
    "    def backward(self, dout):\n",
    "        x = self.x\n",
    "        N, T, D = x.shape\n",
    "        W, b = self.params\n",
    "\n",
    "        dout = dout.reshape(N*T, -1)\n",
    "        rx = x.reshape(N*T, -1)\n",
    "\n",
    "        db = np.sum(dout, axis=0)\n",
    "        dW = np.dot(rx.T, dout)\n",
    "        dx = np.dot(dout, W.T)\n",
    "        dx = dx.reshape(*x.shape)\n",
    "\n",
    "        self.grads[0][...] = dW\n",
    "        self.grads[1][...] = db\n",
    "\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hvSTZU-1-Ay5"
   },
   "source": [
    "### TimeSoftmaxWithLoss クラス\n",
    "TimeSoftmaxWithLoss クラスの入力として想定する形式は、\n",
    "\n",
    "（バッチサイズ）×（単語数=時刻数）×（次元数）\n",
    "\n",
    "であり、この次元数についてsoftmax関数により変換を行うものと考える。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l3Sr6xoPCvEs"
   },
   "outputs": [],
   "source": [
    "class TimeSoftmaxWithLoss:\n",
    "    def __init__(self):\n",
    "        self.params, self.grads = [], []\n",
    "        self.cache = None\n",
    "\n",
    "    def forward(self, xs, ts):\n",
    "        N, T, V = xs.shape\n",
    "\n",
    "        if ts.ndim == 3:  # 教師ラベルがone-hotベクトルの場合\n",
    "            ts = ts.argmax(axis=2)\n",
    "\n",
    "        # バッチ分と時系列分をまとめる（reshape）\n",
    "        xs = xs.reshape(N * T, V)\n",
    "        ts = ts.reshape(N * T)\n",
    "\n",
    "        ys = softmax(xs)\n",
    "        ls = np.log(ys[np.arange(N * T), ts])\n",
    "        loss = -np.sum(ls)\n",
    "        loss /= len(ts)\n",
    "\n",
    "        self.cache = (ts, ys, (N, T, V))\n",
    "        return loss\n",
    "\n",
    "    def backward(self, dout=1):\n",
    "        ts, ys, (N, T, V) = self.cache\n",
    "\n",
    "        dx = ys\n",
    "        dx[np.arange(N * T), ts] -= 1\n",
    "        dx *= dout\n",
    "        dx /= len(ys)\n",
    "\n",
    "        dx = dx.reshape((N, T, V))\n",
    "\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EIYsJAPZCvEy"
   },
   "source": [
    "## データセット用意\n",
    "\n",
    "ptbという英語の文章を集めたデータセットを用意します。\n",
    "\n",
    "このデータセットについて、単語を順に入力していき、次の単語を予測するというタスクを解かせてみます。\n",
    "本来であれば訓練データで学習をさせた後テストデータで検証を行いますが、簡単のため今回は学習のみを行い、テストによる検証は行いません。\n",
    "\n",
    "こちらのデータセットを用いて解いていくタスクは実践的なタスクと言うよりは、RNNの実装がうまくいっており、学習が成功することを確認するためのものとなります。\n",
    "\n",
    "データセットの用意の部分ですので、コードは読み飛ばしていただいても構いません。\n",
    "\n",
    "行っている処理の流れを示すと、\n",
    "1. データのダウンロード\n",
    "1. 単語とIDの変換ディクショナリの作成\n",
    "1. ダウンロードしてきた単語列のデータに対し、全単語をIDに変換\n",
    "\n",
    "と言う流れになります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e8psB7A9CvEz"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import urllib.request\n",
    "import pickle\n",
    "\n",
    "url_base = 'https://raw.githubusercontent.com/tomsercu/lstm/master/data/'\n",
    "key_file = {\n",
    "    'train':'ptb.train.txt'\n",
    "}\n",
    "save_file = {\n",
    "    'train':'ptb.train.npy'\n",
    "}\n",
    "vocab_file = 'ptb.vocab.pkl'\n",
    "\n",
    "def _download(file_name):\n",
    "    file_path = './' + file_name\n",
    "    if os.path.exists(file_path):\n",
    "        return\n",
    "\n",
    "    print('Downloading ' + file_name + ' ... ')\n",
    "\n",
    "    try:\n",
    "        urllib.request.urlretrieve(url_base + file_name, file_path)\n",
    "    except urllib.error.URLError:\n",
    "        import ssl\n",
    "        ssl._create_default_https_context = ssl._create_unverified_context\n",
    "        urllib.request.urlretrieve(url_base + file_name, file_path)\n",
    "\n",
    "    print('Done')\n",
    "\n",
    "def load_vocab():\n",
    "    vocab_path = './' + vocab_file\n",
    "\n",
    "    if os.path.exists(vocab_path):\n",
    "        with open(vocab_path, 'rb') as f:\n",
    "            word_to_id, id_to_word = pickle.load(f)\n",
    "        return word_to_id, id_to_word\n",
    "\n",
    "    word_to_id = {}\n",
    "    id_to_word = {}\n",
    "    data_type = 'train'\n",
    "    file_name = key_file[data_type]\n",
    "    file_path = './' + file_name\n",
    "\n",
    "    _download(file_name)\n",
    "\n",
    "    words = open(file_path).read().replace('\\n', '<eos>').strip().split()\n",
    "\n",
    "    for i, word in enumerate(words):\n",
    "        if word not in word_to_id:\n",
    "            tmp_id = len(word_to_id)\n",
    "            word_to_id[word] = tmp_id\n",
    "            id_to_word[tmp_id] = word\n",
    "\n",
    "    with open(vocab_path, 'wb') as f:\n",
    "        pickle.dump((word_to_id, id_to_word), f)\n",
    "\n",
    "    return word_to_id, id_to_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p9nT8sbgCvE1"
   },
   "outputs": [],
   "source": [
    "def load_ptb(data_type='train'):\n",
    "    save_path = './' + save_file[data_type]\n",
    "    word_to_id, id_to_word = load_vocab()\n",
    "\n",
    "    if os.path.exists(save_path):\n",
    "        corpus = np.load(save_path)\n",
    "        return corpus, word_to_id, id_to_word\n",
    "\n",
    "    file_name = key_file[data_type]\n",
    "    file_path = './' + file_name\n",
    "    _download(file_name)\n",
    "\n",
    "    words = open(file_path).read().replace('\\n', '<eos>').strip().split()\n",
    "    corpus = np.array([word_to_id[w] for w in words])\n",
    "\n",
    "    np.save(save_path, corpus)\n",
    "    return corpus, word_to_id, id_to_word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rbYK-qb0-AzF"
   },
   "source": [
    "読み込んだデータを学習用に分割します。\n",
    "そのままではデータ数が大きすぎるので、前から1000単語のみを使用します。\n",
    "\n",
    "xsには0番目から998番目までの単語IDが、tsには1番目から999番目までの単語IDが格納されています。解くべきタスクとしては、xsのi番目までの単語IDを入力として、i+1番目の単語、即ちtsのi番目の単語を予測するというものになります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mM4f-cue-AzG"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus size: 1000, vocabulary size: 418\n"
     ]
    }
   ],
   "source": [
    "# 学習データの読み込み（データセットを小さくする）\n",
    "corpus, word_to_id, id_to_word = load_ptb('train')\n",
    "corpus_size = 1000\n",
    "corpus = corpus[:corpus_size]\n",
    "vocab_size = int(max(corpus) + 1)\n",
    "\n",
    "xs = corpus[:-1]  # 入力\n",
    "ts = corpus[1:]  # 出力（教師ラベル）\n",
    "data_size = len(xs)\n",
    "print('corpus size: %d, vocabulary size: %d' % (corpus_size, vocab_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ii6uCudrCvE4"
   },
   "source": [
    "## ネットワーク定義\n",
    "### RNNクラス\n",
    "問1-1. <font color=\"Red\">RNNレイヤーを表すクラス RNNクラスを完成させてください。</font>\n",
    "\n",
    "  RNNクラスは以下に従って定義します。\n",
    "    \n",
    "  - `Wx`, `Wh`はそれぞれ順伝播時に入力、前時刻隠れ層にかかる重み行列\n",
    "  - 活性化関数は `tanh`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UKhQecjFCvE4"
   },
   "outputs": [],
   "source": [
    "class RNN:\n",
    "    def __init__(self, Wx, Wh, b):\n",
    "        self.params = [Wx, Wh, b]\n",
    "        self.grads = [np.zeros_like(Wx), np.zeros_like(Wh), np.zeros_like(b)]\n",
    "        self.cache = None\n",
    "\n",
    "    def forward(self, x, h_prev):\n",
    "        Wx, Wh, b = self.params \n",
    "        t = np.dot(x,Wx) + np.dot(h_prev,Wh) + b\n",
    "        h_next = np.tanh(t) \n",
    "\n",
    "        self.cache = (x, h_prev, h_next)\n",
    "        return h_next\n",
    "\n",
    "    def backward(self, dh_next):\n",
    "        Wx, Wh, b = self.params\n",
    "        x, h_prev, h_next = self.cache\n",
    "\n",
    "        dt = dh_next*(1- h_next**2)\n",
    "        db = np.sum(dt,axis=0)\n",
    "        dWh = np.dot(h_prev.T,dt)\n",
    "        dh_prev = np.dot(dt, Wh.T)\n",
    "        dWx =  np.dot(x.T,dt)\n",
    "        dx =  np.dot(dt,Wx.T)\n",
    "\n",
    "        self.grads[0][...] = dWx\n",
    "        self.grads[1][...] = dWh\n",
    "        self.grads[2][...] = db\n",
    "\n",
    "        return dx, dh_prev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qV66lPCN-AzM"
   },
   "source": [
    "### TimeRNNクラス\n",
    "問1-2. <font color=\"Red\">TimeRNNクラスを完成させてください。</font>\n",
    "\n",
    "TimeRNNクラスの仕様は以下の通りです。\n",
    "  \n",
    "  1. 順伝播\n",
    "      \n",
    "      - 時刻`t`を時系列分だけfor文でループさせます\n",
    "      - 順伝播により計算した隠れ層をメンバ変数`h`として格納します\n",
    "      - 順伝播時には<font color=\"Red\">メンバ変数`h`と入力データのうち時刻`t`に対応するデータを使用して</font>出力を計算します\n",
    "      \n",
    "  1. 逆伝播\n",
    "      - 今回のタスクにおいては、全時刻において次単語を予測し、その予測について損失が計算される、即ち勾配が入力されてくるため、逆伝播の入力`dhs`の想定される形は（バッチサイズ）×（単語数=時刻数）×（RNNの出力次元数）となります\n",
    "      - 各時刻において、<font color=\"Red\">次の時刻から伝播してきた勾配と現時刻における出力から伝播してきた勾配との和</font>を入力としてRNN層の逆伝播を計算します\n",
    "  \n",
    "また、今回のタスクにおける少々特殊な処理に対応するためや、この後実装する別タスクにおいても汎用的に使用するためにいくつか細かい仕様を加えます。\n",
    "実装上の細かい仕様のため、問題にはしていませんが、参考にしてください。\n",
    "\n",
    "  1. stateful\n",
    "    - 今回のタスクにおける目的はRNNネットワークが正しく実装できていることです。簡単に学習が成功していることを確認するため、（実務的にも用いられることのある）Truncated BPTT という少々特殊な処理を行います。\n",
    "    - 今回のタスクでは、入力する単語数（時刻数）として1000程度を入力していますが、この単語全てを順伝播させて逆伝播を計算し、ようやくパラメータ更新を1度行うというのでは効率が悪いため、順伝播は1000単語で行うものの逆伝播を5単語程度で区切って行う Truncated BPTT という方式を取っています。\n",
    "      1. まず、連続する5単語（例えば1~5番）を入力として順伝播・逆伝播・パラメータ更新を行います。\n",
    "      1. その際、順伝播の最終時刻における隠れ層`h`の値をメンバ変数として保持しておきます。\n",
    "      1. 次に5単語（先の例では6~10番）を入力として順伝播・逆伝播・パラメータ更新を行いますが、その際に初期入力の`h`を0で初期化せず、前から保持しているメンバ変数`h`の値をそのまま使用します。\n",
    "      1. このことにより、逆伝播は5単語単位で行われますが、順伝播は最初の単語から順にずっと計算されてきた値を使用することができます。\n",
    "      1. `stateful`がTrueの際にこのメンバ変数`h`の保持を行います。Falseの場合には`forward`関数が呼ばれるたびに`h`がリセット、即ち0で初期化されます。\n",
    "    \n",
    "  1. set_state\n",
    "    - 内部状態`h`を外から設定するための関数です。\n",
    "  \n",
    "  1. reset_state\n",
    "    - 内部状態`h`を外から削除するための関数です。\n",
    "  \n",
    "  1. params や grads としてパラメータ・勾配をまとめる\n",
    "    - 後でネットワーククラスを定義した際に、パラメータ更新などを楽に実行するための処理です。\n",
    "  1. backward における入力dhsの次元数による場合分け\n",
    "    - 今回のタスクでは全時刻において勾配が逆伝播してくるため、`dhs`の想定される形は（バッチサイズN）×（単語数=時刻数T）×（RNNの出力次元数H）となりますが、この後別のタスクを解く際には、全時刻ではなく最終時刻の出力のみから勾配が伝播してきます。\n",
    "    - この場合、dhsの次元数が違うため三次元に拡張することが必要になります。\n",
    "    - 最終時刻の出力のみから伝播してきたdhs の形は`(N,T,D)`のうち、`(N,D)`となっています。\n",
    "    - 最終時刻以外の勾配については何も伝播してきていないことから、全て0とすることで問題なく計算がなされます。\n",
    "    - 以上のことから、まず`np.zeros((N,T,D))`によって勾配の形を整え、その勾配の`[:,-1,:]`に対して入力された最終時刻における勾配を代入することで変わらず逆伝播を行うことができます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zHobocVhCvE6"
   },
   "outputs": [],
   "source": [
    "class TimeRNN:\n",
    "    def __init__(self,input_size, output_size, stateful=False):\n",
    "        D, H = input_size, output_size\n",
    "        rn = np.random.randn\n",
    "        np.random.seed(0)\n",
    "\n",
    "        # 重みの初期化\n",
    "        Wx = (rn(D, H) / np.sqrt(D)).astype('f')\n",
    "        Wh = (rn(H, H) / np.sqrt(H)).astype('f')\n",
    "        b = np.zeros(H).astype('f')\n",
    "\n",
    "        self.params = [Wx, Wh, b]\n",
    "        self.grads = [np.zeros_like(Wx), np.zeros_like(Wh), np.zeros_like(b)]\n",
    "        self.layers = None\n",
    "\n",
    "        self.h, self.dh = None, None\n",
    "        self.stateful = stateful\n",
    "        self.input_shapes = None\n",
    "\n",
    "    def forward(self, xs):\n",
    "        Wx, Wh, b = self.params\n",
    "        N, T, D = xs.shape\n",
    "        D, H = Wx.shape\n",
    "        self.input_shapes = [N,T,D]\n",
    "\n",
    "        self.layers = []\n",
    "        hs = np.empty((N, T, H), dtype='f')\n",
    "\n",
    "        if not self.stateful or self.h is None:\n",
    "            self.h = np.zeros((N, H), dtype='f')\n",
    "\n",
    "        for t in range(T):\n",
    "            layer = RNN(*self.params)\n",
    "            self.h = layer.forward(xs[:,t,:],self.h) \n",
    "            hs[:, t, :] = self.h\n",
    "            self.layers.append(layer)\n",
    "\n",
    "        return hs\n",
    "\n",
    "    def backward(self, dhs):\n",
    "        Wx, Wh, b = self.params\n",
    "        N, T, D = self.input_shapes\n",
    "        D, H = Wx.shape\n",
    "        \n",
    "        if dhs.ndim == 2:\n",
    "            temp = np.zeros((N,T,H))\n",
    "            temp[:,-1,:] = dhs\n",
    "            dhs = temp\n",
    "        \n",
    "        N, T, H = dhs.shape\n",
    "\n",
    "        dxs = np.empty((N, T, D), dtype='f')\n",
    "        dh = 0\n",
    "        grads = [0, 0, 0]\n",
    "        for t in reversed(range(T)):\n",
    "            layer = self.layers[t]\n",
    "            dx, dh = layer.backward(dhs[:,t,:]+dh) \n",
    "            dxs[:, t, :] = dx\n",
    "\n",
    "            for i, grad in enumerate(layer.grads):\n",
    "                grads[i] += grad\n",
    "\n",
    "        for i, grad in enumerate(grads):\n",
    "            self.grads[i][...] = grad\n",
    "        self.dh = dh\n",
    "\n",
    "        return dxs\n",
    "\n",
    "    def set_state(self, h):\n",
    "        self.h = h\n",
    "\n",
    "    def reset_state(self):\n",
    "        self.h = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nDfIFVaw-AzQ"
   },
   "source": [
    "### SimpleRnnNetwork クラス\n",
    "バッチサイズN、単語数T、単語の種類数V、embedにより単語をベクトル化した際の次元数D、RNNによる出力次元数Hとします。\n",
    "\n",
    "入力されてくるデータのサイズは`(N,T)`であり\n",
    "\n",
    "TimeEmbedding層により`(N,T,D)`に変換\n",
    "\n",
    "TimeRNN層により`(N,T,H)`に変換\n",
    "\n",
    "TimeAffine層により`(N,T,V)`に変換した後、V次元の中で最大のものを予測単語IDとして出力します。\n",
    "損失については、Softmaxを使用してV種類の各単語について確率値を出力し、クロスエントロピーで計算します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XIN7sid8CvE8"
   },
   "outputs": [],
   "source": [
    "class SimpleRnnNetwork:\n",
    "    def __init__(self, vocab_size, wordvec_size, hidden_size):\n",
    "        V, D, H = vocab_size, wordvec_size, hidden_size\n",
    "        rn = np.random.randn\n",
    "        np.random.seed(0)\n",
    "\n",
    "        # 重みの初期化\n",
    "        embed_W = (rn(V, D) / 100).astype('f')\n",
    "        affine_W = (rn(H, V) / np.sqrt(H)).astype('f')\n",
    "        affine_b = np.zeros(V).astype('f')\n",
    "\n",
    "        # レイヤの生成\n",
    "        self.layers = [\n",
    "            TimeEmbedding(embed_W),\n",
    "            TimeRNN(D, H, stateful=True),\n",
    "            TimeAffine(affine_W, affine_b)\n",
    "        ]\n",
    "        self.loss_layer = TimeSoftmaxWithLoss()\n",
    "        self.rnn_layer = self.layers[1]\n",
    "\n",
    "        # すべての重みと勾配をリストにまとめる\n",
    "        self.params, self.grads = [], []\n",
    "        for layer in self.layers:\n",
    "            self.params += layer.params\n",
    "            self.grads += layer.grads\n",
    "\n",
    "    def forward(self, xs, ts):\n",
    "        for layer in self.layers:\n",
    "            xs = layer.forward(xs)\n",
    "        loss = self.loss_layer.forward(xs, ts)\n",
    "        return loss\n",
    "\n",
    "    def backward(self, dout=1):\n",
    "        dout = self.loss_layer.backward(dout)\n",
    "        for layer in reversed(self.layers):\n",
    "            dout = layer.backward(dout)\n",
    "        return dout\n",
    "\n",
    "    def reset_state(self):\n",
    "        self.rnn_layer.reset_state()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ET7tV8h1-AzU"
   },
   "source": [
    "### ハイパーパラメータや学習用データセットの用意\n",
    "\n",
    "バッチサイズ10のミニバッチを作成するため、offsets や time_idx などを使用します。\n",
    "細かい挙動まで追う必要はありませんが、Truncated BPTT を行うため、バッチサイズ10, 単語数5のミニバッチを作成したあと、通常のようにまたランダムに連続した5単語を取るのではなく、先のミニバッチから連続した5単語をミニバッチとして選択する必要があります。\n",
    "\n",
    "例として簡単のために単語数100個、バッチサイズ2とした場合を考えます。\n",
    "\n",
    "1エポック目でのミニバッチ選択を追うと、\n",
    "\n",
    "```\n",
    "0番目の単語-1番目の単語-2番目の単語-3番目の単語-4番目の単語\n",
    "49番目の単語-50番目の単語-51番目の単語-52番目の単語-53番目の単語\n",
    "```\n",
    "    ↓\n",
    "```\n",
    "5番目の単語-6番目の単語-7番目の単語-8番目の単語-9番目の単語\n",
    "54番目の単語-55番目の単語-56番目の単語-57番目の単語-58番目の単語\n",
    "```\n",
    "    ↓\n",
    "    ……\n",
    "    \n",
    "と言うようにミニバッチ内の各データについて連続して単語を選択しています。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_OX0jXUwCvE9"
   },
   "outputs": [],
   "source": [
    "# ハイパーパラメータの設定\n",
    "batch_size = 20 #10\n",
    "wordvec_size = 100\n",
    "hidden_size = 100\n",
    "time_size = 5 \n",
    "lr = 10 #0.1\n",
    "max_epoch = 40\n",
    "max_grad = 0.25\n",
    "\n",
    "max_iters = data_size // (batch_size * time_size)\n",
    "\n",
    "optimizer = SGD(lr)\n",
    "\n",
    "jump = (corpus_size - 1) // batch_size\n",
    "offsets = [i * jump for i in range(batch_size)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_Xt6DtJDCvFB"
   },
   "source": [
    "## 学習、評価\n",
    "perplexity で評価を行います。\n",
    "\n",
    "40エポックでperplexityが一桁程度まで低下していれば学習成功です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7cDXCBHZ-Azb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 1 | perplexity 383.29\n",
      "| epoch 2 | perplexity 404.52\n",
      "| epoch 3 | perplexity 490.90\n",
      "| epoch 4 | perplexity 434.89\n",
      "| epoch 5 | perplexity 406.42\n",
      "| epoch 6 | perplexity 413.25\n",
      "| epoch 7 | perplexity 388.60\n",
      "| epoch 8 | perplexity 379.11\n",
      "| epoch 9 | perplexity 398.95\n",
      "| epoch 10 | perplexity 411.87\n",
      "| epoch 11 | perplexity 454.15\n",
      "| epoch 12 | perplexity 345.16\n",
      "| epoch 13 | perplexity 325.30\n",
      "| epoch 14 | perplexity 314.11\n",
      "| epoch 15 | perplexity 332.80\n",
      "| epoch 16 | perplexity 282.38\n",
      "| epoch 17 | perplexity 225.48\n",
      "| epoch 18 | perplexity 176.59\n",
      "| epoch 19 | perplexity 148.29\n",
      "| epoch 20 | perplexity 114.22\n",
      "| epoch 21 | perplexity 82.11\n",
      "| epoch 22 | perplexity 64.50\n",
      "| epoch 23 | perplexity 48.97\n",
      "| epoch 24 | perplexity 36.49\n",
      "| epoch 25 | perplexity 29.43\n",
      "| epoch 26 | perplexity 23.07\n",
      "| epoch 27 | perplexity 19.24\n",
      "| epoch 28 | perplexity 14.75\n",
      "| epoch 29 | perplexity 13.37\n",
      "| epoch 30 | perplexity 10.75\n",
      "| epoch 31 | perplexity 8.84\n",
      "| epoch 32 | perplexity 8.11\n",
      "| epoch 33 | perplexity 6.11\n",
      "| epoch 34 | perplexity 5.14\n",
      "| epoch 35 | perplexity 4.89\n",
      "| epoch 36 | perplexity 4.37\n",
      "| epoch 37 | perplexity 3.83\n",
      "| epoch 38 | perplexity 3.59\n",
      "| epoch 39 | perplexity 3.19\n",
      "| epoch 40 | perplexity 3.02\n"
     ]
    }
   ],
   "source": [
    "model = SimpleRnnNetwork(vocab_size, wordvec_size, hidden_size)\n",
    "#model = LSTMNetwork(vocab_size, wordvec_size, hidden_size)\n",
    "\n",
    "time_idx = 0\n",
    "total_loss = 0\n",
    "loss_count = 0\n",
    "rnn_ppl_list = []\n",
    "\n",
    "for epoch in range(max_epoch):\n",
    "    for iter in range(max_iters):\n",
    "        # ミニバッチの取得\n",
    "        batch_x = np.empty((batch_size, time_size), dtype='i')\n",
    "        batch_t = np.empty((batch_size, time_size), dtype='i')\n",
    "        for t in range(time_size):\n",
    "            for i, offset in enumerate(offsets):\n",
    "                batch_x[i, t] = xs[(offset + time_idx) % data_size]\n",
    "                batch_t[i, t] = ts[(offset + time_idx) % data_size]\n",
    "            time_idx += 1\n",
    "\n",
    "        # 勾配を求め、パラメータを更新\n",
    "        loss = model.forward(batch_x, batch_t)\n",
    "        model.backward()\n",
    "        if max_grad is not None:\n",
    "            clip_grads(model.grads, max_grad)\n",
    "\n",
    "        optimizer.update(model.params, model.grads)\n",
    "        total_loss += loss\n",
    "        loss_count += 1\n",
    "\n",
    "    # エポックごとにパープレキシティの評価\n",
    "    ppl = np.exp(total_loss / loss_count)\n",
    "    print('| epoch %d | perplexity %.2f'\n",
    "          % (epoch+1, ppl))\n",
    "    rnn_ppl_list.append(float(ppl))\n",
    "    total_loss, loss_count = 0, 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DyzEKNaLCvFD"
   },
   "source": [
    "## LSTM\n",
    "### LSTMクラス\n",
    "\n",
    "問2-1. <font color=\"Red\">LSTMクラスを完成させてください。</font>\n",
    "\n",
    "LSTMクラスの仕様はRNNクラスとほとんど同じです。\n",
    "\n",
    "各ゲートの計算と通常の順伝播の計算に使用するパラメータを行列にまとめ、一行で計算できるように実装しています。\n",
    "\n",
    "f,g,i,o はそれぞれ、忘却ゲート・入力からの順伝播・入力ゲート・出力ゲートを表しています。\n",
    "\n",
    "<img src=\"lstm_image.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "972frd2QCvFE"
   },
   "outputs": [],
   "source": [
    "class LSTM:\n",
    "    def __init__(self, Wx, Wh, b):\n",
    "        self.params = [Wx, Wh, b]\n",
    "        self.grads = [np.zeros_like(Wx), np.zeros_like(Wh), np.zeros_like(b)]\n",
    "        self.cache = None\n",
    "\n",
    "    def forward(self, x, h_prev, c_prev):\n",
    "        Wx, Wh, b = self.params\n",
    "        N, H = h_prev.shape\n",
    "\n",
    "        A = np.dot(x,Wx) + np.dot(h_prev,Wh) +b\n",
    "\n",
    "        f = A[:, :H]\n",
    "        g = A[:, H:2*H]\n",
    "        i = A[:, 2*H:3*H]\n",
    "        o = A[:, 3*H:]\n",
    "\n",
    "        f =  sigmoid(f)\n",
    "        g =  np.tanh(g)\n",
    "        i =  sigmoid(i)\n",
    "        o =  sigmoid(o)\n",
    "\n",
    "        c_next =  f*c_prev + g*i\n",
    "        h_next =  o*np.tanh(c_next)\n",
    "\n",
    "        self.cache = (x, h_prev, c_prev, i, f, g, o, c_next)\n",
    "        return h_next, c_next\n",
    "\n",
    "    def backward(self, dh_next, dc_next):\n",
    "        Wx, Wh, b = self.params\n",
    "        x, h_prev, c_prev, i, f, g, o, c_next = self.cache\n",
    "\n",
    "        tanh_c_next = np.tanh(c_next)\n",
    "\n",
    "        ds = dc_next+(dh_next*o)*(1-tanh_c_next **2)\n",
    "\n",
    "        dc_prev =  ds*f\n",
    "\n",
    "        di = ds * g\n",
    "        df = ds * c_prev\n",
    "        do = dh_next * tanh_c_next\n",
    "        dg = ds * i\n",
    "\n",
    "        di *= i * (1 - i)\n",
    "        df *= f * (1 - f)\n",
    "        do *= o * (1 - o)\n",
    "        dg *= (1 - g ** 2)\n",
    "\n",
    "        dA = np.hstack((df, dg, di, do))\n",
    "\n",
    "        dWh = np.dot(h_prev.T, dA)\n",
    "        dWx = np.dot(x.T, dA)\n",
    "        db = dA.sum(axis=0)\n",
    "\n",
    "        self.grads[0][...] = dWx\n",
    "        self.grads[1][...] = dWh\n",
    "        self.grads[2][...] = db\n",
    "\n",
    "        dx = np.dot(dA, Wx.T)\n",
    "        dh_prev = np.dot(dA, Wh.T)\n",
    "\n",
    "        return dx, dh_prev, dc_prev\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fSpv_YIw-Azh"
   },
   "source": [
    "### TimeLSTMクラス\n",
    "\n",
    "問2-2. <font color=\"Red\">TimeLSTMクラスを完成させてください。</font>\n",
    "\n",
    "TimeRNNと同じように実装します。\n",
    "\n",
    "SimpleRNN のときと違って、重みの初期化に注意を払う必要があります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RXkWl14bCvFF"
   },
   "outputs": [],
   "source": [
    "class TimeLSTM:\n",
    "    def __init__(self, input_size, output_size, stateful=False):\n",
    "        D,H = input_size, output_size\n",
    "        rn = np.random.randn\n",
    "        np.random.seed(0)\n",
    "        \n",
    "        Wx = (rn(D,4*H) / np.sqrt(D)).astype('f') \n",
    "        Wh = (rn(H,4*H) / np.sqrt(H)).astype('f') \n",
    "        b = np.zeros(4*H).astype('f') \n",
    "\n",
    "        self.params = [Wx, Wh, b]\n",
    "        self.grads = [np.zeros_like(Wx), np.zeros_like(Wh), np.zeros_like(b)]\n",
    "        self.layers = None\n",
    "\n",
    "        self.h, self.c = None, None\n",
    "        self.dh = None\n",
    "        self.stateful = stateful\n",
    "        self.input_shapes = None\n",
    "\n",
    "    def forward(self, xs):\n",
    "        Wx, Wh, b = self.params\n",
    "        N, T, D = xs.shape\n",
    "        H = Wh.shape[0]\n",
    "        self.input_shapes = [N,T,D]\n",
    "\n",
    "        self.layers = []\n",
    "        hs = np.empty((N, T, H), dtype='f')\n",
    "\n",
    "        if not self.stateful or self.h is None:\n",
    "            self.h = np.zeros((N, H), dtype='f')\n",
    "        if not self.stateful or self.c is None:\n",
    "            self.c = np.zeros((N, H), dtype='f')\n",
    "\n",
    "        for t in range(T):\n",
    "            layer = LSTM(*self.params)\n",
    "            self.h, self.c = layer.forward(xs[:,t,:],self.h,self.c) \n",
    "            hs[:, t, :] = self.h\n",
    "\n",
    "            self.layers.append(layer)\n",
    "\n",
    "        return hs\n",
    "\n",
    "    def backward(self, dhs):\n",
    "        Wx, Wh, b = self.params\n",
    "        H = Wh.shape[0]\n",
    "        N, T, D = self.input_shapes\n",
    "        \n",
    "        if dhs.ndim == 2:\n",
    "            temp = np.zeros((N,T,H))\n",
    "            temp[:,-1,:] = dhs\n",
    "            dhs = temp\n",
    "  \n",
    "        N, T, H = dhs.shape\n",
    " \n",
    "        dxs = np.empty((N, T, D), dtype='f')\n",
    "        dh, dc = 0, 0\n",
    "\n",
    "        grads = [0, 0, 0]\n",
    "        for t in reversed(range(T)):\n",
    "            layer = self.layers[t]\n",
    "            dx, dh, dc = layer.backward(dhs[:,t,:]+dh,dc) \n",
    "            dxs[:, t, :] = dx\n",
    "            for i, grad in enumerate(layer.grads):\n",
    "                grads[i] += grad\n",
    "\n",
    "        for i, grad in enumerate(grads):\n",
    "            self.grads[i][...] = grad\n",
    "        self.dh = dh\n",
    "        return dxs\n",
    "\n",
    "    def set_state(self, h, c=None):\n",
    "        self.h, self.c = h, c\n",
    "\n",
    "    def reset_state(self):\n",
    "        self.h, self.c = None, None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "STsi7N7c-Azk"
   },
   "source": [
    "### LSTMNetworkクラス\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9UIwu6fuCvFI"
   },
   "outputs": [],
   "source": [
    "class LSTMNetwork:\n",
    "    def __init__(self, vocab_size=10000, wordvec_size=100, hidden_size=100):\n",
    "        V, D, H = vocab_size, wordvec_size, hidden_size\n",
    "        rn = np.random.randn\n",
    "        np.random.seed(0)\n",
    "\n",
    "        # 重みの初期化\n",
    "        embed_W = (rn(V, D) / 100).astype('f')\n",
    "        affine_W = (rn(H, V) / np.sqrt(H)).astype('f')\n",
    "        affine_b = np.zeros(V).astype('f')\n",
    "\n",
    "        # レイヤの生成\n",
    "        self.layers = [\n",
    "            TimeEmbedding(embed_W),\n",
    "            TimeLSTM(D, H, stateful=True),\n",
    "            TimeAffine(affine_W, affine_b)\n",
    "        ]\n",
    "        self.loss_layer = TimeSoftmaxWithLoss()\n",
    "        self.lstm_layer = self.layers[1]\n",
    "\n",
    "        # すべての重みと勾配をリストにまとめる\n",
    "        self.params, self.grads = [], []\n",
    "        for layer in self.layers:\n",
    "            self.params += layer.params\n",
    "            self.grads += layer.grads\n",
    "\n",
    "    def predict(self, xs):\n",
    "        for layer in self.layers:\n",
    "            xs = layer.forward(xs)\n",
    "        return xs\n",
    "\n",
    "    def forward(self, xs, ts):\n",
    "        score = self.predict(xs)\n",
    "        loss = self.loss_layer.forward(score, ts)\n",
    "        return loss\n",
    "\n",
    "    def backward(self, dout=1):\n",
    "        dout = self.loss_layer.backward(dout)\n",
    "        for layer in reversed(self.layers):\n",
    "            dout = layer.backward(dout)\n",
    "        return dout\n",
    "\n",
    "    def reset_state(self):\n",
    "        self.lstm_layer.reset_state()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ofZZ-gIpCvFO"
   },
   "source": [
    "## 学習、評価\n",
    "\n",
    "ハイパーパラメータなどは先ほどのRNNと全て共通で学習させます。\n",
    "\n",
    "40エポックでperplexity が5以下となっていれば学習成功です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hcgBW6tmCvFP",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 1 | perplexity 278.48\n",
      "| epoch 2 | perplexity 224.88\n",
      "| epoch 3 | perplexity 205.25\n",
      "| epoch 4 | perplexity 188.97\n",
      "| epoch 5 | perplexity 175.05\n",
      "| epoch 6 | perplexity 155.77\n",
      "| epoch 7 | perplexity 133.43\n",
      "| epoch 8 | perplexity 106.73\n",
      "| epoch 9 | perplexity 81.01\n",
      "| epoch 10 | perplexity 58.26\n",
      "| epoch 11 | perplexity 40.60\n",
      "| epoch 12 | perplexity 27.62\n",
      "| epoch 13 | perplexity 20.00\n",
      "| epoch 14 | perplexity 14.09\n",
      "| epoch 15 | perplexity 10.32\n",
      "| epoch 16 | perplexity 7.90\n",
      "| epoch 17 | perplexity 5.75\n",
      "| epoch 18 | perplexity 4.58\n",
      "| epoch 19 | perplexity 3.62\n",
      "| epoch 20 | perplexity 3.06\n",
      "| epoch 21 | perplexity 2.63\n",
      "| epoch 22 | perplexity 2.23\n",
      "| epoch 23 | perplexity 1.98\n",
      "| epoch 24 | perplexity 1.73\n",
      "| epoch 25 | perplexity 1.67\n",
      "| epoch 26 | perplexity 1.54\n",
      "| epoch 27 | perplexity 1.44\n",
      "| epoch 28 | perplexity 1.37\n",
      "| epoch 29 | perplexity 1.28\n",
      "| epoch 30 | perplexity 1.29\n",
      "| epoch 31 | perplexity 1.24\n",
      "| epoch 32 | perplexity 1.19\n",
      "| epoch 33 | perplexity 1.21\n",
      "| epoch 34 | perplexity 1.17\n",
      "| epoch 35 | perplexity 1.14\n",
      "| epoch 36 | perplexity 1.13\n",
      "| epoch 37 | perplexity 1.10\n",
      "| epoch 38 | perplexity 1.06\n",
      "| epoch 39 | perplexity 1.03\n",
      "| epoch 40 | perplexity 1.02\n"
     ]
    }
   ],
   "source": [
    "model = LSTMNetwork(vocab_size, wordvec_size, hidden_size)\n",
    "\n",
    "time_idx = 0\n",
    "total_loss = 0\n",
    "loss_count = 0\n",
    "lstm_ppl_list = []\n",
    "\n",
    "for epoch in range(max_epoch):\n",
    "    for iter in range(max_iters):\n",
    "        # ミニバッチの取得\n",
    "        batch_x = np.empty((batch_size, time_size), dtype='i')\n",
    "        batch_t = np.empty((batch_size, time_size), dtype='i')\n",
    "        for t in range(time_size):\n",
    "            for i, offset in enumerate(offsets):\n",
    "                batch_x[i, t] = xs[(offset + time_idx) % data_size]\n",
    "                batch_t[i, t] = ts[(offset + time_idx) % data_size]\n",
    "            time_idx += 1\n",
    "\n",
    "        # 勾配を求め、パラメータを更新\n",
    "        loss = model.forward(batch_x, batch_t)\n",
    "        model.backward()\n",
    "        if max_grad is not None:\n",
    "            clip_grads(model.grads, max_grad)\n",
    "\n",
    "        optimizer.update(model.params, model.grads)\n",
    "        total_loss += loss\n",
    "        loss_count += 1\n",
    "\n",
    "    # エポックごとにパープレキシティの評価\n",
    "    ppl = np.exp(total_loss / loss_count)\n",
    "    print('| epoch %d | perplexity %.2f'\n",
    "          % (epoch+1, ppl))\n",
    "    lstm_ppl_list.append(float(ppl))\n",
    "    total_loss, loss_count = 0, 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fnkwvXuS-Azs"
   },
   "source": [
    "LSTMとRNNの学習結果を比較し、LSTMの方が安定して素早く学習が収束していることを確認してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jBRkO629-Azt"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEKCAYAAAAIO8L1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3Xl8FPX9x/HXZzebhBwEAuQiQe6bJGBAFE8UEAEPioi21SLWHl7V/tra2van/fWwxWqrtVYtFrAo4g2IWOt9gBIgQLjkhoQjXDkgd/L9/TETDLAkC2R3Nruf5+Oxjzl2ZvPOKPvJzHfm+xVjDEoppdSJXE4HUEopFZy0QCillPJKC4RSSimvtEAopZTySguEUkopr7RAKKWU8koLhFJKKa+0QCillPJKC4RSSimvIpwOcDY6duxounbt6nQMpZRqVZYvX37AGNOpue1adYHo2rUrubm5TsdQSqlWRUR2+LKdXmJSSinllV8LhIhsF5E1IpInIrn2ukQReVdENtnT9vZ6EZHHRWSziKwWkSH+zKaUUqppgTiDuMwYk22MybGX7wfeM8b0At6zlwHGAr3s1+3AUwHIppRS6hScaIO4BrjUnp8FfAj8zF4/21j9jy8VkXYikmqM2eNARqVUiKmpqaGgoIDKykqnowRMdHQ06enpeDyeM9rf3wXCAP8REQM8bYx5Bkhu+NI3xuwRkSR7287Arkb7FtjrtEAopc5aQUEB8fHxdO3aFRFxOo7fGWM4ePAgBQUFdOvW7Yw+w98FYoQxZrddBN4VkQ1NbOvtv9hJoxmJyO1Yl6Do0qVLy6RUSoW8ysrKsCkOACJChw4d2L9//xl/hl/bIIwxu+1pEfA6MAzYJyKpAPa0yN68AMhotHs6sNvLZz5jjMkxxuR06tTsbbxKKXVMuBSHBmf7+/qtQIhIrIjEN8wDo4F8YD5wi73ZLcCb9vx84Gb7bqbhQEmwtj98tvkA6/eUOh1DKaX8yp9nEMnApyKyCvgSeMsYsxh4GBglIpuAUfYywCJgK7AZeBb4oR+znTFjDHe8sIKfv7bG6ShKqVbG7XaTnZ3NwIEDmTBhAsXFxQBs374dEeGJJ544tu2dd97JzJkzAfjOd75D586dqaqqAuDAgQMEohcJvxUIY8xWY0yW/RpgjPmdvf6gMeZyY0wve3rIXm+MMXcYY3oYYwYZY4LyEemtB45SXF5D3q5idh0qdzqOUqoVadOmDXl5eeTn55OYmMiTTz557L2kpCT++te/Ul1d7XVft9vNc889F6iogD5JfdqW7zh8bH7+qpOaSJRSyifnn38+hYWFx5Y7derE5ZdfzqxZs7xu/6Mf/YjHHnuM2traQEVs3X0xOWHlzsO0jY6gR1IcC1bt5o7LejodSSl1mh5asJZ1u1u2HbF/Wlv+d8IAn7atq6vjvffeY9q0acetv//++xk7diy33nrrSft06dKFCy+8kOeff54JEya0SObm6BnEaVqxo5jBXdpzTVYaG/aWsWlfmdORlFKtREVFBdnZ2XTo0IFDhw4xatSo497v1q0bw4YN44UXXvC6/y9+8QumT59OfX19IOLqGcTpKK2s4auiMq4alMpVman8ZuE6FqzazX2j+zgdTSl1Gnz9S7+lNbRBlJSUMH78eJ588knuvvvu47b5xS9+waRJk7j44otP2r9nz55kZ2czb968gOTVM4jTkLezGGNgyDntSIqP5vweHZi/ajdW7yBKKeWbhIQEHn/8cR555BFqamqOe69v377079+fhQsXet33gQce4JFHHglETC0Qp2PFzsOIQHZGOwAmZKax/WA5+YX6TIRS6vQMHjyYrKws5s6de9J7DzzwAAUFBV73GzBgAEOGBKaza73EdBpW7CymT3I88dFWx1dXDkzhV2/ms2D1bgalJzicTikV7I4cOXLc8oIFC47N5+fnH5vPyso6rp2h4XmIBq+99pp/Ap5AzyB8VF9vWLnzMIO7tD+2rl1MJBf36sSCVbupr9fLTEqp0KIFwkeb9x+hrLKWc89pf9z6CVlp7CmpZPnOw6fYUymlWictED5aYT8gN6RLu+PWj+qfTLTHxfw8fWhOKRVatED4aPmOw7SP8dCtY+xx62OjIri8bzKL1uyhti4w9yYrpVQgaIHw0YqdhxnSpb3X7nMnZKVx8Gg1n2856EAypZTyDy0QPigur2bL/qMMOaH9ocGlfToRFxXBghDvm2nL/iP8ftF66rRBXqmwoAXCByt3WV3yDj6h/aFBtMfN6AHJLF67l6raukBGC6g/LNrAMx9vZXPRkeY3VkqdJC4u7qR1Gzdu5NJLLyU7O5t+/fpx++23884775CdnU12djZxcXH06dOH7Oxsbr75Zj788ENEhBkzZhz7jJUrVyIiLf4AnRYIH6zYcRi3S8hK914gAK7OSqOsspaPNp758H7BbHPREf67fh8AG/bqg4FKtZS7776be++9l7y8PNavX89dd93FmDFjyMvLIy8vj5ycHObMmUNeXh6zZ88GYNCgQbz00kvHPmPu3LlkZWW1eDYtED5YsfMwfVPiiY069XOFI3p2pH2MhwWrg3IQvLP2z0+2EhXhIsIlbNirHRQq1VL27NlDenr6seVBgwY1u0+XLl2orKxk3759GGNYvHgxY8eObfFs+iR1M+rqDXk7i5k4JL3J7TxuF1cNSuW1FYWUV9cSExk6h7aorJLXVhRyfU46udsPs1ELhGrt3r4f9rbwqJApg2Dsw81vd4J7772XkSNHcsEFFzB69GimTp1Ku3anvlrRYNKkSbz88ssMHjyYIUOGEBUVdSapm6RnEM3YuLeMo9V1Jz0g582ErDQqaur47/qiACQLnFmfb6emvp7bLupO39R4Nuh43Eq1mKlTp7J+/Xquv/56PvzwQ4YPH35saNGmTJ48mZdffpkXX3yRG2+80S/ZQufPXD9ZsbPhAbnmC8TQrokkt41ift5urs5K83e0gDhaVcu/l+5kTP8UunWMpU9KPG/m7aakooaENh6n4yl1Zs7gL31/SktL49Zbb+XWW29l4MCB5Ofnc+655za5T0pKCh6Ph3fffZe//vWvfP755y2eS88gmrFi52E6xkWSkdim2W3dLmF8ZhoffVVESXlNs9u3Bi8t20VJRQ23X9IdgH4pbQH0MpNSLWTx4sXHuvzeu3cvBw8epHPnzj7t+5vf/IY//vGPuN1uv2TTM4hmrNxpjSDn7QE5byZkpTHj0228kVfILRd09W84P6upq2fGp9sY2rX9sTOoPinxAGzcW8qwbolOxlOq1SkvLz+uQfq+++6joKCAe+65h+joaACmT59OSkqKT593wQUX+CVnAy0QTTh4pIptB45yw9AMn/fJSk/gvG6JTH9nI5f3SyK9fYwfE/rXojV7KCyu4MGrvx59KzUhmrbREXonk1Jn4FRDhT766KOn3OfDDz88bvnSSy/l0ksvPWm7Bx988CySeaeXmJqwcqf1gJwv7Q8NRIRHrs+i3hh+9urqVtsNuDGGpz/aSo9OsVzeN+nYehGhb0pbLRBKhQEtEE1YsfMwES4h8zQHA8pIjOGX4/rz2eaDzPlih5/S+ddnmw+ybk8p372oOy7X8ZfX+qbGs3FvmQ61qlSI0wLRhOU7DjMgrS3RntNvALpxWAYX9+7E7xdtYPuBo35I519Pf7yFjnFRXDv45MayPinxHKmqpeBwhQPJlDpz4fZHzdn+vlogTqG2rp7VBSXHjSB3OkSEP30jE49b+J+XV7WqDu7W7S7lk00HmDqiq9fi2PdYQ7VeZlKtR3R0NAcPHgybImGM4eDBg8cav8+ENlKfwoa9ZVTU1J2yB1dfpCRE89A1A7j3pVXM+HQrt1/cowUT+s+zn2wlJtLNt847x+v7vZOtArFhbylX9E8OZDSlzlh6ejoFBQXs3x+a/aV5Ex0dfdxdU6dLC8QpLLdHkPPlCeqmXJvdmcX5e3nkna+4tE/SsS/XYLW7uIIFq3bz7fPPISHG+4Nw8dEe0tu30YZq1ap4PB66devmdIxWRS8xncKKnYdJbhtFWsKZn56Bdanpd9cNIi46gh/PW0VNM6PO1dTVc+BI84/Z+8tzn27DANMubPofUt+UtnqJSakQpwXiFJoaQe50dYyL4vfXDWRNYQlPfbjlpPeNMSzfcYhfv5nP8N+/x/l/eI/c7YfO+ueerh0Hj/LilzsZNyi12ec3+qbEs/XA0ZAe/0KpcKcFwouiskp2Hao468tLjV05MJVrstN4/L1N5BeWAPDVvjKmv7OBi/70Ad94agkvLdvF8B4dSGvXhh/OWUFRWWWL/fym1NcbZi/Zzti/foJLhDtH9mx2n76p8dTVGx08SKkQ5vc2CBFxA7lAoTFmvIh0A+YCicAK4NvGmGoRiQJmA+cCB4EbjDHb/Z3PmxU7GkaQa7kCAfDQ1QNYsuUgd7ywgjYeNxv2luF2CSN6duS+Ub0ZPSCFuKgI1u8p5bq/f8adc1Yy57vn4XH7r47vOlTOT15ZxdKth7i4dycenjiItHbN9zvVcCfThj1lDEg7vedElFKtQyDOIO4B1jda/iPwmDGmF3AYmGavnwYcNsb0BB6zt3PEF9sOEul2MbBz2xb93HYxkfxxUiaFhytoE+nmoasHsPTnlzP71mFMHJJOnD0gUb/UtvzxG5l8uf0Qf1i0oUUzNKivNzy/ZDtj/vIx+YWlPDxxELOmDvWpOAB07RBLZISLjfu0HUKpUOXXMwgRSQfGAb8D7hPrgv5I4CZ7k1nAg8BTwDX2PMArwN9EREyAb1r+77p9zF6ygzEDkomKaPkeEi/rk8Ta34xp9rOvye7Myp3FPPfZNrIyErgm27feHX2x61A5P31lNUu2HuSiXh15+BuZdPaxMDSIcLvolRSndzIpFcL8fYnpL8BPgYZ7OzsAxcaYWnu5AGj45usM7AIwxtSKSIm9/QE/Zzxm2fZD3PHCCgamtWX6pJYf37WBr4XngXH9WLu7hPtfXUOflHj6ppz9Gc0LX+zkt2+twyXCHyYOYsrQjDNuiO+TEs+nmwL2n0cpFWB+u8QkIuOBImPM8sarvWxqfHiv8efeLiK5IpLbkg+8bNhbyrSZy+jcrg3PfWdok+NPB4rH7eLJm4YQFx3B959fTknF2Y0x8eQHm/nF62sY0qU979x7MTcO63JWd2n1S2lLUVkVh45Wn1UupVRw8mcbxAjgahHZjtUoPRLrjKKdiDR8+6YDu+35AiADwH4/ATjpXk9jzDPGmBxjTE6nTp1aJOiuQ+Xc8tyXtIl0M3vaMDrEtfzYrmcqqW00T31zCAWHK/jxvLwz7h322Y+3Mv2djVw3uDOzbh122peUvGkYG2LDXh2CVKlQ5LcCYYz5uTEm3RjTFZgCvG+M+SbwATDJ3uwW4E17fr69jP3++4Fofzh4pIpbnvuSiuo6Zt96XlCO35DTNZFfjuvHf9cX8eQHm097/5mfbeN3i9YzLjOV6ZMycbvO/tkOsG51Be2TSalQ5cRzED/DarDejNXGMMNePwPoYK+/D7jf30GOVNUydeYyCosrmPGdocf+Ig5Gt1zQlWuz03j0v1/xwcYin/eb88UOHlywjjEDkvnLDdlEtOAts53iokiMjdQCoVSICsiFdmPMh8CH9vxWYJiXbSqB6wORB6C6tp7vP7+ctbtLefpb5zK0a3APnyki/GFiJhv2ljFt5jKuye7MHZf1pGdS3Cn3mbdsFw+8ns/Ivkk8ceOQFn+ewho8KJ71WiCUCklh+SR1fb3hvnl5fLr5AA9PHNRqeiRtE+nmhe8O57aLurM4fy+jHvuIu15c6fUv+NdXFvCz11ZzUa+O/P2bQ4iM8M9/6j4p8Xy1t6zVjpynlDq1sCwQT7y/mYWr93D/2L5cn+P7eNPBIDE2kl9c1Y9Pf3YZ37+kB++v38eYv3zMD/69nLW7rS48Fq7ezY/nreL87h149uacMxrwyFf9UtpSUVPHzkPlfvsZSilnOH8vpwNuPC+DuOgIbh3R1ekoZ6xDXBQ/u7Ivt1/UnX99to1/fbadt/P3MqJnB5ZuPUTOOYn88xb/FgdofCdTGV07xvr1ZymlAisszyCS4qOZdmG3Fump1WntYyO5b3QfPr1/JPeN6k1+YSnZGe14bupQYiL9X/97J8cjore6KhWKwvIMIhQltPFw9+W9+P4lPXAJLXq3UlPaRLrp2iFW72RSKgRpgQgx/mqMbkqf5HgtEEqFoLC8xKRaVt/UeLYdPEpFtQ4epFQo0QKhzlrflHiMgU1FehahVCjRAqHOWkMvsxv2aIFQKpRogVBnrUtizLER8pRSoUMLhDprLpfQOyWejfv0VlelQokWCNUi+ibH6yUmpUKMFgjVIvqkxHPwaDX7y6qcjqKUaiFaIFSLaBgbQp+oVip0aIFQLaLhTiZ9YE6p0KEFQrWIxNhIkuKjWK/tEEqFDC0QqsX0SYlndUExdTo2hFIhQQuEajHjBqWyqegI97+6WgcQUioEaGd9qsVMGdaF3SWVPP7eJiIjXPz22oEh0aW6UuFKC4RqUfde0Yvq2nr+8dEWPG4X/zuhvxYJpVopLRCqRYkIP7uyDzV19cz4dBuRES5+PravFgmlWiFtg1AtTkT45bh+3Hz+OTzz8VYe+c9GjDm7NonC4gp++cYaikorWyilUqo5egah/EJEeHDCAGrq6nnygy1Eut3cc0WvM/qsHQePctOzX1BYXEFclIf7x/Zt4bRKKW/0DEL5jcsl/O7aQXxjSDqP/fcr/v7h5tP+jC37jzD56SUcra4lMz2BV1cUUFtX74e0SqkTaYFQfuVyCX+alMnVWWn8afFGpr+zgcoa30ae27i3jBueXkpdvWHu7cO587Ke7C+r4qOv9vs5tVIKtECoAHC7hEcnZ/GNIek8+cEWrnj0I95es6fJdon8whKmPLMEtwvm3n4+fVPaclnfJDrGRfLSsl0BTK9U+NICoQIiwu3iz5OzeOG284iLiuAHc1Zw07NfsH7PyZ37rdx5mBufXUpMZATzvnc+PZPiAPC4XUwcks77G4q011ilAkALhAqoC3p2ZOFdF/J/1w5k/d5Sxj3+Cb98Yw2HjlYD8OW2Q3zrn1+QGBvJS98bzjkdYo/bf3JOOrX1hjdWFjoRX6mwImd7+6GTcnJyTG5urtMx1BkqLq/mL//dxPNLdxAb6ebG87ow+/MdpLWLZs5tw0lJiPa638S/f0ZZZS3/ufdifb5CqTMgIsuNMTnNbadnEMox7WIiefDqASy+5yKyMtrx9EdbOadDDHNvP/+UxQFgck4Gm4qOkLerOIBplQo/+hyEclyv5Hhm3zqMFTuL6ZUcR9toT5Pbj8tM5aEF65iXu4vBXdoHKKVS4UfPIFRQEBHOPad9s8UBID7aw1WDUlmwag/l1bUBSKdUePJbgRCRaBH5UkRWichaEXnIXt9NRL4QkU0i8pKIRNrro+zlzfb7Xf2VTbV+k3PSOVJVy9tr9jodRamQ5c8ziCpgpDEmC8gGrhSR4cAfgceMMb2Aw8A0e/tpwGFjTE/gMXs7pbwa1i2Rrh1imJerz0Qo5S9+KxDGcsRe9NgvA4wEXrHXzwKuteevsZex379c9BYVdQoiwvU5GXyx7RDbDxx1Oo5SIcmnAiEiuSJyh4icVougiLhFJA8oAt4FtgDFxpiGC8cFQGd7vjOwC8B+vwTo4OUzb7fz5O7fr10uhLNvDEnHJfDycj2LUMoffD2DmAKkActEZK6IjPHlr3tjTJ0xJhtIB4YB/bxtZk+9fd5JD2kYY54xxuQYY3I6derkY3wVilISormkdydeWV6g42Ar5Qc+FQhjzGZjzANAb+AF4Dlgp4g8JCKJPuxfDHwIDAfaiUjD7bXpwG57vgDIALDfTwAO+f6rqHA0OSeDfaVVfLxJzyaVamk+t0GISCbwZ2A68CowCSgF3j/F9p1EpJ093wa4AlgPfGDvC3AL8KY9P99exn7/fdOaH/NWAXF5v2QSYyN5WRurlWpxPj0oJyLLgWJgBnC/Maahp7QvRGTEKXZLBWaJiBurEM0zxiwUkXXAXBH5LbDS/kzs6fMishnrzGHKGf1GKqxERri4bnBnZi/ZzqGj1STGRjodSamQ4euT1NcbY7Y2XiEi3Ywx24wxE73tYIxZDQz2sn4rVnvEiesrget9zKPUMZNzMpjx6TZeX1nItAu7OR1HqZDh6yWmV3xcp1TA9UmJJys9gZdzd5312NdKqa81eQYhIn2BAUCCiDQ+U2gLnLo3tdbAGNDHLELG9TkZ/PKNfNbtKWVAWoLTcZQKCc2dQfQBxgPtgAmNXkOA7/o3mh/lvQD/uBDqapxOolrIVYNScbuEhav3OB1FqZDR5BmEMeZN4E0ROd8YsyRAmfwvqi3sy4ctH0Dv0U6nUS0gMTaSET07snD1bn46po+OE6FUC2jyDEJEfmrP3iQij5/4CkA+/+g1Gtq0h9UvOZ1EtaDxmansOlTB6oISp6MoFRKau8S03p7mAsu9vFqniEgYcB1seAuqypxOo1rImP4peNzCwtW7m99YKdWsJguEMWaBPfuSMWZW4xfwlv/j+VHmDVBbAesXOp1EtZCEGA8X9+rEW6v3UK9dbyh11ny9zfVLu6tuAETkG8Dn/okUIBnnQbtzYPVcp5OoFjQ+K5XdJZWs3HXY6ShKtXq+FohvAk+IyHQRmYN1B9NI/8UKABHrLGLrR1Cqd76Eiiv6JRMZ4WLBKv1vqtTZ8rWzvjXA74DvA5cBdxpjCvwZLCAybwAM5Oszf6EiPtrDZX06sWjNHu3hVamz5Ot4EDOAHwGZwFRggYjc4c9gAdGxJ3Q+F1bp3UyhZHxmGkVlVSzbrp0BK3U2fL3ElA9cZve99A5Wt91D/BcrgDJvgH1rYN9ap5OoFnJ5vyTaeNx6N5NSZ8nXS0yPAdEi0sdeLjHGTGtmt9ZhwEQQN6ye53QS1UJiIiMY2S+Jt9fspbau3uk4SrVavl5imgDkAYvt5WwRme/PYAET1wl6XgFrXoZ6/TIJFRMyUzl4tJqlW/Uyk1JnytdLTA9iddFdDGCMyQNCp1/lzMlQWgg7PnU6iWohl/ZJIjZSLzMpdTZ8LRC1xpgT+y8InVtE+lwFkfHa9UYIifa4GdU/mcVr91Kjl5mUOiM+N1KLyE2AW0R6icgTtPYH5RqLjIH+V8O6+VBT4XQa1ULGZ6ZRXF7Dp5sPOB1FqVbJ1wJxF9a4EFXAi1hjUf/IX6EckTkZqkph49tOJ1Et5KLeHYmPjmChPjSn1Bnx9S6mcmPMA8aYocaYHHu+0t/hAqrrRRCfpnczhZCoCDdjBqTwn3V7qaqtczqOUq1OcyPKLaCJtgZjzNUtnsgpLjcMmgRL/w5HD0BsR6cTqRYwPjOVV5YX8PFXBxjVP9npOEq1Kk0WCOCRgKQIFpk3wOePw9rXYVjrHTBPfW1Ez460j/GwcPVuLRBKnabmRpT7qGFeRCKBvlhnFBuNMdV+zhZ4KQMheaB1N5MWiJDgcbu4cmAK8/N2U1lTR7TH7XQkpVoNXx+UGwdsAR4H/gZsFpGx/gzmmMzJULAMDm5xOolqIeMz0zhaXccHG4qcjqJUq+LrXUx/xuqL6VJjzCVYPbo+5r9YDho4CRBtrA4h53VLpGNcJAtX691MSp0OXwtEkTFmc6PlrUBo/jmW0Bm6XwLLnoX9XzmdRrWACLeLqwal8t/1+ygpr3E6jlKthq8FYq2ILBKR74jILcACYJmITBSRiX7M54yrHrE68Js1AQ5sbn57FfQm52RQVVvPG3mFTkdRqtXwtUBEA/uAS4BLgf1AIjABGO+XZE7q2AtuWQD1tTBrvLZHhICBnRMY1DmBF7/ciTGh00uMUv7UbIEQETew2hgz9RSvWwOQM/CS+lpFoq7aOpM4tM3pROosTRmWwYa9ZeTtKnY6ilKtQrMFwhhTB4TOA3GnI7k/3DwfasqtInF4h9OJ1Fm4OiuNNh43c7/c5XQUpVoFXy8xfS4ifxORi0RkSMPLr8mCRcpAuPlNqCqzLjcV73Q6kTpD8dEers5KY8Hq3ZRVamO1Us3xtUBcgNVZ32+wbnn9M+H0lHVqFtz8BlSUWGcSJQVOJ1JnaMqwDMqr65i/SseJUKo5vnbWd5mX18im9hGRDBH5QETWi8haEbnHXp8oIu+KyCZ72t5eLyLyuIhsFpHVQXeGkjYYvv06lB+CmeOhVL9gWqPsjHb0TYnXy0xK+cDXJ6mTRWSGiLxtL/cXkebGpK4FfmyM6QcMB+4Qkf7A/cB7xphewHv2MsBYoJf9uh146rR/G39LPxe+9ZrVmd+M0bA33+lE6jSJCFOGZrCmsIT8whPHwFJKNebrJaaZwDtAmr38Fc2MB2GM2WOMWWHPlwHrgc7ANcAse7NZwLX2/DXAbGNZCrQTkVQf8wVOxlD4zkLrFtjnxsDGxU4nUqfpusHpREW4ePFLbU9Sqim+FoiOxph5QD2AMaYW8LmDfRHpCgwGvgCSjTF77M/ZAyTZm3UGGp/3F9jrgk9aNnz3fejQE16cAp//DfTe+lYjIcbDuEGpvJm3m/LqWqfjKBW0fC0QR0WkA/bYECIyHPDp/FxE4oBXgR8ZY0qb2tTLupO+dUXkdhHJFZHc/fv3+xLBP9qmwdS3od8E+M8DsOAeqA29Dm5D1ZRhXThSVav9MynVBF8LxH3AfKC7iHwGzMYahrRJIuLBKg5zjDGv2av3NVw6sqcNfToVABmNdk8HTmoJNsY8Y49ql9OpUycf4/tJZAxcPwsu+jGsmAX/nmg1YqugN7Rre3p0itXLTEo1wdcCsQ54HViG1eXGs1jtEKckIgLMANYbYx5t9NZ84BZ7/hbgzUbrb7bvZhoOlDRcigpqLhdc/mu47mnY9QX88wrtv6kVEBFuHNaFlTuL2bi3zOk4SgUlXwvEbKzBgn4PPIF1p9HzzewzAvg2MFJE8uzXVcDDwCgR2QSMspcBFmH1ErsZqwD98HR+EcdlTbG65qgshn+OhE3vOp1INWPikHQi3dpYrdSpiC8dl4nIKmNMVnPrAi0nJ8fk5uY6GeFkh7fD3G/CvnwY/kO44kGIiHI4lDqVO19YwSebDvDFLy7X0eZU2BCR5cZJZoaiAAAYJElEQVSYnOa28/UMYqV92afhw88DPjvTcCGtfVe47T0Y9j1Y+nd49nLYv9HpVOoUbhrWhZKKGt7OD/6rmUoFmq8F4jys/pi2i8h2YAlwiYisEZHVfkvXWnmi4ao/wY0vQdluePoSyP2X3gobhIZ378A5HWJ4UZ+sVuokET5ud6VfU4SqPlfCDz6H178PC38EW96DCY9DTKLTyZTN5RJuGJrBnxZvZMv+I/ToFOd0JKWChq99Me1o6uXvkK1afIrVPceo/7Oeun5qBGz7xOlUqpFJ56YT4RLmLNXGaqUa8/USkzobLheMuBtuexc8baweYVc0dxOYCpSk+Giuzk5j9pLt2j+TUo1ogQiktMHwvY+hx0iYfyesmO10ImX71bj+tI+N5MfzVlFV63MvMkqFNC0QgRYVB1NegJ5XwPy7YPms5vdRftc+NpI/fSOTjfvKePTdJp8BVSpsaIFwgicabpgDPUfBgrth+UynEyngsr5JTBmawTMfb2X5Du0yRSktEE7xRMMN/4Zeo62O/nL/5XQiBfxyfH86t2vDffNWaU+vKuxpgXBS4yKx8EeQ+5zTicJeXFQEj1yfxc5D5fxh0Qan4yjlKC0QTouIsovEGFh4Lyyb4XSisDe8ewduHdGN55fu4JNNDnYpr5TDtEAEg4gouOF56H0lvHUfLPun04nC3k/G9KFnUhw/eXk1JRU1TsdRyhFaIIJFRBRMng29x8JbP4b815rfR/lNtMfNo5Oz2H+kiofmr3U6jlKO0AIRTCKi4PqZ0OV8q3uOnUudThTWMtPbccdlPXltZSGL8/c6HUepgNMCEWw80dZzEgnp8OKNcHCL04nC2l0jezKwc1seeH0NB45UOR1HqYDSAhGMYhLhmy9b83Ou12FMHeRxu3h0cjZllbX87q31TsdRKqC0QASrDj3gxrlQUgBzb4KaSqcTha3eyfHcdlE3Xl9ZSN6uYqfjKBUwWiCCWZfzYOLTsHMJvPlDqK93OlHY+uFlPekYF8X/LVyHL6MwKhUKtEAEuwHXwRUPQf6r8P7/OZ0mbMVFRfA/o3uzfMdhFq7W0edUeNAC0RqMuAfOnQqfPqqd+zno+pwM+qW25eG3N1BZoz2+qtCnBaI1EIGrHrF6gF14L2x+z+lEYcntEn41vh+FxRXM+HSb03GU8jstEK2FO8J6RiKpP7w8FYp19DMnXNCjI6P6J/P3DzZTVKY3DqjQpgWiNYmKt7rkMPXw6nehTnsbdcIvrupHdV09f35Hx41QoU0LRGuT2A3GPwa7lsLH051OE5a6dYzllvO7Mm/5Ltbu1iFKVejSAtEaZV4PWTfCx3+CHZ87nSYs3XV5L9q18fDbhev1tlcVsrRAtFZXTYf2Xa1LTfqkdcAltPFw76jeLNl6kHfX7XM6jlJ+oQWitYqKh2/MgCP7rGFL9a/YgLtpWBd6JcXx+0Xrqa7VhxhV6NEC0Zp1HgKX/xrWL9BxrR0Q4XbxwLh+bD9Yzuwl252Oo1SL0wLR2p1/J/QYCYt/DkU6RGagXdoniUt6d+Kv723i0NFqp+Mo1aK0QLR2Lhdc+w+IjIVXbtVO/Rzwy3H9qKiuY/o7WqBVaNECEQrik+G6f0DRWnj3V06nCTu9kuOZOqIrc5ftYuXOw07HUarF+K1AiMhzIlIkIvmN1iWKyLsissmetrfXi4g8LiKbRWS1iAzxV66Q1WsUDP8hfPkMbFjkdJqwc88VvUmKj+LXb66lrl5vGFChwZ9nEDOBK09Ydz/wnjGmF/CevQwwFuhlv24HnvJjrtB1xYOQkml1DV68y+k0YSUuKoIHxvVnTWEJL3yp3aCo0OC3AmGM+Rg48Qb9a4CG7khnAdc2Wj/bWJYC7UQk1V/ZQlbDmNZ1tVZ7RF2N04nCyoTMVC7o0YHpizdwUIcnVSEg0G0QycaYPQD2NMle3xlo/Cdvgb1Ona4OPeDqx6HgS3jvIafThBUR4TfXDKC8uo4/LtYGa9X6BUsjtXhZ5/VCrojcLiK5IpK7f/9+P8dqpQZOhKG3wedPwMa3nU4TVnomxTPtom7Myy1g+Q59wl21boEuEPsaLh3Z0yJ7fQGQ0Wi7dGC3tw8wxjxjjMkxxuR06tTJr2FbtdG/s9ojXv++dg0eYHeP7EVqQjS/emMttXX6hLVqvQJdIOYDt9jztwBvNlp/s30303CgpOFSlDpDnmiYPMvqGvzlqVCrD3EFSmxUBL8a3591e0qZ84UWZ9V6+fM21xeBJUAfESkQkWnAw8AoEdkEjLKXARYBW4HNwLPAD/2VK6wkdoern4DCXG2PCLCxA1O4qFdHHvnPRvaXaYO1ap2kNXdVnJOTY3Jzc52OEfwW/cR6PmLKC9B3nNNpwsaW/Ue48i8fMyErjUcnZzsdR6ljRGS5MSanue2CpZFa+dPo30JqNrzxAzi8w+k0YaNHpzi+e1F3XltRyJfbtMFatT5aIMJBw/MRxsAr2h4RSHeO7Enndm349Zv5VFTXOR1HqdOiBSJcJHaDa/4Ghcvh7Z/q+BEBEhMZwUNXD2DjvjK+PeMLSsr14UXVemiBCCf9r4ERP4Ll/4Klf3c6Tdi4on8yT9w4mFUFxUx+egn7SrXHXdU6aIEIN5f/L/SbAO88oA/RBdD4zDRmTh1GweFyJv79c7buP+J0JKWapQUi3LhccN0zkJYNr0yDPaucThQ2RvTsyNzbz6eypo5J/1jC6oJipyMp1SQtEOEoMgZunAtt2sMLU6DU60Pryg8GpSfwyg8uICbSzY3PLOXTTQecjqTUKWmBCFfxKXDTS1BVCi9OgeqjTicKG906xvLqDy4gIzGGqTO/ZMEqLdAqOGmBCGcpA2HSc7B3Dbz6XajX2zADJbltNC9973wGZ7Tn7rkrmfnZNqcjKXUSLRDhrvcYuPJh2PgW/Pd/nU4TVhLaeJg9bRij+iXz4IJ1/Py1NVTVapFWwUMLhILzvgdDv2t1D758ptNpwkq0x81T3zqXH17agxe/3MmNzyylSG+DVUFCC4SyXPkw9LwCFt4H695sfnvVYtwu4adX9uXJm4awfk8Z45/4lOU7DjsdSyktEMrmjoBJ/4L0HJh3C+Q+53SisDMuM5XX77iAaI+bKc8sYa6Oba0cpgVCfS26LXz7Deg1GhbeCx9N1y45AqxvSlvm3zmC4d07cP9ra3jg9TVU1+qgQ8oZWiDU8SJjYMocyJwCH/zW6repXr+gAqldTCQzpw7je5d0Z84XO7np2aUUlWm7hAo8LRDqZG4PXPsUnH+nNY7Ea7dpD7AB5nYJPx/bj8dvHEz+7hKu/MsnvJlXSGsev0W1PloglHcuF4z5HYz6DeS/Ci/eAFXaf1CgXZ2Vxvw7LyQjMYZ75uYxbVYuu4srnI6lwoQWCNW0EffANU/C1g9h9tVw9KDTicJO7+R4XvvBBfxyXD+WbDnI6Mc+5vkl26mv17MJ5V9aIFTzBn8LbpgD+9bCc6Nhd57TicKO2yXcdlF3/nPvxWRntONXb67lhmeWsEV7hVV+pAVC+abvVfDt163LTM+OhA9+r+0SDshIjOH5acOYPimTr/YdYexfP+HJDzbrnU7KL6Q1N3rl5OSY3Nxcp2OEl4rD8Pb9sHouJA+C656ClEFOpwpLRWWVPDR/HW+t2UNibCRXZ6Vx3eDOZKYnICJOx1NBTESWG2Nymt1OC4Q6IxsWwYJ7oOIQXPIzuPBe6+4nFXCfbNrP3GW7eHfdPqpr6+nRKZaJQ9K5dnBnOrdr43Q8FYS0QCj/Kz9kPSex5mVIzbJujU0e4HSqsFVSUcOiNXt4fUUhX24/BMDw7olMHJzOmIEpJLTRAq4sWiBU4Kybbz15XVli3fU0dBq0TXM6VVjbdaic11cW8tqKArYfLMfjFkb07MhVA1MZPSCZdjGRTkdUDtICoQLr6AFY9BNY+xqIC3qNgXNvgZ6jrH6elCOMMawqKGHRmj0sWrOHgsMVRLiE83t04KpBqYzun0yHuCinY6oA0wKhnHFwC6x8HlbOgaNFEJ8K2d+EId+G9l2dThfWjDHkF5ayKN8qFjsOluMSGNo1kcFd2jOocwKDOieQkdhGG7lDnBYI5ay6GvjqHVgxCzb/F0w9dL8MsqZYnQHGJDqdMKwZY1i3p5S31+zlg41FbNxbRq394F3b6AgG2sViYOcEMtMT6JIYo0UjhGiBUMGjpMA6o1j5PJTsAnFDl/Ohz1jr+YrE7k4nDHtVtXVs3FvGmsIS8gtLyS8sYePeMqrrrOcrOsZFkXNOe3K6tienayID0tricetjVK2VFggVfOrrYfdK2LgINr4NRWut9Z36WsWizzhIG6xtFkGiuraer/aVkbermOU7DrNs+yEKDlv9QEV7XGRntGNo10R6JcfTPsZDuzaRtIvx0C7GQ1xUhJ5xBDEtECr4HdoGXy22Csb2z8DUQUQ0JA+0bptteCX1gwhtSA0Ge0sqyd1xiNzth1m+4zBrd5fgrUsot0to18ZDQoyH1IRouiTGck6HGM5JjKFLhxi6JMYQH6233TpFC4RqXSoOw5b3oXAF7FllvapKrfdcHqtIpGZal6PanQPtuliv2CSr51nliKNVtewurqC4oobi8hqKy6utaYU1PVxeTWFxJbsOlXPo6PFdsyTGRtIlMYaUttEktY0iKT6KpPiGeWuaGBOJy6VnIi1NC4Rq3erroXj718VizyrYuwaO7j9+O3cUtMuwikVCBiSkQ9vO1nMYCenWNDLWkV9BHa+0soadB8vZech67ThYzq5D5ewrrWRfaSWllbUn7eMSiPa4aeNxW9NIN9Ee17Hl+OgIkuKjSW4bTUpCFMnx0SQnWMtxUXqp8lRaZYEQkSuBvwJu4J/GmIeb2l4LRBiqPgrFu6B4JxTvsKeNXuUHTt4nOgHapkNckjUfnWANrxqdAFGNlqPiITLu62lkrPXSa+kBUVlTx/6yKorKKikqraKorIoDR6qoqK6jsraOiup6KmvqqKipOzYtraihqLSKsqqTi0tcVATtYz3ERkYQFxVBbFTD1E1sVASxkRFERrhwu8R6iRybd7mECJfgcbuIjHAR6RZ76ramES48biEqwk1URMM2rmPvRbgkqNtgfC0QQVNiRcQNPAmMAgqAZSIy3xizztlkKqhExkJSX+vlTU0llO2B0kIo3W3dQVW621o+UmRNK0ugshRqfRl4R74uFp5oq43EHWm1iTSed0c2ennslz3vapiPsKYuz8nzLg+4IsDltu7ycrkbzTesd52wTYR1eU3s98AuZtJo3v4dxNXoJfbLXj72vr1vw3sN88fW+fcLL9rjJiMxhozEmNPe92hVLftKK9lbahWXvaWV7C2ppLi8miNVdRytqqW4vJqCw+UctZePVNf6bch1l4DH7TpWeFwNhUcEtwvcIkS4XUS4BY/LhSdCiHBZRcfjdlnvuQSXgIg1ddtFx2UvT87JYETPjv75BWxBUyCAYcBmY8xWABGZC1wDaIFQvvNEQ2I369Wc2mqrnaOyBCqLra7Mq4/Y0zLrbOXYujKorYLaSqirtueroKbY+pzaSqivsZ7/qKuxtqmrsdeFWrfoJxYOL8XkuKLj42cemzQuRifMw8nLQCzQHejOqb7xG+0bKRAJ5lgxNfZe1jYnzhtjrzPWlg1FpfF7x88Lxnz9mdZ8w+fZUwOmBkyNWD/dQD2Nf87x8w0afg7A/rh7oedtp/h9W0YwFYjOwK5GywXAeSduJCK3A7cDdOnSJTDJVGiKiISIjhDr37/CMAbqaxsVjBrv8/V11svY0/pae77WapM5aX391/PG/ko59iex+fpnN6w39V9PaViu97K+8T7m5HUnbeNlv4afbeqbLxKNMzd8RuPsJ25z0vIJn3/izzvp8615aXT6II2/hs1JM83k9pbrVFm9LJ+03yl+9gnbdO3rwx9BZymYCoS3/4tOOkrGmGeAZ8Bqg/B3KKXOmsjXl52UakWC6f7AAiCj0XI6sNuhLEopFfaCqUAsA3qJSDcRiQSmAPMdzqSUUmEraC4xGWNqReRO4B2s21yfM8asdTiWUkqFraApEADGmEXAIqdzKKWUCq5LTEoppYKIFgillFJeaYFQSinllRYIpZRSXgVVZ32nS0T2AzvOcPeOgJee3YKCZjszmu3MaLYz05qznWOM6dTch7TqAnE2RCTXl94MnaDZzoxmOzOa7cyEQza9xKSUUsorLRBKKaW8CucC8YzTAZqg2c6MZjszmu3MhHy2sG2DUEop1bRwPoNQSinVhLAsECJypYhsFJHNInK/03kaE5HtIrJGRPJExNEBt0XkOREpEpH8RusSReRdEdlkT9sHUbYHRaTQPnZ5InKVQ9kyROQDEVkvImtF5B57vePHrolsjh87EYkWkS9FZJWd7SF7fTcR+cI+bi/ZvT0HS7aZIrKt0XHLDnS2RhndIrJSRBbay2d/3IwxYfXC6il2C9YIhZHAKqC/07ka5dsOdHQ6h53lYmAIkN9o3Z+A++35+4E/BlG2B4H/CYLjlgoMsefjga+A/sFw7JrI5vixwxo0LM6e9wBfAMOBecAUe/0/gB8EUbaZwCSn/5+zc90HvAAstJfP+riF4xnEsbGvjTHVQMPY1+oExpiPgUMnrL4GmGXPzwKuDWgo2ymyBQVjzB5jzAp7vgxYjzWkruPHrolsjjOWI/aix34ZYCTwir3eqeN2qmxBQUTSgXHAP+1loQWOWzgWCG9jXwfFPxCbAf4jIsvt8beDTbIxZg9YXzZAksN5TnSniKy2L0E5cvmrMRHpCgzG+oszqI7dCdkgCI6dfZkkDygC3sU62y82xtTamzj27/XEbMaYhuP2O/u4PSYiUU5kA/4C/BSot5c70ALHLRwLhE9jXztohDFmCDAWuENELnY6UCvyFNADyAb2AH92MoyIxAGvAj8yxpQ6meVEXrIFxbEzxtQZY7KxhhweBvTztllgU9k/9IRsIjIQ+DnQFxgKJAI/C3QuERkPFBljljde7WXT0z5u4Vgggnrsa2PMbntaBLyO9Y8kmOwTkVQAe1rkcJ5jjDH77H/E9cCzOHjsRMSD9QU8xxjzmr06KI6dt2zBdOzsPMXAh1jX+duJSMPgZo7/e22U7Ur7kp0xxlQB/8KZ4zYCuFpEtmNdMh+JdUZx1sctHAtE0I59LSKxIhLfMA+MBvKb3ivg5gO32PO3AG86mOU4DV++tutw6NjZ139nAOuNMY82esvxY3eqbMFw7ESkk4i0s+fbAFdgtZF8AEyyN3PquHnLtqFRwResa/wBP27GmJ8bY9KNMV2xvs/eN8Z8k5Y4bk63vDvxAq7CuntjC/CA03ka5eqOdVfVKmCt09mAF7EuN9RgnXlNw7q2+R6wyZ4mBlG254E1wGqsL+NUh7JdiHU6vxrIs19XBcOxayKb48cOyARW2hnygV/b67sDXwKbgZeBqCDK9r593PKBf2Pf6eTUC7iUr+9iOuvjpk9SK6WU8iocLzEppZTygRYIpZRSXmmBUEop5ZUWCKWUUl5pgVBKKeWVFgilTkFE/iAil4rItRKgXn/F6s23YyB+llLN0QKh1Kmdh9VP0SXAJw5nUSrgtEAodQIRmS4iq7H611kC3AY8JSK/FpEeIrLY7kzxExHpa+8zU0T+Ya/7yu4fp2EcgX+JNcbHShG5zF7vFpFH7PWrReSuRhHuEpEV9nt9A/zrK3VMRPObKBVejDE/EZGXgW9j9bH/oTFmBICIvAd83xizSUTOA/6O1fcNQFess40ewAci0hO4w/7MQfaX/X9EpDcwFegGDDbG1IpIYqMIB4wxQ0Tkh8D/YBUopQJOC4RS3g3G6oaiL7AOjvWAegHwstX1DgCNu3eeZ6zO7jaJyFZ73wuBJwCMMRtEZAfQG6svn38YuztmY0zjsS0aOvdbDkxs+V9NKd9ogVCqEXvIyJlYvV8eAGKs1ZKHdXZQbKwun705sd8ag/dul7HXn6qfmyp7Wof+G1UO0jYIpRoxxuTZBaBhKM73gTHGmGxjTAmwTUSuB6tqiEhWo92vFxGXiPTA6ihtI/Ax8E17+95AF3v9f4DvN3THfMIlJqWCghYIpU4gIp2Aw/blor7GmHWN3v4mME1EGnrcbTxc7UbgI+BtrHaKSqw2CreIrAFeAr5jrLED/gnsBFbbn3WTv38vpU6X9uaqVAsQkZlY3Sy/0ty2SrUWegahlFLKKz2DUEop5ZWeQSillPJKC4RSSimvtEAopZTySguEUkopr7RAKKWU8koLhFJKKa/+H/oSKyaXLIi8AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(range(max_epoch), rnn_ppl_list)\n",
    "plt.plot(range(max_epoch), lstm_ppl_list)\n",
    "plt.legend([\"RNN\", \"LSTM\"])\n",
    "plt.xlabel(\"#epoch\")\n",
    "plt.ylabel(\"perplexity\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5a9St6Om-Azx"
   },
   "source": [
    "\n",
    "## 提出可否"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V4T4bucL-Azy"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "学習成功です。次のステップに進んでください。\n"
     ]
    }
   ],
   "source": [
    "if rnn_ppl_list[-1] > 10:\n",
    "    print(\"RNNの実装に間違いがあります。問1を見直してください。\")\n",
    "elif lstm_ppl_list[-1] > 5:\n",
    "    print(\"LSTMの実装に間違いがあります。問2を見直してください。\")\n",
    "else:\n",
    "    print(\"学習成功です。次のステップに進んでください。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q2FutIo3-Az0"
   },
   "source": [
    "## GRU\n",
    "### GRUクラス\n",
    "\n",
    "問3-1. <font color=\"Red\">GRUクラスを完成させてください。</font>\n",
    "\n",
    "GRUクラスの仕様はLSTMクラスとほとんど同じです。\n",
    "\n",
    "各ゲートの計算と通常の順伝播の計算に使用するパラメータを行列にまとめ、一行で計算できるように実装しています。\n",
    "\n",
    "r がリセットゲート、zが更新ゲートを表します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J3lrNddh-Az1"
   },
   "outputs": [],
   "source": [
    "class GRU:\n",
    "    def __init__(self, Wx, Wh):\n",
    "        self.params = [Wx, Wh]\n",
    "        self.grads = [np.zeros_like(Wx), np.zeros_like(Wh)]\n",
    "        self.cache = None\n",
    "\n",
    "    def forward(self, x, h_prev):\n",
    "        Wx, Wh = self.params\n",
    "        H, H3 = Wh.shape\n",
    "        Wxz, Wxr, Wx = Wx[:, :H], Wx[:, H:2 * H], Wx[:, 2 * H:]\n",
    "        Whz, Whr, Wh = Wh[:, :H], Wh[:, H:2 * H], Wh[:, 2 * H:]\n",
    "\n",
    "        z = sigmoid(np.dot(x, Wxz) + np.dot(h_prev, Whz))\n",
    "        r = sigmoid(np.dot(x, Wxr) + np.dot(h_prev, Whr))\n",
    "        h_hat = np.tanh(np.dot(x, Wx) + np.dot(r*h_prev, Wh))\n",
    "        print(h_prev.shape,h_hat.shape)\n",
    "        h_next = (1-z)*h_prev + z*h_hat\n",
    "\n",
    "        self.cache = (x, h_prev, z, r, h_hat)\n",
    "\n",
    "        return h_next\n",
    "\n",
    "\n",
    "    def backward(self, dh_next):\n",
    "        Wx, Wh = self.params\n",
    "        H, H3 = Wh.shape\n",
    "        Wxz, Wxr, Wx = Wx[:, :H], Wx[:, H:2 * H], Wx[:, 2 * H:]\n",
    "        Whz, Whr, Wh = Wh[:, :H], Wh[:, H:2 * H], Wh[:, 2 * H:]\n",
    "        x, h_prev, z, r, h_hat = self.cache\n",
    "\n",
    "        dh_hat =dh_next * z\n",
    "        dh_prev = dh_next * (1-z)\n",
    "\n",
    "        dt = dh_hat * (1 - h_hat ** 2)\n",
    "        dWh = np.dot((r * h_prev).T, dt)\n",
    "        dhr = np.dot(dt, Wh.T)\n",
    "        dWx = np.dot(x.T, dt)\n",
    "        dx = np.dot(dt, Wx.T)\n",
    "        dh_prev += r * dhr\n",
    "\n",
    "        dz = dh_next * h_hat - dh_next * h_prev\n",
    "        dt = dz * z * (1-z)\n",
    "        dWhz = np.dot(h_prev.T, dt)\n",
    "        dh_prev += np.dot(dt, Whz.T)\n",
    "        dWxz = np.dot(x.T, dt)\n",
    "        dx += np.dot(dt, Wxz.T)\n",
    "\n",
    "        dr = dhr * h_prev\n",
    "        dt = dr * r * (1-r)\n",
    "        dWhr = np.dot(h_prev.T, dt)\n",
    "        dh_prev += np.dot(dt, Whr.T)\n",
    "        dWxr = np.dot(x.T, dt)\n",
    "        dx += np.dot(dt, Wxr.T)\n",
    "\n",
    "        dWx = np.hstack((dWxz, dWxr, dWx))\n",
    "        dWh = np.hstack((dWhz, dWhr, dWh))\n",
    "        \n",
    "        self.grads[0][...] = dWx\n",
    "        self.grads[1][...] = dWh\n",
    "\n",
    "\n",
    "        return dx, dh_prev\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t7TYSfoi-Az2"
   },
   "source": [
    "### TimeGRUクラス\n",
    "\n",
    "問3-2. <font color=\"Red\">TimeGRUクラスを完成させてください。</font>\n",
    "\n",
    "TimeGRUクラスの仕様はTimeLSTMクラスとほとんど同じです。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-jclSpgq-Az3"
   },
   "outputs": [],
   "source": [
    "class TimeGRU:\n",
    "    def __init__(self, input_size, output_size, stateful=False):\n",
    "        D, H = input_size, output_size\n",
    "        rn = np.random.randn\n",
    "        np.random.seed(0)\n",
    "        \n",
    "        Wx = (rn(D,4*H) / np.sqrt(D)).astype('f') \n",
    "        Wh = (rn(H,4*H) / np.sqrt(H)).astype('f') \n",
    "\n",
    "        self.params = [Wx, Wh]\n",
    "        self.grads = [np.zeros_like(Wx), np.zeros_like(Wh)]\n",
    "        self.layers = None\n",
    "        self.h = None\n",
    "        self.stateful = stateful\n",
    "\n",
    "    def forward(self, xs):\n",
    "        Wx, Wh = self.params\n",
    "        N, T, D = xs.shape\n",
    "        H, H3 = Wh.shape\n",
    "\n",
    "        self.layers = []\n",
    "        hs = np.empty((N, T, H), dtype='f')\n",
    "\n",
    "        if not self.stateful or self.h is None:\n",
    "            self.h = np.zeros((N, H), dtype='f')\n",
    "\n",
    "        for t in range(T):\n",
    "            layer = GRU(*self.params)\n",
    "            self.h = layer.forward(xs[:,t,:],self.h) \n",
    "            hs[:, t, :] = self.h\n",
    "            self.layers.append(layer)\n",
    "\n",
    "        return hs\n",
    "\n",
    "    def backward(self, dhs):\n",
    "        Wx, Wh = self.params\n",
    "        N, T, H = dhs.shape\n",
    "        D = Wx.shape[0]\n",
    "\n",
    "        dxs = np.empty((N, T, D), dtype='f')\n",
    "        grads = [0,0]\n",
    "        dh = 0\n",
    "        for t in reversed(range(T)):\n",
    "            layer = self.layers[t]\n",
    "            dx, dh = layer.backward(dhs[:,t,:]+dh) \n",
    "\n",
    "            dxs[:, t, :] = dx\n",
    "            for i, grad in enumerate(layer.grads):\n",
    "                grads[i] += grad\n",
    "            \n",
    "        for i, grad in enumerate(grads):\n",
    "            self.grads[i][...] = grad\n",
    "\n",
    "        return dxs\n",
    "\n",
    "    def set_state(self, h):\n",
    "        self.h = h\n",
    "\n",
    "    def reset_state(self):\n",
    "        self.h = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UxL7g9mu-Az5"
   },
   "source": [
    "### GRUNetworkクラス\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_vrYrBg--Az6"
   },
   "outputs": [],
   "source": [
    "class GRUNetwork:\n",
    "    def __init__(self, vocab_size=10000, wordvec_size=100, hidden_size=100):\n",
    "        V, D, H = vocab_size, wordvec_size, hidden_size\n",
    "        rn = np.random.randn\n",
    "        np.random.seed(0)\n",
    "\n",
    "        # 重みの初期化\n",
    "        embed_W = (rn(V, D) / 100).astype('f')\n",
    "        affine_W = (rn(H, V) / np.sqrt(H)).astype('f')\n",
    "        affine_b = np.zeros(V).astype('f')\n",
    "\n",
    "        # レイヤの生成\n",
    "        self.layers = [\n",
    "            TimeEmbedding(embed_W),\n",
    "            TimeGRU(D, H, stateful=True),\n",
    "            TimeAffine(affine_W, affine_b)\n",
    "        ]\n",
    "        self.loss_layer = TimeSoftmaxWithLoss()\n",
    "        self.lstm_layer = self.layers[1]\n",
    "\n",
    "        # すべての重みと勾配をリストにまとめる\n",
    "        self.params, self.grads = [], []\n",
    "        for layer in self.layers:\n",
    "            self.params += layer.params\n",
    "            self.grads += layer.grads\n",
    "\n",
    "    def predict(self, xs):\n",
    "        for layer in self.layers:\n",
    "            xs = layer.forward(xs)\n",
    "        return xs\n",
    "\n",
    "    def forward(self, xs, ts):\n",
    "        score = self.predict(xs)\n",
    "        loss = self.loss_layer.forward(score, ts)\n",
    "        return loss\n",
    "\n",
    "    def backward(self, dout=1):\n",
    "        dout = self.loss_layer.backward(dout)\n",
    "        for layer in reversed(self.layers):\n",
    "            dout = layer.backward(dout)\n",
    "        return dout\n",
    "\n",
    "    def reset_state(self):\n",
    "        self.lstm_layer.reset_state()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yxbAcqGa-Az8"
   },
   "source": [
    "## 学習、評価\n",
    "\n",
    "ハイパーパラメータなどは先ほどのRNN・LSTMと全て共通で学習させます。\n",
    "\n",
    "40エポックでperplexity が5以下となっていれば学習成功です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QL1EbV7v-Az9",
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (20,200) (20,100) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-74-5da52586cb90>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;31m# 勾配を求め、パラメータを更新\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmax_grad\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-73-589f3e2580be>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, xs, ts)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-73-589f3e2580be>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, xs)\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m             \u001b[0mxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mxs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-72-4b7db0ef4ff2>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, xs)\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0mlayer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGRU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m             \u001b[0mhs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-69-717195a1470f>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, h_prev)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mWxz\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh_prev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mWhz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mWxr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh_prev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mWhr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mh_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mWx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mh_prev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mWh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh_prev\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mh_hat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mh_next\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mh_prev\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mh_hat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (20,200) (20,100) "
     ]
    }
   ],
   "source": [
    "model = GRUNetwork(vocab_size, wordvec_size, hidden_size)\n",
    "\n",
    "time_idx = 0\n",
    "total_loss = 0\n",
    "loss_count = 0\n",
    "gru_ppl_list = []\n",
    "\n",
    "for epoch in range(max_epoch):\n",
    "    for iter in range(max_iters):\n",
    "        # ミニバッチの取得\n",
    "        batch_x = np.empty((batch_size, time_size), dtype='i')\n",
    "        batch_t = np.empty((batch_size, time_size), dtype='i')\n",
    "        for t in range(time_size):\n",
    "            for i, offset in enumerate(offsets):\n",
    "                batch_x[i, t] = xs[(offset + time_idx) % data_size]\n",
    "                batch_t[i, t] = ts[(offset + time_idx) % data_size]\n",
    "            time_idx += 1\n",
    "\n",
    "        # 勾配を求め、パラメータを更新\n",
    "        loss = model.forward(batch_x, batch_t)\n",
    "        model.backward()\n",
    "        if max_grad is not None:\n",
    "            clip_grads(model.grads, max_grad)\n",
    "\n",
    "        optimizer.update(model.params, model.grads)\n",
    "        total_loss += loss\n",
    "        loss_count += 1\n",
    "\n",
    "    # エポックごとにパープレキシティの評価\n",
    "    ppl = np.exp(total_loss / loss_count)\n",
    "    print('| epoch %d | perplexity %.2f'\n",
    "          % (epoch+1, ppl))\n",
    "    gru_ppl_list.append(float(ppl))\n",
    "    total_loss, loss_count = 0, 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "G80Gpmza-A0A"
   },
   "source": [
    "GRUとLSTM、RNNの学習結果を比較し、GRUがLSTMと同様（若しくはそれ以上）の性能を持っていることを確認してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nyRMCYbX-A0B",
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (40,) and (0,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-75-c3dfe7c52729>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrnn_ppl_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlstm_ppl_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgru_ppl_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"RNN\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"LSTM\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"GRU\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"#epoch\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   3356\u001b[0m                       mplDeprecation)\n\u001b[1;32m   3357\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3358\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3359\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3360\u001b[0m         \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwashold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1853\u001b[0m                         \u001b[0;34m\"the Matplotlib list!)\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlabel_namer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1854\u001b[0m                         RuntimeWarning, stacklevel=2)\n\u001b[0;32m-> 1855\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1856\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1857\u001b[0m         inner.__doc__ = _add_data_doc(inner.__doc__,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_alias_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1527\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m             \u001b[0mlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_grab_next_args\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    404\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 406\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mseg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    407\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mseg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, tup, kwargs)\u001b[0m\n\u001b[1;32m    381\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex_of\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 383\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_xy_from_xy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommand\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'plot'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_xy_from_xy\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m    240\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m             raise ValueError(\"x and y must have same first dimension, but \"\n\u001b[0;32m--> 242\u001b[0;31m                              \"have shapes {} and {}\".format(x.shape, y.shape))\n\u001b[0m\u001b[1;32m    243\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m             raise ValueError(\"x and y can be no greater than 2-D, but have \"\n",
      "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (40,) and (0,)"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3Xl8VOW9x/HPb5YkZCEhkJUkhn0PiwGxVK0oioDgimgXrsXSRVurva322vbq7WZrr3a5asWlgkURFxQoal2oW9nCvu9LEggBskL25Ll/nBMMEMg2ycnM/N6v17zOmTNnJr8c8Tsnz3nO84gxBqWUUoHL5XQBSiml2pcGvVJKBTgNeqWUCnAa9EopFeA06JVSKsBp0CulVIDToFdKqQCnQa+UUgFOg14ppQKcx+kCAHr06GHS09OdLkMppfzK2rVrjxtj4prar1MEfXp6OllZWU6XoZRSfkVEDjZnP226UUqpANesoBeRAyKyWUQ2iEiWvS1WRN4Xkd32spu9XUTkzyKyR0Q2icio9vwFlFJKXVhLzuivNMaMMMZk2s8fBD40xvQDPrSfA1wH9LMfs4GnfVWsUkqplmtL0800YK69Phe4ocH2ecayEogRkaQ2/ByllFJt0NygN8A/RWStiMy2tyUYY44A2Mt4e3tPILvBe3PsbUoppRzQ3F4344wxh0UkHnhfRHZcYF9pZNs5s5vYXxizAdLS0ppZhlJKqZZq1hm9MeawvcwHFgFjgKP1TTL2Mt/ePQdIbfD2FOBwI585xxiTaYzJjItrshuoUkqpVmoy6EUkQkSi6teBa4AtwGJgpr3bTOBte30x8A27981YoLi+iaez+XzPcbYfKXG6DKWUalfNabpJABaJSP3+Lxtj3hWRNcBCEZkFHAJutfdfBkwC9gBlwJ0+r9oHjDHc/fI60rtH8Nbd45wuRyml2k2TQW+M2QcMb2T7CeCqRrYb4G6fVNeO9h0/RVFZNRvKisguKCM1NtzpkpRSql0E7Z2xaw8Wnl5fvPGcSwhKKRUwgjbo1x8qpGuYh5FpMSzRoFdKBbCgDfp1B4sYmdaNacOT2ZFXyu6jpU6XpJRS7SIog76koppd+aWMSuvGpIwkXIKe1SulAlZQBv2GQ0UYA6MuiiE+KoxL+3Rn8cbDWNeRlVIqsARl0K87VIgIjEiNAeD6jGQOnChjS672qVdKBZ4gDfoiBiREERXmBWDi0ES8bmHJJm2+UUoFnqAL+ro6w/pDhYxM63Z6W0x4CJf3i2PJxsPU1WnzjVIqsARd0O85dpLSihouvqjbGduvH57MkeIK1h4qPM87lVLKPwVd0K+zb5QalRZzxvYJgxMI87pYvEGbb5RSgSXogn7twUK6hXvp1SPijO0RoR6uGpjAss1HqKmtc6g6pZTyvaAL+nWHChmV1g17kLYzXD88mROnqvj33hMOVKaUUu0jqIK+qKyKvcdOMeqs9vl6XxkQR2SoJ+Bvntp77CS/WbadWr3wrFRQCKqgX59dBMDIs9rn64V53VwzJIF3t+ZRWVPbkaV1qN8u28GcT/axJ/+k06UopTpAUAX9uoOFuF3C8JTGgx5g6vBkSitq+HjnsQ6srOPsyT/JB9uPArAjT28QUyoYBFfQHypkYGIUEaHnH4Z/XN8edAv3smRTp5wUq82e+3QfoR4XHpewI08HclMqGARN0NfWGTYcKmJUWuPt8/W8bheThiXxwbajlFXVdFB1HSO/tII31+Vyy8Up9ImLZKcGvVJBIWiCfmdeKaeqas+5Uaox1w9Ppry6lg+25ze5rz+Z++8DVNfVcddlvRmYFMUOnS9XqaAQNEG/7lD9jVJNB/3o9FgSuoYG1M1Tpypr+PvKQ1w7OJFePSIYkBjF4eIKisurnS5NKdXOgiroe0SGkBrbpcl93S5hSkYyH+/Kp7gsMILw1TXZFJdXM/uK3gAMSuwKoM03SgWBoAn69YesGaUau1GqMdcPT6a61vDWhtx2rqz9VdfW8fxn+xmd3u30XzQDEqMA2Kk9b5QKeEER9CdOVrL/+Klmtc/XG54SzSW9YnnsvZ3kFJa1Y3Xtb9nmI+QWlTP78j6ntyVFh9E1zKM9b5QKAkER9OsPWTdKNad9vp6I8Idbh1NnDA+8sclvhy82xvDMx/voExfBVQPjT28XEQYmdtWgVyoIBEXQrztUiMclZKREt+h9qbHh/GzyYD7fc4L5qw62U3Xt6/M9J9h2pIRvXdYbl+vMZquBSVHszCvVKRSVCnBBEfRrDxYyJLkrYV53i997+5hULu8fx2+W7eDA8VPtUF37euaTvfSIDOWGkT3PeW1AYhQnK2vIKSx3oDKlVEcJ+KCvqa1jU07xGTNKtYSI8PubM/C6hf98baNfDQS27XAJn+4+zp3j0hv9kht4+oKsNt8oFcgCPuh35JVSXl173hErmyMxOoxHpg0h62Ahz3+2z4fVta9nP91HeIibr11yUaOv90+wgl7HvFEqsAV80K+1Z5RqSY+bxtwwoifXDkngD+/tYtfRzn8GfLionCUbD3Pb6FSiw72N7hMV5iWlWxe9IKtUgAv4oF93qJCErqEkR4e16XNEhF/fOIzIMA8/WriR6iZmoaqureP4yco2/cy2eOGz/Rhg1pd7XXC/gYldtelGqQAXFEF/vhmlWqpHZCi/uXEom3OLefpfe8953RjD2oMF/OLtLYz9zYdc+tsPyTpQ0Oaf21IHT5zildWHmDwsiZRu4Rfcd2BiFPuOnwro8feVCnYBHfT5pRVkF5S3udmmoYlDk5g2Ipk/f7ibLbnFAOw6Wspj7+3gst8v5+anV/DqmmzG9ulOckwXvjd/HfmlFT77+RdSV2eYt+IA1/3pU1wi3DO+b5PvGZgURW2d0UlIlApg5x+Y/Swi4gaygFxjzBQR6QUsAGKBdcDXjTFVIhIKzAMuBk4AtxljDvi88mZYd7B+RinfBT3AI1OHsGLvCe5+eR1dvG525JXidgnj+vbg/gn9uWZIIpGhHrYfKeHGpz7nnvnrmf+tS/C62+97NbugjB+/vpGV+wq4vH8cj940jOSYpsf1qe95s+NIKUOSW3afgVLKP7Qkee4Ftjd4/jvgCWNMP6AQmGVvnwUUGmP6Ak/Y+zli1f4ThLhdDO3Z1aefGxMewu9uySC3sJwuIW4emTqElT+9innfHMNNo1KItCc2GZTUld/dnMHqAwX8dtkOn9ZQr67O8NKKA1z7x0/YklvCozcNY+6do5sV8gDp3SMI8bjY6QcXmJVSrdOsM3oRSQEmA78G7herwXs8cIe9y1zgYeBpYJq9DvA68H8iIqaDb7/8YNtR5q04yLVDEgj1tPxGqaZcOSCerf9zbZOfPW1ET9YfKuKFz/czPDWaaSPOvXGptbILyvjJ65tYse8El/XrwaM3Z9CzmQFfz+N20S8+UnveKBXAmtt080fgJ0CU/bw7UGSMqZ+CKQeoT7CeQDaAMaZGRIrt/Y/7pOJmWHOggLtfXsfQ5K48dsvwdvs5zf0CeWjyILYeLubBNzYzIDGKgYlt/wvj5VWH+NU/tuES4bc3DWPG6NRWX3AekBjFZ7s77D+PUqqDNdl0IyJTgHxjzNqGmxvZ1TTjtYafO1tEskQk69gx303EvSOvhFkvrqFnTBde+I/RF5wftqN43S6evGMUkWEevvPS2jZP9vHk8j3816LNjErrxnv3Xc7tY9La1KtoUGJX8ksrKThV1aa6lFKdU3Pa6McBU0XkANbF1/FYZ/gxIlKfoilA/XRMOUAqgP16NHBOH0NjzBxjTKYxJjMuLq5Nv0S97IIyZr6wmi4hbubNGkP3yFCffK4vxHcN4+mvjiKnsJwfLdzQ6tEwn/1kH4+9t5MbR/Zk7jfHtLippjH1Y9PrHbJKBaYmg94Y81NjTIoxJh2YAXxkjPkqsBy4xd5tJvC2vb7Yfo79+kcd0T5/4mQlM19YTXlVLfO+eUmT/cedkJkey88mD+KD7fk8uXxPi9//4uf7+fWy7UzOSOKxWzJwu9p+bwBYXSxBx7xRKlC1pb/fA1gXZvdgtcE/b29/Huhub78feLBtJTbtZGUNd764htyicp7/j9Gnz1A7o5lfSueGEck8/sEulu9s/uTj81cd5OEl27h2SAJ/vG0EHh921YyLDCU2IkSDXqkA1aIGbGPMv4B/2ev7gDGN7FMB3OqD2pqlqqaO77y0lq2HS3jmaxczOj22o350q4gIv70pgx15pcx6cQ3TRvTk7iv70jc+8rzvWbgmm4cWbWH8wHj+cvson/fHtyYhiWK7Br1SAcmv74ytqzPcv3ADn+05zqM3DePqwQlOl9QsXULcvPytsdx1WW/e3ZLHhCc+5vuvrG/0jHrR+hweeHMTl/XrwVNfHUWIp33+kw1IjGJXXqnfzqSllDo/vw76v3y0h6WbjvDgdQO5NTPV6XJaJDYihP+aNIjPHriS71zRh4+2H+XaP37Cd/++lq2HraEVlm46zI8WbuTS3t159huZrZo4pbkGJXalvLqWQwX+PT+uUupczvc9bIPbL0klMszDN8elO11Kq3WPDOWBiQOZfVlv/vb5fv72+QHe2ZLHuL7dWbmvgMyLYnluZvuGPDTseVNKeo+Idv1ZSqmO5ddn9PFRYcz6ci+fjEzptG4RIdx/zQA+e3A890/oz5bcEkakxvDCnaMJD2n/7+P+CVGIaBdLpQKRX5/RB6LoLl5+cFU/vnNFH1yCT3vXXEiXEDfp3SO0541SAUiDvpNqr4uuFzIgIUqDXqkA5NdNN8q3BiZFsf/EKcqrdBISpQKJBr06bWBiFMbA7nw9q1cqkGjQq9PqR9XccUSDXqlAokGvTkuLDT89Y5ZSKnBo0KvTXC6hf2IUO49qF0ulAokGvTrDwIQobbpRKsBo0KszDEiM4sSpKo6VVjpdilLKRzTo1Rnqx6bXO2SVChwa9OoM9T1v9MYppQKHBr06Q2xECPFRoWzXdnqlAoYGvTrHgMQoNuUUUatj0ysVEDTo1TkmD0tid/5JHnxjk05EolQA0EHN1DlmjEnjcHEFf/5wNyEeF7+6YWhADAWtVLDSoFeNuu/qflTV1PHXj/fidbv47+sHa9gr5ac06FWjRIQHJg6guraO5z/bT4jHxU+vG6hhr5Qf0jZ6dV4iws8mD+Ibl17EnE/28Yd/7sSYtrXZ5xaV87O3NpNfUuGjKpVSTdEzenVBIsLD1w+huraOJ5fvJcTt5t6r+7Xqsw6eOMUdz64it6icyFAvD1430MfVKqUao2f0qkkul/DrG4Zx86gUnvhgF0/9a0+LP2PvsZNMf2YFp6pqyEiJ5o11OdTU1rVDtUqps2nQq2ZxuYTf35LB1OHJ/P7dnTz23g4qqps3E9XOvFJue2YltXWGBbPHcs+VfTlWWsnHu461c9VKKdCgVy3gdgmPTx/OzaNSeHL5Xq5+/GPe2Xzkgu32W3KLmTFnBW4XLJh9KQMTu3LlwHh6RIbw6prsDqxeqeClQa9axON28b/Th/PyXZcQGerhu/PXccezq9h+5NxB0NYfKuT2Z1cSHuJh4bcvpW98JABet4ubRqXw0Y58HSVTqQ6gQa9a5Ut9e7D0+1/mlzcMZXteCZP//Ck/e2szBaeqAFi9v4CvPbeK2IgQXv32WC7qHnHG+6dnplBTZ3hrfa4T5SsVVKSt3eV8ITMz02RlZTldhmqlorIq/vjBbl5aeZCIEDe3X5LGvH8fJDkmjPl3jSUxOqzR99301OeUVtTwz/su1/75SrWCiKw1xmQ2tZ+e0as2iwkP4eGpQ3j33ssYnhrDMx/v46Lu4SyYfel5Qx5gemYqu/NPsiG7qAOrVSr4aD965TP9EqKY980xrDtURL+ESLqGeS+4/+SMJB5Zso2FWdmMTOvWQVUqFXz0jF75lIhw8UXdmgx5gKgwL5OGJbFk4xHKqmo6oDqlglOTQS8iYSKyWkQ2ishWEXnE3t5LRFaJyG4ReVVEQuztofbzPfbr6e37Kyh/Nj0zhZOVNbyzOc/pUpQKWM05o68ExhtjhgMjgIkiMhb4HfCEMaYfUAjMsvefBRQaY/oCT9j7KdWoMb1iSe8ezsIs7VOvVHtpMuiN5aT91Gs/DDAeeN3ePhe4wV6fZj/Hfv0q0S4V6jxEhFszU1m1v4ADx085XY5SAalZbfQi4haRDUA+8D6wFygyxtQ3rOYAPe31nkA2gP16MdC9kc+cLSJZIpJ17JjeCh/Mbh6VgkvgtbV6Vq9Ue2hW0Btjao0xI4AUYAwwqLHd7GVjZ+/ndNY3xswxxmQaYzLj4uKaW68KQInRYVzRP47X1+boPLVKtYMW9boxxhQB/wLGAjEiUt89MwU4bK/nAKkA9uvRQIEvilWBa3pmKkdLKvlkt/51p5SvNafXTZyIxNjrXYCrge3AcuAWe7eZwNv2+mL7OfbrH5nOcPut6tSuGpRAbEQIr+lFWaV8rjln9EnAchHZBKwB3jfGLAUeAO4XkT1YbfDP2/s/D3S3t98PPOj7slWgCfG4uHFkT97fdvT0eDlKKd9o8s5YY8wmYGQj2/dhtdefvb0CuNUn1amgMj0zlec/28+i9bnM+nIvp8tRKmDonbGq0xiQGMXwlGhey8pu89y0Sqkv+H/QayAElFszU9mRV8q2Rsa3V0q1jn8H/YaX4a9fhtpqpytRPjJpWBJul7B00xGnS1EqYPh30Id2haNbYO9ypytRPhIbEcK4vj1YuumwNt8o5SP+HfT9roEu3WDTq05XonxoSkYS2QXlbMopdroUpQKCfwe9JwSG3Ag7/gGVpU5Xo3zk2sGJeN3C0k2Hm95ZKdUk/w56gIzboKYcti91uhLlI9HhXi7vF8c/Nh2hTodEUKrN/D/oUy+BmItg0wKnK1E+NGV4EoeLK1ifXeh0KUr5Pf8PehHrrH7fx1CiPTUCxdWDEgjxuFiyUf+bKtVW/h/0YAU9Bra83uSuyj9EhXm5ckAcyzYf0REtlWqjwAj6Hn2h58WwUXvfBJIpGcnkl1ay5oAOfqpUWwRG0IN1Vn90Mxzd6nQlykeuGhRPF69be98o1UaBE/RDbgJxw6aFTleifCQ8xMP4QfG8szmPmto6p8tRym8FTtBHxkHfq2Hza1CnoRAors9I4sSpKlbu0+YbpVorcIIeIGM6lOTCwc+crkT5yFcGxBMRos03SrVFYAX9gEkQEqVDIgSQMK+bCYMTeHdrHtXafKNUqwRW0IeEw+CpsG0xVJc7XY3ykSkZyRSVVfPZnuNOl6KUXwqsoAer+aayBHa+43Qlykcu69+DqDAPS/XmKaVaJfCCPv0yiErW3jcBJNTj5tohifxzWx6VNbVOl6OU3wm8oHe5YdgtsOd9OKV/6geKKRlJlFbU8Mku/W+qVEsFXtCDdfNUXQ1sXeR0JcpHxvXtQbdwr/a+UaoVAjPoE4dCwlDtfRNAvG4XE4cm8sG2o1RUa/ONUi0RmEEP1kXZnDVwYq/TlSgfmZKRzKmqWpbvyHe6FKX8SuAG/dBbANGLsgHkkl6x9IgM0YnDlWqhwA366J7Q+wpY8ywc2+V0NcoHPG4Xk4Yl8cH2oxSXVTtdjlJ+I3CDHmDSH6yBzuZeD8f3OF2N8oHpmalU1tTx1oZcp0tRym8EdtD36Aczl1g9cOZO0fb6ADC0ZzTDekbzyupDGKMTkijVHIEd9ADxA62wr62yzuwL9jtdkWqjGWNS2ZFXyobsIqdLUcovBH7QAyQMhm8shuoyK+wLDzpdkWqDqcOT6eJ1s2B1ttOlKOUXgiPowepb/423obLUasYpOuR0RaqVosK8TB2ezJJNhymt0IuySjUleIIeIGk4fOMtKC+2zuyLc5yuSLXSjDGplFXVsnij3imrVFOaDHoRSRWR5SKyXUS2isi99vZYEXlfRHbby272dhGRP4vIHhHZJCKj2vuXaJHkkfD1RVBWAC9OgRINCn80IjWGgYlR2nyjVDM054y+BviRMWYQMBa4W0QGAw8CHxpj+gEf2s8BrgP62Y/ZwNM+r7qtUi6Gr71pDXr2/DWQt8XpilQLiQgzRqeyObeYLbnFTpejVKfWZNAbY44YY9bZ66XAdqAnMA2Ya+82F7jBXp8GzDOWlUCMiCT5vPK2Sh0N/7HU6nr5wrWw812nK1ItdOPIFEI9Ll5ZrddblLqQFrXRi0g6MBJYBSQYY46A9WUAxNu79QQa/j2dY2/rfJJHwLc+gu594ZUZ8O//A+2b7Teiw71MHpbE2xsOU1ZV43Q5SnVazQ56EYkE3gB+aIwpudCujWw7Jz1FZLaIZIlI1rFjx5pbhu91TYY734FB18M/H4Il90JNlXP1qBaZMSaNk5U1Ov6NUhfQrKAXES9WyM83xrxpbz5a3yRjL+uHFMwBUhu8PQU454qnMWaOMSbTGJMZFxfX2vp9IyQcbp0Ll/0I1s2Fv99kXaxVnd7o9G70iYvQ5hulLqA5vW4EeB7Ybox5vMFLi4GZ9vpM4O0G279h974ZCxTXN/F0ai4XXPULuPEZyF4Fz12t4+P4ARHh9jFprD9UxM68UqfLUapTas4Z/Tjg68B4EdlgPyYBjwITRGQ3MMF+DrAM2AfsAZ4Fvuf7stvR8BnWkAkVRfDceNj9vtMVqSbcNCqFELdelFXqfKQzDAyVmZlpsrKynC7jTIUHYMFX4egWGPs9uPph8IQ6XJQ6n3teXsenu4+z6r+uIszrdrocpTqEiKw1xmQ2tV9w3RnbEt3S4a4PYcy3YeVT8OxVcGyn01Wp87hjTBrF5dW8s6XztxIq1dE06C/EGwaTfg+3vwqlh+GZKyDrb9oFsxMa27s7F3UP5xW9U1apc2jQN8eAifDdf0PaWFj6Q1j4de2V08m4XMJto1NZvb+AvcdOOl2OUp2KBn1zRSVawyZM+KV1F+3T42D/p05XpRq45eIUPC5h/kq9KKtUQxr0LeFywbgfwF3vg7eLNQLmupecrkrZ4qPCmDoimXkrDuj4N0o1oEHfGskj4dufQJ/xsPgeWDfP6YqU7eeTB9MtIoQfLdxIZU2t0+Uo1Slo0LdWaCTMeBn6Xg2Lvw9r5zb9HtXuukWE8PubM9h5tJTH39/ldDlKdQoa9G3hDYPb5kPfCbDkB7D2RacrUsCVA+OZMTqVOZ/sY+1BvWiulAZ9W3nD4La/Q79rrAHRsv7mdEUK+NmUwfSM6cL9CzfqyJYq6GnQ+0LDsF/6Q8h6wemKgl5kqIc/3DqcQwVl/HbZDqfLUcpRGvS+4gm1w/5aWHofrHne6YqC3tje3fnmuF68tPIgn+52cChspRymQe9LnlC47SXoPxH+cT+sec7pioLej68dQN/4SH782iaKy6udLkcpR2jQ+5onFKbPg/7XwT9+BFvebPo9qt2Eed08Pn04x05W8sjirU6Xo5QjNOjbgycUbn0R0i6FRd+BQyudriioZaTEcPeVfXlzfS7vbslzuhylOpwGfXvxhln97KNT4JXb4cRepysKat8f35ehPbvy0KLNHD9Z6XQ5SnUoDfr2FB4LX33NWp9/qw6E5iCv28Xj00dQWlHDr/+x3elylOpQGvTtrXsfuH0BFOfAgjugusLpioJW/4Qo7rqsF4vW57Ihu8jpcpTqMBr0HSHtErjpGTi0At7+HtTVOV1R0PrelX3pERnKL5duozPMrqZUR9Cg7yhDboSrH4Etb8BHv3S6mqAVGerhP6/pz9qDhSzdpLNRqeCgQd+Rxt0LF98Jnz2ug6A56NbMVAYldeXRd3ZQUa0jXKrAp0HfkURg0h+sES+X3gd7PnS6oqDkdgk/nzKI3KJynv9sv9PlKNXuNOg7mttj9bGPHwyv3QlFOhuSE77UpwcTBifw1PI95JfqBXIV2DTonRAaZQ2VYOrgjW9BrY6u6IT/mjSIqto6/vc9HbdeBTYNeqfE9oIpT0D2SvjkMaerCUq9ekQw89J0Fq7NZuthnXpQBS4Neidl3ArDb4dPfg8H/+10NUHp+1f1I6aLl18t3a7dLVXA0qB32qTHoFu61YSjd852uOguXu6b0J8V+07w/rajTpejVLvQoHdaaBTc/DycPGpNR6hnlR3ujjFp9IuP5DfLtlNVozezqcCjQd8Z9BwFV/0Cti/ReWcd4HG7eGjyIA6cKGPeigNOl6OUz2nQdxaX3gN9xsO7P4V8nfquo31lQDxX9I/jTx/upuBUldPlKOVTGvSdhcsFN/wVQiLg9W/q4GcO+NnkQZRX1fLYe/pFqwKLBn1nEpUAN/4V8rfC+z93upqg0y8hijvHpbNgTTbrDxU6XY5SPtNk0IvICyKSLyJbGmyLFZH3RWS3vexmbxcR+bOI7BGRTSIyqj2LD0j9JsDY78HqObBjmdPVBJ17r+5PfFQov3h7K7V1emFcBYbmnNG/CEw8a9uDwIfGmH7Ah/ZzgOuAfvZjNvC0b8oMMlc/DIkZ1pDGRdlOVxNUIkM9PDR5MJtzi3l5tQ5PoQJDk0FvjPkEOLuD9zSgfvjFucANDbbPM5aVQIyIJPmq2KBRP+dsbY3VXl9b7XRFQeX6jCS+1Kc7j727gxM67aAKAK1to08wxhwBsJfx9vaeQMNT0Bx7m2qp7n1g6p8hZzV8+IjT1QQVEeF/pg2hrKqW372rF2aV//P1xVhpZFujDZ0iMltEskQk69ixYz4uI0AMvQlG3wX//gvsfMfpaoJK3/goZl3Wi4VZOaw9qHcsK//W2qA/Wt8kYy/z7e05QGqD/VKAw419gDFmjjEm0xiTGRcX18oygsA1v7ba6xd9R4c07mA/GN+PpOgwfv7WVmpq9Y5Z5b9aG/SLgZn2+kzg7Qbbv2H3vhkLFNc38ahW8obB9LnWkMav3Qk1ejNPR4kI9fDzKYPZdqSE+av0S1b5r+Z0r3wFWAEMEJEcEZkFPApMEJHdwAT7OcAyYB+wB3gW+F67VB1sYnvD1L9Abpa213ew64Ymclm/Hvzhnzs5VqoXZpV/ks4wNGtmZqbJyspyuozOb9mPrf71M16GgZOdriZo7D12kol//ITrhyfz+PQRTpej1GkistYYk9nUfnpnrD+55leQNALe+i4UHnS6mqDRJy6Sb13WmzfX5bJ6v16YVf5Hg96f1PevNwZe1/b6jnTP+L4AVZVQAAAOw0lEQVT0jOnCL97eQnlVrdPlKNUiGvT+JrYXTPs/yF0L7/xEx6/vIOEhHh6ZOoSdR0v5+vOrKC7Tm9iU/9Cg90eDp8G4H8Lav8HKp5yuJmhcPTiBv9w+ko05RUx/ZgVHS3SEUeUfNOj91VX/DYOuh/ce0pupOtCUjGRevHMMOYVl3PTUv9l37KTTJSnVJA16f+VywY1zIHkEvD4Ljmx0uqKgMa5vDxbMvpSK6lpu+esKNuUUOV2SUhekQe/PQsLh9gXQpRu8PANKGr0JWbWDYSnRvP7dLxEe4ub2OSv5bPdxp0tS6rw06P1dVCLc8SpUlsArM6DqlNMVBY1ePSJ447tfIjU2nDtfXM2SjfpFqzonDfpAkDgUbnkB8jbDG9+COu3+11ESuobx6rcvZWRqN36wYD0vfr7f6ZKUOocGfaDofy1MfBR2/gM++G+nqwkq0V28zJs1hgmDEnh4yTZ++uZmKmv0y1Z1Hhr0geSSb8Pob1nDGq990elqgkqY183TX7uY732lD6+sPsTtc1aSr90vVSehQR9oJj4Kfa+GpffDtreb3l/5jNsl/GTiQJ68YxTbj5Qy5S+fsfagTjKunKdBH2jcHrjlb5CSCQtnQtYLTlcUdCZnJLHo7i8R5nUzY84KFujcs8phGvSBKKwrfP0t6HcNLL0PPn5Mh0roYAMTu7L4nnGM7d2dB9/czEOLNlNVo5OXKGdo0AeqkHCYMR8yZsDyX1nj4tRp0HSkmPAQXrxzDN++ojfzVx3ijmdXkl+q7faq42nQBzK3F254Gi69xxrH/s27dMTLDuZ2CT+9bhB/vn0kWw4XM/GPn/L2hlw6wzwQKnho0Ac6lwuu/TVM+B/Y8ga8chtU6vgsHW3q8GQW3/NlUmPDuXfBBmbNzeJwUbnTZakgoUEfLMbdC9OehH3/gnlT4dQJpysKOv0Tonjzu1/iZ5MHsWLvCa554hNeWnGAujo9u1ftS4M+mIz8Gtw2H45uhReugcMbnK4o6Lhdwl2X9eaf913OiNQYfv72Vm6bs4K9Ogqmakca9MFm4CT4+iKr+ebZ8bD8N9pu74DU2HBemjWGx27JYNfRk1z3p095cvke7Zmj2oVODh6sygvhnQdh0wJIGAY3Pg2Jw5yuKijll1bwyOJt/GPzEWIjQpg6PJkbR/YkIyUaEXG6PNWJNXdycA36YLdjGSy5F8oL4IoH4Mv3Wb11VIf7dPcxFqzJ5v1tR6mqqaNPXAQ3jUrhhpE96RnTxenyVCekQa+ar6zA6me/+TVIGm51yUwY4nRVQau4vJplm4+waF0uqw8UADC2dyw3jUzh2qGJRHfRL2Jl0aBXLbdtsXUnbUWx1Utn9Czomux0VUEtu6CMRetzeXNdDgdOlOF1C+P69mDS0CSuGZJATHiI0yUqB2nQq9Y5dRyW/Ri2vgnign7XwsUzoe8Eaxwd5QhjDBtzilm2+QjLNh8hp7Acj0u4tE93Jg1L4prBCXSPDHW6TNXBNOhV25zYC+tfgvXz4VQ+RCXBiK/CqK9Dt3Snqwtqxhi25JawbIsV+gdPlOESGJ0ey8i0bgzrGc2wntGkxnbRi7kBToNe+UZtNex6D9bNhT0fgKmD3lfC8BnWoGnhsU5XGNSMMWw7UsI7m/NYvjOfnXml1Ng3YHUN8zDUDv2hPaPJSIkmLTZcwz+AaNAr3yvOsc7w178Exdkgbki7FAZcZ/XPj+3tdIVBr7Kmlp15pWzOLWZLbglbcovZmVdKVa3VP79HZCiZF3UjM70bmemxDEnuitett9P4Kw161X7q6uDweti5DHa+A/lbre1xA63QHzAZkkdqm34nUVVTx66jpWzILmLtwULWHCggp9AaZyfM62JEagyj02PplxBFt3AvMV1CiAn3EhPuJTLUo38BdGIa9KrjFOyHXe9awX/gczC14AmDhKFWd836R/wg8OgFw84gr7iCrIMFZB0oZO3BQrYeLqaxIXfcLiGmi5focC9J0WGkxUZwUfdwLooNJ617OGmx4USFaXdPp2jQK2eUF8LejyB3HRzZaD0qS6zXXF4r7JMyrGaemIsgJs16RMRbI20qR5yqrOFwUTlF5dUUlVVTVFZlLcutZWFZFblFFWQXlFFw6swhM2IjQkiLDSexaxjxXUOJjwolPqp+3VrGhofgculfBr6mQa86h7o6KDrwRegf2Qh5m+HUsTP3c4dCTKoV+tGpEJ0CXXta/fijU6xlSIQjv4I6U0lFNYdOlHGowHocPFFGdkEZR0sqOFpSQUlFzTnvcYk1gXoXr9tahrgJ87pOP48K8xAfFUZC1zASo0NJiAojIdp6HhmqTYDn42jQi8hE4E+AG3jOGPPohfbXoA9CVaegKBuKDkHRQXvZ4FF2/Nz3hEVD1xSIjLfWw6KtaRPDoiG0wfPQKAiJ/GIZEmE9tK25Q1RU13KstJL80grySyrJL63k+MlKyqtqqaippbyqjorqWsqra08vS8qryS+ppLTy3C+JyFAP3SK8RIR4iAz1EBFav3QTEeohIsRDiMeF2yXWQ+T0ussleFyC1+0ixOMixC320m0tPS68biHU4ybUU7+P6/RrHpd06msUzQ16n39ViogbeBKYAOQAa0RksTFmm69/lvJjIREQP9B6NKa6AkqPQEkulBy2evyUHLaen8y3lhXFUFECNc2ZwEO+CH1vmHUNwR1iXTNouO4OafDw2g973VW/7rGWLu+56y4vuDzgclu9klzuBuv1211n7eOxmq3Efg3sLyVpsG7/DuJq8BD7YT8//br93vrX6tdPb2vf4ArzukmNDSc1NrzF7z1VWcPRkgrySqwvibySCvKKKygqq+JkZS2nKmsoKqsip7CMU/bzk1U17TYlskvA63ad/gJx1X+BiOB2gVsEj9uFxy14XS68HsHjsr48vG6X9ZpLcAmIWEu3/eXhsp9Pz0xlXN8e7fML2Nrjb6IxwB5jzD4AEVkATAM06FXzecMgtpf1aEpNlXUdoKIYKoqsIZirTtrLUuuvh9PbSqGmEmoqoLbKXq+E6iLrc2oqoK7aun+gttrap7ba3hZowzmf/QXQyJfCGV8ezfzM04uGXypnrcO5z4EIoDfQm/Mld4P3hgiEgDn9pWjsd1n7nL1ujL3NWHvWfzk0fO3MdcGYLz7TWq//PHtpwFSDqRbrpxuoo+HPOXO9Xv3PATgWeR/0ves8v69vtEfQ9wSyGzzPAS45eycRmQ3MBkhLS2uHMlTQ8ISApwdEtO9ZEcZAXU2D4K9ufL2u1noYe1lXY6/XWNcsztle98W6saPh9Cmq+eJn1283dV8sqX9e18j2hu8x5247Z59G3lf/s01d02HfsOb6z2hY+9n7nPP8rM8/++ed8/nWujQ4nZeGcWrOWWmi7sbqOl+tjTw/533n+dln7ZM+sBknM23UHkHf2L+Gc35bY8wcYA5YbfTtUIdSviXyRXOOUn6kPfqz5QCpDZ6nAIfb4ecopZRqhvYI+jVAPxHpJSIhwAxgcTv8HKWUUs3g86YbY0yNiNwDvIfVvfIFY8xWX/8cpZRSzdMudyIYY5YBy9rjs5VSSrWM3nOulFIBToNeKaUCnAa9UkoFOA16pZQKcJ1i9EoROQYcbOXbewCNjIDVKWhtraO1tY7W1jr+XNtFxpi4pj6kUwR9W4hIVnNGb3OC1tY6WlvraG2tEwy1adONUkoFOA16pZQKcIEQ9HOcLuACtLbW0dpaR2trnYCvze/b6JVSSl1YIJzRK6WUugC/DnoRmSgiO0Vkj4g86HQ9DYnIARHZLCIbRMTRCXFF5AURyReRLQ22xYrI+yKy215260S1PSwiufax2yAikxyqLVVElovIdhHZKiL32tsdP3YXqM3xYyciYSKyWkQ22rU9Ym/vJSKr7OP2qj26bWep7UUR2d/guI3o6Noa1OgWkfUistR+3vbjZozxywfWyJh7sWYeCwE2AoOdrqtBfQeAHk7XYddyOTAK2NJg2++BB+31B4HfdaLaHgb+sxMctyRglL0eBewCBneGY3eB2hw/dliTD0Xa615gFTAWWAjMsLf/FfhuJ6rtReAWp//N2XXdD7wMLLWft/m4+fMZ/em5aY0xVUD93LTqLMaYT4CCszZPA+ba63OBGzq0KNt5ausUjDFHjDHr7PVSYDvWVJmOH7sL1OY4YzlpP/XaDwOMB163tzt13M5XW6cgIinAZOA5+7ngg+Pmz0Hf2Ny0neIfus0A/xSRtfb8uJ1NgjHmCFihAcQ7XM/Z7hGRTXbTjiPNSg2JSDowEusMsFMdu7Nqg05w7Ozmhw1APvA+1l/fRcaYGnsXx/5/Pbs2Y0z9cfu1fdyeEJFQJ2oD/gj8BGuOcYDu+OC4+XPQN2tuWgeNM8aMAq4D7haRy50uyI88DfQBRgBHgP91shgRiQTeAH5ojClxspazNVJbpzh2xphaY8wIrKlExwCDGtutY6uyf+hZtYnIUOCnwEBgNBALPNDRdYnIFCDfGLO24eZGdm3xcfPnoO/Uc9MaYw7by3xgEdY/9s7kqIgkAdjLfIfrOc0Yc9T+n7EOeBYHj52IeLGCdL4x5k17c6c4do3V1pmOnV1PEfAvrHbwGBGpn+zI8f9fG9Q20W4KM8aYSuBvOHPcxgFTReQAVlP0eKwz/DYfN38O+k47N62IRIhIVP06cA2w5cLv6nCLgZn2+kzgbQdrOUN9iNpuxKFjZ7ePPg9sN8Y83uAlx4/d+WrrDMdOROJEJMZe7wJcjXUNYTlwi72bU8etsdp2NPjiFqw28A4/bsaYnxpjUowx6Vh59pEx5qv44rg5fYW5jVenJ2H1NtgLPOR0PQ3q6o3VC2gjsNXp2oBXsP6Mr8b6S2gWVtvfh8BuexnbiWp7CdgMbMIK1SSHavsy1p/Jm4AN9mNSZzh2F6jN8WMHZADr7Rq2AL+wt/cGVgN7gNeA0E5U20f2cdsC/B27Z45TD+ArfNHrps3HTe+MVUqpAOfPTTdKKaWaQYNeKaUCnAa9UkoFOA16pZQKcBr0SikV4DTolVIqwGnQK6VUgNOgV0qpAPf/YUd8ghPN5C0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(range(max_epoch), rnn_ppl_list)\n",
    "plt.plot(range(max_epoch), lstm_ppl_list)\n",
    "plt.plot(range(max_epoch), gru_ppl_list)\n",
    "plt.legend([\"RNN\", \"LSTM\", \"GRU\"])\n",
    "plt.xlabel(\"#epoch\")\n",
    "plt.ylabel(\"perplexity\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8-QQl5QZ-A0D"
   },
   "source": [
    "\n",
    "## 提出可否"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lpWhGBYN-A0D"
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-76-034c64ebf1b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mif\u001b[0m \u001b[0mgru_ppl_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"GRUの実装に間違いがあります。問3を見直してください。\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"学習成功です。次のステップに進んでください。\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "if gru_ppl_list[-1] > 5:\n",
    "    print(\"GRUの実装に間違いがあります。問3を見直してください。\")\n",
    "else:\n",
    "    print(\"学習成功です。次のステップに進んでください。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g9ZeqQfS-A0F"
   },
   "source": [
    "## Classification\n",
    "では実際にRNNやLSTMを用いて実践的な問題を解いていきましょう。\n",
    "\n",
    "今回解いていくタスクは二値分類なので、まずは出力層の活性化と損失関数をつなげたSigmoidWithLossクラスを定義します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3vrQMLkm-A0F"
   },
   "outputs": [],
   "source": [
    "class SigmoidWithLoss:\n",
    "    def __init__(self):\n",
    "        self.params, self.grads = [], []\n",
    "        self.loss = None\n",
    "        self.y = None\n",
    "        self.t = None\n",
    "        \n",
    "    def forward(self, x, t):\n",
    "        self.t = t\n",
    "        x = x.flatten()\n",
    "        self.y = sigmoid(x)\n",
    "        self.loss = -np.mean(np.log(self.y + 1e-7) * t + np.log(1 - self.y + 1e-7) * (1 - t))\n",
    "        return self.loss\n",
    "    \n",
    "    def backward(self, dout=1):\n",
    "        batch_size = self.t.shape[0]\n",
    "        dx = (self.y - self.t)/batch_size\n",
    "        dx = dx.reshape(-1,1)\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p0r8DMHJ-A0H"
   },
   "source": [
    "## データセットの用意\n",
    "\n",
    "今回使用するデータは \"movie review\" と呼ばれる映画の評論記事の分類問題です。\n",
    "評論記事に対して「1(positive)」「0(negative)」の二値がラベルとして付与されています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hBxRZA55-A0H"
   },
   "outputs": [],
   "source": [
    "from gensim.models import word2vec\n",
    "import gensim.downloader as api\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FYaC0Zar0VIG"
   },
   "outputs": [],
   "source": [
    "def load_movie_reviews():\n",
    "    from nltk.corpus import movie_reviews\n",
    "    try:\n",
    "        movie_reviews.categories()\n",
    "    except:\n",
    "        import nltk\n",
    "        nltk.download('movie_reviews')\n",
    "        from nltk.corpus import movie_reviews\n",
    "    raw_data = []\n",
    "\n",
    "    # NLTK's corpus is structured in an interesting way\n",
    "    # first iterate through the two categories (pos and neg)\n",
    "    for category in movie_reviews.categories():\n",
    "\n",
    "        if category == 'pos':\n",
    "            label = '1'\n",
    "        elif category == 'neg':\n",
    "            label = '0'\n",
    "\n",
    "        # each of these categories is just fileids, so grab those\n",
    "        for fileid in movie_reviews.fileids(category):\n",
    "            # then each review is a NLTK class where each item in that class instance is a word\n",
    "            review_words = list(movie_reviews.words(fileid))\n",
    "            if len(review_words) >= 400:\n",
    "                review_words = review_words[:400]\n",
    "            else:\n",
    "                review_words.extend([\" \" for i in range(400 - len(review_words))])\n",
    "            review_dictionary = {\n",
    "                'text': review_words,\n",
    "                'label': label\n",
    "            }\n",
    "\n",
    "            raw_data.append(review_dictionary)\n",
    "\n",
    "    return raw_data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z3Q0F0VK-A0M"
   },
   "outputs": [],
   "source": [
    "if os.path.exists(\"data.pkl\"):\n",
    "    f = open(\"data.pkl\", \"rb\")\n",
    "    data = pickle.load(f)\n",
    "    f.close()\n",
    "else:\n",
    "    data = load_movie_reviews()\n",
    "    f = open(\"data.pkl\", \"wb\")\n",
    "    pickle.dump(data,f)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WUPxiQj4-A0O"
   },
   "source": [
    "## Embedder の用意\n",
    "\n",
    "先ほどの例ではEmbed層をネットワーク内に含めていましたが、Embed 層も含めて学習をすると時間がかかってしまうため、今回はあらかじめ用意された embedder を使用してネットワークに入れる前に単語列をベクトル化しておきます。\n",
    "\n",
    "embedderモデルのダウンロードには時間がかかりますのでご注意ください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z6IvEiQ5-A0R"
   },
   "outputs": [],
   "source": [
    "if os.path.exists(\"embedder.model\"):\n",
    "    model = word2vec.Word2VecKeyedVectors.load_word2vec_format(\"embedder.model\")\n",
    "else:\n",
    "    model = api.load(\"glove-twitter-25\")\n",
    "    model.save_word2vec_format(\"embedder.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oocxBSPH-A0T"
   },
   "outputs": [],
   "source": [
    "def embed_one_word_via_model(word, model):\n",
    "    try:\n",
    "        return model[word]\n",
    "    except:\n",
    "        return np.zeros(model.vector_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vy8BecrW-A0V",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "embedding = []\n",
    "labels = []\n",
    "for d in data:\n",
    "    embedding.append(np.array([embed_one_word_via_model(word,model) for word in d[\"text\"]]))\n",
    "    labels.append(int(d[\"label\"]))\n",
    "embedding = np.array(embedding)\n",
    "labels = np.array(labels)\n",
    "\n",
    "X_train, X_test, T_train, T_test = train_test_split(embedding, labels, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XtARJu9j-A0X"
   },
   "source": [
    "## ネットワーク の用意\n",
    "問4-1. <font color=\"Red\">以下の SimpleRNNClassifier, LSTMClassifier クラスを完成させてください。</font>\n",
    "\n",
    "先ほどの問題では各時刻の入力に対して一つずつ出力が計算されましたが、今回のタスクにおいては、全時刻の入力データに対して一つの出力を計算します。\n",
    "\n",
    "そのため、順伝播においてRNN層やLSTM層の出力に対して、時系列のうち最終出力のみを取り出し、Affine層に入力します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WXX5-R79-A0Y"
   },
   "outputs": [],
   "source": [
    "class SimpleRNNClassifier:\n",
    "    def __init__(self, wordvec_size, hidden_size):\n",
    "        D, H = wordvec_size, hidden_size\n",
    "        rn = np.random.randn\n",
    "        np.random.seed(0)\n",
    "\n",
    "        # 重みの初期化\n",
    "        rnn_Wx = (rn(D, H) / np.sqrt(D)).astype('f')\n",
    "        rnn_Wh = (rn(H, H) / np.sqrt(H)).astype('f')\n",
    "        rnn_b = np.zeros(H).astype('f')\n",
    "        affine_W = (rn(H, 1) / np.sqrt(H)).astype('f')\n",
    "        affine_b = np.zeros(1).astype('f')\n",
    "\n",
    "        # レイヤの生成\n",
    "        self.affine_layer = Affine(affine_W, affine_b)\n",
    "        self.loss_layer = SigmoidWithLoss()\n",
    "        self.rnn_layer = TimeRNN(D, H, stateful=False)\n",
    "\n",
    "        # すべての重みと勾配をリストにまとめる\n",
    "        self.params, self.grads = [], []\n",
    "        self.params += self.rnn_layer.params\n",
    "        self.grads += self.rnn_layer.grads\n",
    "        self.params += self.affine_layer.params\n",
    "        self.grads += self.affine_layer.grads\n",
    "\n",
    "    def forward(self, xs, ts):\n",
    "        xs = self.predict(xs)\n",
    "        loss = self.loss_layer.forward(xs, ts)\n",
    "        return loss\n",
    "    \n",
    "    def predict(self, xs):\n",
    "        xs = self.rnn_layer.forward(xs)[######問4.1.1######] \n",
    "        xs = self.affine_layer.forward(xs)\n",
    "        return xs\n",
    "\n",
    "    def backward(self, dout=1):\n",
    "        dout = self.loss_layer.backward(dout)\n",
    "        dout = self.affine_layer.backward(dout)\n",
    "        dout = self.rnn_layer.backward(dout)\n",
    "        return dout\n",
    "\n",
    "    def reset_state(self):\n",
    "        self.rnn_layer.reset_state()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kYFDYsE7-A0b"
   },
   "outputs": [],
   "source": [
    "class LSTMClassifier:\n",
    "    def __init__(self, wordvec_size, hidden_size):\n",
    "        D, H = wordvec_size, hidden_size\n",
    "        rn = np.random.randn\n",
    "        np.random.seed(0)\n",
    "\n",
    "        # 重みの初期化\n",
    "        rnn_Wx = (rn(D, 4*H) / np.sqrt(D)).astype('f')\n",
    "        rnn_Wh = (rn(H, 4*H) / np.sqrt(H)).astype('f')\n",
    "        rnn_b = np.zeros(4*H).astype('f')\n",
    "        affine_W = (rn(H, 1) / np.sqrt(H)).astype('f')\n",
    "        affine_b = np.zeros(1).astype('f')\n",
    "\n",
    "        # レイヤの生成\n",
    "        self.affine_layer = Affine(affine_W, affine_b)\n",
    "        self.loss_layer = SigmoidWithLoss()\n",
    "        self.rnn_layer = TimeLSTM(D, H, stateful=False)\n",
    "\n",
    "        # すべての重みと勾配をリストにまとめる\n",
    "        self.params, self.grads = [], []\n",
    "        self.params += self.rnn_layer.params\n",
    "        self.grads += self.rnn_layer.grads\n",
    "        self.params += self.affine_layer.params\n",
    "        self.grads += self.affine_layer.grads\n",
    "\n",
    "    def forward(self, xs, ts):\n",
    "        xs = self.predict(xs)\n",
    "        loss = self.loss_layer.forward(xs, ts)\n",
    "        return loss\n",
    "    \n",
    "    def predict(self, xs):\n",
    "        xs = self.rnn_layer.forward(xs)[######問4.1.2######] \n",
    "        xs = self.affine_layer.forward(xs)\n",
    "        return xs\n",
    "\n",
    "    def backward(self, dout=1):\n",
    "        dout = self.loss_layer.backward(dout)\n",
    "        dout = self.affine_layer.backward(dout)\n",
    "        dout = self.rnn_layer.backward(dout)\n",
    "        return dout\n",
    "\n",
    "    def reset_state(self):\n",
    "        self.rnn_layer.reset_state()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OXDRZyAX-A0e"
   },
   "source": [
    "## 学習の実行\n",
    "今回のタスクにおいては、RNNではうまく学習が行われず損失があまり減少してくれません。\n",
    "\n",
    "対してLSTMでは、環境によって結果に差は出ますが、RNNに比べると順調に損失が減少します。\n",
    "\n",
    "学習の実行には少々時間がかかるため、注意してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m7GontpJ-A0f"
   },
   "outputs": [],
   "source": [
    "lr = 0.01\n",
    "n_epoch = 10\n",
    "eval_interval = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jl4z5nq7-A0h",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "rnn_model = SimpleRNNClassifier(25, 100)\n",
    "lstm_model = LSTMClassifier(25, 100)\n",
    "optimizer1 = Adam(lr)\n",
    "optimizer2 = Adam(lr)\n",
    "batch_size = 100\n",
    "rnn_loss_list = []\n",
    "lstm_loss_list = []\n",
    "\n",
    "np.random.seed(0)\n",
    "for epoch in range(n_epoch):\n",
    "    total_rnn_loss = 0\n",
    "    total_lstm_loss = 0\n",
    "    perm = np.random.permutation(len(X_train))\n",
    "    for i, idx in enumerate(range(0, len(X_train), batch_size)):\n",
    "        X_batch = X_train[perm[idx:idx+batch_size]]\n",
    "        T_batch = T_train[perm[idx:idx+batch_size]]\n",
    "        \n",
    "        rnn_loss = rnn_model.forward(X_batch, T_batch)\n",
    "        rnn_model.backward()\n",
    "        optimizer1.update(rnn_model.params, rnn_model.grads)\n",
    "        total_rnn_loss += rnn_loss*len(X_batch)\n",
    "        \n",
    "        lstm_loss = lstm_model.forward(X_batch, T_batch)\n",
    "        lstm_model.backward()\n",
    "        optimizer2.update(lstm_model.params, lstm_model.grads)\n",
    "        total_lstm_loss += lstm_loss*len(X_batch)\n",
    "        if i % eval_interval == 0:\n",
    "            print('| idx %d / %d | RNN loss %.2f | LSTM loss %.2f |'\n",
    "                 %(idx, len(X_train), total_rnn_loss/(idx+batch_size), total_lstm_loss/(idx+batch_size)))\n",
    "    average_rnn_loss = total_rnn_loss / len(X_train)\n",
    "    rnn_loss_list.append(average_rnn_loss)\n",
    "    average_lstm_loss = total_lstm_loss / len(X_train)\n",
    "    lstm_loss_list.append(average_lstm_loss)\n",
    "    rnn_pred = rnn_model.predict(X_test).flatten()\n",
    "    lstm_pred = lstm_model.predict(X_test).flatten()\n",
    "    rnn_accuracy = ((rnn_pred > 0) == T_test).mean() * 100\n",
    "    lstm_accuracy = ((lstm_pred > 0) == T_test).mean() * 100\n",
    "    print('| epoch %d | RNN loss %.2f | LSTM loss %.2f | RNN accuracy %.2f | LSTM accuracy %.2f'\n",
    "          % (epoch+1, average_rnn_loss, average_lstm_loss, rnn_accuracy, lstm_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3HhOzPJ0-A0k"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(range(n_epoch), rnn_loss_list)\n",
    "plt.plot(range(n_epoch), lstm_loss_list)\n",
    "plt.legend([\"RNN\", \"LSTM\"])\n",
    "plt.xlabel(\"#epoch\")\n",
    "plt.ylabel(\"Cross Entropy Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4m_igEHD-A0l"
   },
   "source": [
    "## bi-directional LSTM\n",
    "問4-2. <font color=\"Red\">以下の BidirectionalLSTMClassifier クラスを完成させてください。</font>\n",
    "\n",
    "入力系列データに対して、順方向のデータを処理するforward LSTM層と逆方向のデータを処理するbackward LSTM層を用意します。\n",
    "\n",
    "通常のLSTM層とパラメータ数が大きく変わらないように各LSTM層は hidden_size の半分の次元数を出力します。\n",
    "\n",
    "forward LSTM と backward LSTM の出力を横につなげ、affine層に入力し分類タスクを解きます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IgpTdphW-A0m"
   },
   "outputs": [],
   "source": [
    "class BidirectionalLSTMClassifier:\n",
    "    def __init__(self, wordvec_size, hidden_size):\n",
    "        D, H = wordvec_size, hidden_size //2\n",
    "        rn = np.random.randn\n",
    "        np.random.seed(0)\n",
    "\n",
    "        # 重みの初期化\n",
    "        affine_W = (rn(H * 2, 1) / np.sqrt(H)).astype('f')\n",
    "        affine_b = np.zeros(1).astype('f')\n",
    "\n",
    "        # レイヤの生成\n",
    "        self.affine_layer = Affine(affine_W, affine_b)\n",
    "        self.loss_layer = SigmoidWithLoss()\n",
    "        self.forward_rnn_layer = TimeLSTM(D, H, stateful=False)\n",
    "        self.backward_rnn_layer = TimeLSTM(D, H, stateful=False)\n",
    "\n",
    "        # すべての重みと勾配をリストにまとめる\n",
    "        self.params, self.grads = [], []\n",
    "        self.params += self.forward_rnn_layer.params\n",
    "        self.grads += self.forward_rnn_layer.grads\n",
    "        self.params += self.backward_rnn_layer.params\n",
    "        self.grads += self.backward_rnn_layer.grads\n",
    "        self.params += self.affine_layer.params\n",
    "        self.grads += self.affine_layer.grads\n",
    "\n",
    "    def forward(self, xs, ts):\n",
    "        xs = self.predict(xs)\n",
    "        loss = self.loss_layer.forward(xs, ts)\n",
    "        return loss\n",
    "    \n",
    "    def predict(self, xs):\n",
    "        forward_xs = self.forward_rnn_layer.forward(xs)[######問4.2.1######] \n",
    "        backward_xs = self.backward_rnn_layer.forward(xs[######問4.2.2######])[######問4.2.3######] \n",
    "        xs = np.hstack((forward_xs, backward_xs))\n",
    "        xs = self.affine_layer.forward(xs)\n",
    "        return xs\n",
    "\n",
    "    def backward(self, dout=1):\n",
    "        dout = self.loss_layer.backward(dout)\n",
    "        dout = self.affine_layer.backward(dout)\n",
    "        dout1, dout2 = np.hsplit(dout, 2)\n",
    "        dout1 = self.forward_rnn_layer.backward(dout1)\n",
    "        dout2 = self.backward_rnn_layer.backward(dout2)\n",
    "        return (dout1, dout2)\n",
    "\n",
    "    def reset_state(self):\n",
    "        self.forward_rnn_layer.reset_state()\n",
    "        self.backward_rnn_layer.reset_state()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "74sZCjOy-A0n"
   },
   "source": [
    "## 学習の実行\n",
    "Bidirectional LSTM がLSTMより良い性能を出していることを確認してください。\n",
    "\n",
    "10エポックで損失が0.2を下回っていれば学習成功です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r1OwKNvA-A0o"
   },
   "outputs": [],
   "source": [
    "lr = 0.01\n",
    "n_epoch = 10\n",
    "eval_interval = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JNRv0_2K-A0p",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "bilstm_model = BidirectionalLSTMClassifier(25, 100)\n",
    "optimizer = Adam(lr)\n",
    "batch_size = 100\n",
    "bilstm_loss_list = []\n",
    "np.random.seed(0)\n",
    "for epoch in range(n_epoch):\n",
    "    total_bilstm_loss = 0\n",
    "    perm = np.random.permutation(len(X_train))\n",
    "    for i, idx in enumerate(range(0, len(X_train), batch_size)):\n",
    "        X_batch = X_train[perm[idx:idx+batch_size]]\n",
    "        T_batch = T_train[perm[idx:idx+batch_size]]\n",
    "        \n",
    "        bilstm_loss = bilstm_model.forward(X_batch, T_batch)\n",
    "        bilstm_model.backward()\n",
    "        optimizer.update(bilstm_model.params, bilstm_model.grads)\n",
    "        total_bilstm_loss += bilstm_loss*len(X_batch)\n",
    "        if i % eval_interval == 0:\n",
    "            print('| idx %d / %d | BiLSTM loss %.2f |'\n",
    "                 %(idx, len(X_train), total_bilstm_loss/(idx+batch_size)))\n",
    "\n",
    "    average_bilstm_loss = total_bilstm_loss / len(X_train)\n",
    "    bilstm_loss_list.append(average_bilstm_loss)\n",
    "    bilstm_pred = bilstm_model.predict(X_test).flatten()\n",
    "    bilstm_accuracy = ((bilstm_pred > 0) == T_test).mean() * 100\n",
    "    print('| epoch %d | BiLSTM loss %.2f | BiLSTM accuracy %.2f'\n",
    "          % (epoch+1, average_bilstm_loss, bilstm_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TNat1zIf-A0r",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(range(n_epoch), rnn_loss_list)\n",
    "plt.plot(range(n_epoch), lstm_loss_list)\n",
    "plt.plot(range(n_epoch), bilstm_loss_list)\n",
    "plt.legend([\"RNN\", \"LSTM\", \"BiLSTM\"])\n",
    "plt.xlabel(\"#epoch\")\n",
    "plt.ylabel(\"Cross Entropy Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NO6x3b-t-A0s"
   },
   "source": [
    "\n",
    "## 提出可否"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ie0QOeJt-A0s"
   },
   "outputs": [],
   "source": [
    "if average_bilstm_loss > 0.2:\n",
    "    print(\"RNNの実装に間違いがあります。問4を見直してください。\")\n",
    "else:\n",
    "    print(\"学習成功です。次のステップに進んでください。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IlswOIfWCvFR"
   },
   "source": [
    "## Seq2Seq\n",
    "## データセット用意"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HOzLPGCk-A0u"
   },
   "source": [
    "Seq2seq を用いてタスクを解いていきます。\n",
    "\n",
    "今回用いるデータセットは、足し算の数式を並べたものになります。数式とその答を全て文字列として考え、足し算の式をLSTMによって一文字ずつ読み込み、その答えを一文字ずつ出力していきます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "000wqFK6CvFS"
   },
   "outputs": [],
   "source": [
    "id_to_char = {}\n",
    "char_to_id = {}\n",
    "\n",
    "\n",
    "def _update_vocab(txt):\n",
    "    chars = list(txt)\n",
    "\n",
    "    for i, char in enumerate(chars):\n",
    "        if char not in char_to_id:\n",
    "            tmp_id = len(char_to_id)\n",
    "            char_to_id[char] = tmp_id\n",
    "            id_to_char[tmp_id] = char\n",
    "\n",
    "def load_sequence(file_name='addition.txt'):\n",
    "    file_path = './' + file_name\n",
    "\n",
    "    if not os.path.exists(file_path):\n",
    "        print('No file: %s' % file_name)\n",
    "        return None\n",
    "\n",
    "    questions, answers = [], []\n",
    "\n",
    "    for line in open(file_path, 'r'):\n",
    "        idx = line.find('_')\n",
    "        questions.append(line[:idx])\n",
    "        answers.append(line[idx:-1])\n",
    "\n",
    "    # create vocab dict\n",
    "    for i in range(len(questions)):\n",
    "        q, a = questions[i], answers[i]\n",
    "        _update_vocab(q)\n",
    "        _update_vocab(a)\n",
    "\n",
    "    # create np array\n",
    "    x = np.zeros((len(questions), len(questions[0])), dtype=np.int)\n",
    "    t = np.zeros((len(questions), len(answers[0])), dtype=np.int)\n",
    "\n",
    "    for i, sentence in enumerate(questions):\n",
    "        x[i] = [char_to_id[c] for c in list(sentence)]\n",
    "    for i, sentence in enumerate(answers):\n",
    "        t[i] = [char_to_id[c] for c in list(sentence)]\n",
    "\n",
    "    # shuffle\n",
    "    indices = np.arange(len(x))\n",
    "    np.random.shuffle(indices)\n",
    "    x = x[indices]\n",
    "    t = t[indices]\n",
    "\n",
    "    # 10% for validation set\n",
    "    split_at = len(x) - len(x) // 10\n",
    "    (x_train, x_test) = x[:split_at], x[split_at:]\n",
    "    (t_train, t_test) = t[:split_at], t[split_at:]\n",
    "\n",
    "    return (x_train, t_train), (x_test, t_test)\n",
    "\n",
    "\n",
    "def get_vocab():\n",
    "    return char_to_id, id_to_char\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3uFQosKWCvFT",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(x_train, t_train), (x_test, t_test) = load_sequence('addition.txt')\n",
    "char_to_id, id_to_char = get_vocab()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "djem-PB6CvFV"
   },
   "source": [
    "## ネットワーク定義\n",
    "問5. <font color=\"Red\">以下の Seq2seq クラスを完成させてください。</font>\n",
    "\n",
    "  - Encoderクラスは、各時刻での入力を順伝播させた後、最後の時刻に対応する出力をDecoder クラスに渡します。\n",
    "  - Decoderクラスの順伝播では、まずEncoderクラスの出力を内部状態としてセットし、入力系列データを順伝播させていきます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9TZQsu3QCvFV"
   },
   "outputs": [],
   "source": [
    "class Encoder:\n",
    "    def __init__(self, vocab_size, wordvec_size, hidden_size):\n",
    "        V, D, H = vocab_size, wordvec_size, hidden_size\n",
    "        rn = np.random.randn\n",
    "\n",
    "        embed_W = (rn(V, D) / 100).astype('f')\n",
    " \n",
    "        self.embed = TimeEmbedding(embed_W)\n",
    "        self.lstm = TimeLSTM(D, H, stateful=False)\n",
    "\n",
    "        self.params = self.embed.params + self.lstm.params\n",
    "        self.grads = self.embed.grads + self.lstm.grads\n",
    "        self.hs = None\n",
    "\n",
    "    def forward(self, xs):\n",
    "        xs = self.embed.forward(xs)\n",
    "        hs = self.lstm.forward(xs)\n",
    "        self.hs = hs\n",
    "        return hs[######問4.1######]\n",
    "\n",
    "    def backward(self, dhs):\n",
    "        dout = self.lstm.backward(dhs)\n",
    "        dout = self.embed.backward(dout)\n",
    "        return dout\n",
    "\n",
    "\n",
    "class Decoder:\n",
    "    def __init__(self, vocab_size, wordvec_size, hidden_size):\n",
    "        V, D, H = vocab_size, wordvec_size, hidden_size\n",
    "        rn = np.random.randn\n",
    "\n",
    "        embed_W = (rn(V, D) / 100).astype('f')\n",
    "        affine_W = (rn(H, V) / np.sqrt(H)).astype('f')\n",
    "        affine_b = np.zeros(V).astype('f')\n",
    "\n",
    "        self.embed = TimeEmbedding(embed_W)\n",
    "        self.lstm = TimeLSTM(D, H, stateful=True)\n",
    "        self.affine = TimeAffine(affine_W, affine_b)\n",
    "\n",
    "        self.params, self.grads = [], []\n",
    "        for layer in (self.embed, self.lstm, self.affine):\n",
    "            self.params += layer.params\n",
    "            self.grads += layer.grads\n",
    "\n",
    "    def forward(self, xs, h):\n",
    "        self.lstm.set_state(######問4.2######)\n",
    "\n",
    "        out = self.embed.forward(xs)\n",
    "        out = self.lstm.forward(out)\n",
    "        score = self.affine.forward(out)\n",
    "        return score\n",
    "\n",
    "    def backward(self, dscore):\n",
    "        dout = self.affine.backward(dscore)\n",
    "        dout = self.lstm.backward(dout)\n",
    "        dout = self.embed.backward(dout)\n",
    "        dh = self.lstm.dh\n",
    "        return dh\n",
    "\n",
    "class Seq2seq():\n",
    "    def __init__(self, vocab_size, wordvec_size, hidden_size):\n",
    "        V, D, H = vocab_size, wordvec_size, hidden_size\n",
    "        self.encoder = Encoder(V, D, H)\n",
    "        self.decoder = Decoder(V, D, H)\n",
    "        self.softmax = TimeSoftmaxWithLoss()\n",
    "\n",
    "        self.params = self.encoder.params + self.decoder.params\n",
    "        self.grads = self.encoder.grads + self.decoder.grads\n",
    "\n",
    "    def forward(self, xs, ts):\n",
    "        decoder_xs, decoder_ts = ts[:, :-1], ts[:, 1:]\n",
    "\n",
    "        h = self.encoder.forward(xs) \n",
    "        score = self.decoder.forward(decoder_xs, h) \n",
    "        loss = self.softmax.forward(score, decoder_ts) \n",
    "        return loss\n",
    "\n",
    "    def backward(self, dout=1):\n",
    "        dout = self.softmax.backward(dout)\n",
    "        dh = self.decoder.backward(dout)\n",
    "        dout = self.encoder.backward(dh)\n",
    "        return dout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xnZqVX0ECvFW"
   },
   "outputs": [],
   "source": [
    "vocab_size = len(char_to_id)\n",
    "wordvec_size = 16\n",
    "hideen_size = 128\n",
    "batch_size = 128\n",
    "max_epoch = 8\n",
    "max_grad = 5.0\n",
    "\n",
    "model = Seq2seq(vocab_size, wordvec_size, hideen_size)\n",
    "optimizer = Adam()\n",
    "\n",
    "data_size = len(x_train)\n",
    "max_iters = data_size // batch_size\n",
    "loss_list = []\n",
    "eval_interval = 50\n",
    "current_epoch = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gkmNOSrrCvFY"
   },
   "source": [
    "### 学習、評価"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Shwm9X8OCvFZ",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for epoch in range(max_epoch):\n",
    "    # シャッフル\n",
    "    idx = np.random.permutation(np.arange(data_size))\n",
    "    x = x_train[idx]\n",
    "    t = t_train[idx]\n",
    "    for iters in range(max_iters):\n",
    "        batch_x = x[iters*batch_size:(iters+1)*batch_size]\n",
    "        batch_t = t[iters*batch_size:(iters+1)*batch_size]\n",
    "        # 勾配を求め、パラメータを更新\n",
    "        loss = model.forward(batch_x, batch_t)\n",
    "        model.backward()\n",
    "#         params, grads = remove_duplicate(model.params, model.grads)  # 共有された重みを1つに集約\n",
    "        if max_grad is not None:\n",
    "            clip_grads(model.grads, max_grad)\n",
    "        optimizer.update(model.params,model.grads)\n",
    "        total_loss += loss\n",
    "        loss_count += 1\n",
    "        # 評価\n",
    "        if (eval_interval is not None) and (iters % eval_interval) == 0:\n",
    "            avg_loss = total_loss / loss_count\n",
    "            print('| epoch %d |  iter %d / %d | loss %.2f'\n",
    "                  % (current_epoch + 1, iters + 1, max_iters, avg_loss))\n",
    "            loss_list.append(float(avg_loss))\n",
    "            total_loss, loss_count = 0, 0\n",
    "    current_epoch += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P5TtdA2_-A05",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(range(len(loss_list)), loss_list)\n",
    "plt.xlabel(\"#iter\")\n",
    "plt.ylabel(\"Cross Entropy Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5m6Hk71s-A1D"
   },
   "source": [
    "\n",
    "## 提出可否"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dI9k0bSr-A1D"
   },
   "outputs": [],
   "source": [
    "if loss_list[-1] > 1.1:\n",
    "    print(\"Seq2seqの実装に間違いがあります。問4を見直してください。\")\n",
    "else:\n",
    "    print(\"学習成功です。提出してください\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Day5演習.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
